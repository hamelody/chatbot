import streamlit as st
import os
import io
import fitz  # PyMuPDF
import pandas as pd
import docx
from pptx import Presentation
import faiss
import openai
import numpy as np
import json
import time
from datetime import datetime
from openai import AzureOpenAI
from azure.storage.blob import BlobServiceClient
import tempfile  # ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©
from werkzeug.security import check_password_hash, generate_password_hash
from streamlit_cookies_manager import EncryptedCookieManager
import traceback
import base64

st.set_page_config(
    page_title="ìœ ì•¤ìƒëª…ê³¼í•™ ì—…ë¬´ ê°€ì´ë“œ ë´‡",
    layout="centered",
    initial_sidebar_state="auto"
)

# --- Base64 ì¸ì½”ë”© í•¨ìˆ˜ ì •ì˜ ---
def get_base64_of_bin_file(bin_file_path):
    try:
        with open(bin_file_path, 'rb') as f:
            data = f.read()
        return base64.b64encode(data).decode()
    except FileNotFoundError:
        print(f"ERROR: ë¡œê³  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {bin_file_path}")
        return None
    except Exception as e:
        print(f"ERROR: ë¡œê³  íŒŒì¼ '{bin_file_path}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# --- ì „ì—­ ë³€ìˆ˜ ë° ê²½ë¡œ ì„¤ì • ---
# ë¡œì»¬/ë¦¬í¬ì§€í† ë¦¬ ê¸°ë°˜ íŒŒì¼ (Streamlit Cloud ë°°í¬ ì‹œ í•¨ê»˜ í¬í•¨ë¨)
RULES_PATH_REPO = ".streamlit/prompt_rules.txt"
COMPANY_LOGO_PATH_REPO = "company_logo.png"

# Azure Blob Storage ë‚´ ê°ì²´ ì´ë¦„ (ìƒìˆ˜í™”)
INDEX_BLOB_NAME = "vector_db/vector.index" # Blob ë‚´ ê²½ë¡œ ì‚¬ìš© ê°€ëŠ¥
METADATA_BLOB_NAME = "vector_db/metadata.json"
USERS_BLOB_NAME = "app_data/users.json"
UPLOAD_LOG_BLOB_NAME = "app_logs/upload_log.json"
USAGE_LOG_BLOB_NAME = "app_logs/usage_log.json"

# --- CSS ìŠ¤íƒ€ì¼ ---
st.markdown("""
<style>
    /* CSS ìŠ¤íƒ€ì¼ì€ ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€í•©ë‹ˆë‹¤. */
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button {
        background-color: #FFFFFF; color: #333F48; border: 1px solid #BCC0C4;
        border-radius: 8px; padding: 8px 12px; font-weight: 500;
        width: auto; min-width: 100px; white-space: nowrap; display: inline-block;
        transition: background-color 0.3s ease, border-color 0.3s ease;
    }
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button:hover {
        background-color: #F0F2F5; border-color: #A0A4A8;
    }
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button:active {
        background-color: #E0E2E5;
    }
    .chat-bubble-container { display: flex; flex-direction: column; margin-bottom: 15px; }
    .user-align { align-items: flex-end; }
    .assistant-align { align-items: flex-start; }
    .bubble { padding: 10px 15px; border-radius: 18px; max-width: 75%; word-wrap: break-word; display: inline-block; color: black; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.08); position: relative; }
    .user-bubble { background-color: #90EE90; color: black; border-bottom-right-radius: 5px; }
    .assistant-bubble { background-color: #E9E9EB; border-bottom-left-radius: 5px; }
    .timestamp { font-size: 0.7rem; color: #8E8E93; padding: 2px 5px 0px 5px; }
    .main-title-container { text-align: center; margin-bottom: 24px; }
    .main-title { font-size: 2.1rem; font-weight: bold; display: block; }
    .sub-title { font-size: 0.9rem; color: gray; display: block; margin-top: 4px;}
    .logo-container { display: flex; align-items: center; }
    .logo-image { margin-right: 10px; }
    .version-text { font-size: 0.9rem; color: gray; }
</style>
""", unsafe_allow_html=True)


# --- Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì•± ì‹¤í–‰ ì´ˆê¸°ì— í•œ ë²ˆë§Œ) ---
@st.cache_resource
def get_azure_openai_client_cached():
    print("Attempting to initialize Azure OpenAI client...")
    try:
        client = AzureOpenAI(
            api_key=st.secrets["AZURE_OPENAI_KEY"],
            azure_endpoint=st.secrets["AZURE_OPENAI_ENDPOINT"],
            api_version=st.secrets["AZURE_OPENAI_VERSION"]
        )
        print("Azure OpenAI client initialized successfully.")
        return client
    except KeyError as e:
        st.error(f"Azure OpenAI ì„¤ì • ì˜¤ë¥˜: secrets.toml íŒŒì¼ì— '{e.args[0]}' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ERROR: Missing Azure OpenAI secret: {e.args[0]}")
        return None
    except Exception as e:
        st.error(f"Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ERROR: Azure OpenAI client initialization failed: {e}\n{traceback.format_exc()}")
        return None

@st.cache_resource
def get_azure_blob_clients_cached():
    print("Attempting to initialize Azure Blob Service client...")
    try:
        blob_service_client = BlobServiceClient.from_connection_string(st.secrets["AZURE_BLOB_CONN"])
        container_name = st.secrets["BLOB_CONTAINER"]
        container_client = blob_service_client.get_container_client(container_name)
        print(f"Azure Blob Service client and container client for '{container_name}' initialized successfully.")
        return blob_service_client, container_client
    except KeyError as e:
        st.error(f"Azure Blob Storage ì„¤ì • ì˜¤ë¥˜: secrets.toml íŒŒì¼ì— '{e.args[0]}' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ERROR: Missing Azure Blob Storage secret: {e.args[0]}")
        return None, None
    except Exception as e:
        st.error(f"Azure Blob í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ERROR: Azure Blob client initialization failed: {e}\n{traceback.format_exc()}")
        return None, None

openai_client = get_azure_openai_client_cached()
blob_service, container_client = get_azure_blob_clients_cached()

EMBEDDING_MODEL = None
if openai_client:
    try:
        EMBEDDING_MODEL = st.secrets["AZURE_OPENAI_EMBEDDING_DEPLOYMENT"]
        print(f"Embedding model set to: {EMBEDDING_MODEL}")
    except KeyError:
        st.error("secrets.toml íŒŒì¼ì— 'AZURE_OPENAI_EMBEDDING_DEPLOYMENT' ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ERROR: Missing AZURE_OPENAI_EMBEDDING_DEPLOYMENT secret.")
        openai_client = None
    except Exception as e:
        st.error(f"ì„ë² ë”© ëª¨ë¸ ì„¤ì • ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"ERROR: Loading AZURE_OPENAI_EMBEDDING_DEPLOYMENT secret: {e}")
        openai_client = None

# --- ì‚¬ìš©ì ì •ë³´ ë¡œë“œ/ì €ì¥ (Azure Blob Storage ê¸°ë°˜) ---
@st.cache_resource # ì•± ë¡œë“œ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ë„ë¡, ë‹¨ USERSëŠ” ìì£¼ ë°”ë€” ìˆ˜ ìˆìœ¼ë¯€ë¡œ cache ì „ëµ ê³ ë¯¼ í•„ìš”
def load_users_from_blob(_container_client):
    if not _container_client:
        print("ERROR: Blob Container client is None for load_users_from_blob.")
        return {"admin": {"name": "ê´€ë¦¬ì(ì˜¤ë¥˜)", "department": "ì˜¤ë¥˜", "password_hash": generate_password_hash("error"), "approved": True, "role": "admin"}} # ì•ˆì „ ê¸°ë³¸ê°’

    users_data = {}
    print(f"Attempting to load users data from Blob: '{USERS_BLOB_NAME}'")
    try:
        users_blob_client = _container_client.get_blob_client(USERS_BLOB_NAME)
        if users_blob_client.exists():
            with tempfile.TemporaryDirectory() as tmpdir:
                local_users_path = os.path.join(tmpdir, os.path.basename(USERS_BLOB_NAME))
                with open(local_users_path, "wb") as download_file:
                    download_file.write(users_blob_client.download_blob().readall())
                if os.path.getsize(local_users_path) > 0:
                    with open(local_users_path, "r", encoding="utf-8") as f:
                        users_data = json.load(f)
                    print(f"'{USERS_BLOB_NAME}' loaded successfully from Blob Storage.")
                else: # íŒŒì¼ì€ ì¡´ì¬í•˜ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°
                    print(f"WARNING: '{USERS_BLOB_NAME}' exists in Blob but is empty.")
        else: # íŒŒì¼ì´ ì•„ì˜ˆ ì—†ëŠ” ê²½ìš°
            print(f"WARNING: '{USERS_BLOB_NAME}' not found in Blob Storage. Initializing with default admin.")
        
        # users.jsonì´ ë¹„ì–´ìˆê±°ë‚˜ admin ê³„ì •ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ê´€ë¦¬ì ìƒì„±
        if "admin" not in users_data:
            users_data["admin"] = {
                "name": "ê´€ë¦¬ì", "department": "í’ˆì§ˆë³´ì¦íŒ€",
                "password_hash": generate_password_hash("diteam"), # ì‹¤ì œ ìš´ì˜ ì‹œ ë³€ê²½ ê¶Œì¥
                "approved": True, "role": "admin"
            }
            # ìƒˆ admin ì •ë³´ë¥¼ Blobì— ì¦‰ì‹œ ì €ì¥ ì‹œë„ (ìµœì´ˆ ì‹¤í–‰ ì‹œ)
            if _container_client: # ì¬í™•ì¸
                 # ì´ í•¨ìˆ˜ëŠ” ì•„ë˜ì— ì •ì˜ë¨. ìˆœí™˜ í˜¸ì¶œ í”¼í•˜ê¸° ìœ„í•´ USERS ì „ì—­ ë³€ìˆ˜ ì‚¬ìš© ëŒ€ì‹  ë°”ë¡œ users_data ì „ë‹¬.
                save_data_to_blob(users_data, USERS_BLOB_NAME, _container_client, "ì‚¬ìš©ì ì •ë³´")
            print("Default admin account created/ensured in users_data.")

    except Exception as e:
        print(f"ERROR loading '{USERS_BLOB_NAME}' from Blob: {e}\n{traceback.format_exc()}")
        st.error(f"ì‚¬ìš©ì ì •ë³´ ë¡œë“œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜ ì‹œ ì•ˆì „í•œ ê¸°ë³¸ê°’ ë°˜í™˜
        users_data = {"admin": {"name": "ê´€ë¦¬ì(ì˜¤ë¥˜)", "department": "ì˜¤ë¥˜", "password_hash": generate_password_hash("error"), "approved": True, "role": "admin"}}
    return users_data

def save_data_to_blob(data_to_save, blob_name, _container_client, data_description="ë°ì´í„°"):
    if not _container_client:
        st.error(f"Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ '{data_description}'ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ERROR: Blob Container client is None, cannot save '{blob_name}'.")
        return False
    print(f"Attempting to save '{data_description}' to Blob Storage: '{blob_name}'")
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            local_temp_path = os.path.join(tmpdir, os.path.basename(blob_name))
            with open(local_temp_path, "w", encoding="utf-8") as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
            
            blob_client_instance = _container_client.get_blob_client(blob_name)
            with open(local_temp_path, "rb") as data_stream:
                blob_client_instance.upload_blob(data_stream, overwrite=True)
            print(f"Successfully saved '{data_description}' to Blob: '{blob_name}'")
        return True
    except Exception as e:
        st.error(f"Azure Blobì— '{data_description}' ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"ERROR saving '{data_description}' to Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        return False

USERS = {} # ì „ì—­ ë³€ìˆ˜ ì„ ì–¸
if container_client: # Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ëœ í›„ì— ì‚¬ìš©ì ì •ë³´ ë¡œë“œ
    USERS = load_users_from_blob(container_client)
else:
    st.error("Azure Blob Storage ì—°ê²° ì‹¤íŒ¨. ì‚¬ìš©ì ì •ë³´ë¥¼ ë¡œë“œ/ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("CRITICAL: Cannot load USERS due to Blob client initialization failure.")
    # ë¹„ìƒì‹œ ë¡œì»¬ íŒŒì¼ ì‹œë„ ë˜ëŠ” ì—ëŸ¬ ìƒíƒœ ëª…ì‹œ
    USERS = {"admin": {"name": "ê´€ë¦¬ì(ì—°ê²°ì‹¤íŒ¨)", "department": "ì‹œìŠ¤í…œ", "password_hash": generate_password_hash("fallback"), "approved": True, "role": "admin"}}


# --- ì¿ í‚¤ ë§¤ë‹ˆì € ë° ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì´í›„ ìˆ˜í–‰) ---
cookies = None
cookie_manager_ready = False
# ... (ì´ì „ ë‹µë³€ì˜ ì¿ í‚¤ ì´ˆê¸°í™” ë¡œì§ê³¼ ë™ì¼, ë‹¨ USERS ë¡œë“œ ì´í›„ì— ë°°ì¹˜ë  ìˆ˜ ìˆë„ë¡ ìˆœì„œ ì¡°ì • í•„ìš” ì‹œ ê°€ëŠ¥)
# ì´ ë¶€ë¶„ì€ USERS ë¡œë“œì™€ ì§ì ‘ì ì¸ ì„ í›„ê´€ê³„ëŠ” ì—†ìœ¼ë‚˜, st.secrets ë¡œë“œëŠ” ì´ë¯¸ ìœ„ì—ì„œ ìˆ˜í–‰ë¨.
print(f"Attempting to load COOKIE_SECRET from st.secrets (again for context): {st.secrets.get('COOKIE_SECRET')}")
try:
    cookie_secret_key = st.secrets.get("COOKIE_SECRET")
    if not cookie_secret_key:
        st.error("secrets.toml íŒŒì¼ì— 'COOKIE_SECRET'ì´(ê°€) ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì¿ í‚¤ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ERROR: COOKIE_SECRET is not set or empty in st.secrets (cookie init block).")
    else:
        cookies = EncryptedCookieManager(
            prefix="gmp_chatbot_auth_v2/", # Prefix ë³€ê²½ ì‹œ ê¸°ì¡´ ì¿ í‚¤ì™€ í˜¸í™˜ ì•ˆë¨
            password=cookie_secret_key
        )
        if cookies.ready():
            cookie_manager_ready = True
            print("CookieManager is ready (cookie init block).")
        else:
            print("CookieManager not ready on initial setup (cookie init block).")
except Exception as e:
    st.error(f"ì¿ í‚¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
    print(f"CRITICAL: CookieManager initialization error (cookie init block): {e}\n{traceback.format_exc()}")

SESSION_TIMEOUT = 1800
try:
    session_timeout_secret = st.secrets.get("SESSION_TIMEOUT")
    if session_timeout_secret: SESSION_TIMEOUT = int(session_timeout_secret)
    print(f"Session timeout set to: {SESSION_TIMEOUT} seconds (cookie init block).")
except: pass # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ìœ ì§€

if "authenticated" not in st.session_state:
    print("Initializing session state: 'authenticated' and 'user' (cookie init block)")
    st.session_state["authenticated"] = False
    st.session_state["user"] = {}
    if cookie_manager_ready:
        auth_cookie_val = cookies.get("authenticated")
        print(f"Cookie 'authenticated' value: {auth_cookie_val} (cookie init block)")
        if auth_cookie_val == "true":
            login_time_str = cookies.get("login_time", "0")
            login_time = float(login_time_str if login_time_str else "0")
            if (time.time() - login_time) < SESSION_TIMEOUT:
                user_json_cookie = cookies.get("user", "{}")
                try:
                    user_data_from_cookie = json.loads(user_json_cookie if user_json_cookie else "{}")
                    if user_data_from_cookie:
                        st.session_state["user"] = user_data_from_cookie
                        st.session_state["authenticated"] = True
                        print(f"User '{user_data_from_cookie.get('name')}' authenticated from cookie (cookie init block).")
                    else: # ì¿ í‚¤ ì‚¬ìš©ì ì •ë³´ ë¹„ì–´ìˆìŒ
                        print("User data in cookie is empty. Clearing auth state (cookie init block).")
                        st.session_state["authenticated"] = False
                        if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
                except json.JSONDecodeError: # ì¿ í‚¤ ì†ìƒ
                    print("ERROR: Failed to decode user JSON from cookie. Clearing auth state (cookie init block).")
                    st.session_state["authenticated"] = False
                    if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
            else: # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ
                print("Session timeout. Clearing auth state from cookie (cookie init block).")
                st.session_state["authenticated"] = False
                if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
    else:
        print("CookieManager not ready, cannot restore session from cookie (cookie init block).")


# --- ë¡œê·¸ì¸ UI ë° ë¡œì§ ---
if not st.session_state.get("authenticated", False):
    # ... (ì´ì „ ë‹µë³€ì˜ ë¡œê·¸ì¸ UI ë° ë¡œì§ê³¼ ë™ì¼)
    # ë‹¨, save_users_local() í˜¸ì¶œ ë¶€ë¶„ì„ save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´")ë¡œ ë³€ê²½
    st.title("ğŸ” ë¡œê·¸ì¸ ë˜ëŠ” íšŒì›ê°€ì…")
    if not cookie_manager_ready and st.secrets.get("COOKIE_SECRET"):
        st.warning("ì¿ í‚¤ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    with st.form("auth_form_blob", clear_on_submit=False):
        mode = st.radio("ì„ íƒ", ["ë¡œê·¸ì¸", "íšŒì›ê°€ì…"], key="auth_mode_blob")
        uid = st.text_input("ID", key="auth_uid_blob")
        pwd = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="auth_pwd_blob")
        name, dept = "", ""
        if mode == "íšŒì›ê°€ì…":
            name = st.text_input("ì´ë¦„", key="auth_name_blob")
            dept = st.text_input("ë¶€ì„œ", key="auth_dept_blob")
        submit_button = st.form_submit_button("í™•ì¸")

    if submit_button:
        if not uid or not pwd: st.error("IDì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif mode == "íšŒì›ê°€ì…" and (not name or not dept): st.error("ì´ë¦„ê³¼ ë¶€ì„œë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            if mode == "ë¡œê·¸ì¸":
                user_data_login = USERS.get(uid)
                if not user_data_login: st.error("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” IDì…ë‹ˆë‹¤.")
                elif not user_data_login.get("approved", False): st.warning("ê°€ì… ìŠ¹ì¸ì´ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.")
                elif check_password_hash(user_data_login["password_hash"], pwd):
                    st.session_state["authenticated"] = True
                    st.session_state["user"] = user_data_login
                    if cookie_manager_ready:
                        try:
                            cookies["authenticated"] = "true"; cookies["user"] = json.dumps(user_data_login)
                            cookies["login_time"] = str(time.time()); cookies.save()
                            print(f"Login successful for user '{uid}'. Cookies saved (login block).")
                        except Exception as e_cookie_save: st.warning(f"ë¡œê·¸ì¸ ì¿ í‚¤ ì €ì¥ ì¤‘ ë¬¸ì œ ë°œìƒ: {e_cookie_save}")
                    else: st.warning("ì¿ í‚¤ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë¡œê·¸ì¸ ìƒíƒœë¥¼ ë¸Œë¼ìš°ì €ì— ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.success(f"{user_data_login.get('name', uid)}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤!"); st.rerun()
                else: st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            elif mode == "íšŒì›ê°€ì…":
                if uid in USERS: st.error("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” IDì…ë‹ˆë‹¤.")
                else:
                    USERS[uid] = {"name": name, "department": dept,
                                  "password_hash": generate_password_hash(pwd),
                                  "approved": False, "role": "user"}
                    if not save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´"):
                        st.error("ì‚¬ìš©ì ì •ë³´ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
                        # ì‹¤íŒ¨ ì‹œ USERS ë”•ì…”ë„ˆë¦¬ ë¡¤ë°± ê³ ë ¤ ê°€ëŠ¥
                    else:
                        st.success("ê°€ì… ì‹ ì²­ ì™„ë£Œ! ê´€ë¦¬ì ìŠ¹ì¸ í›„ ë¡œê·¸ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.stop()

# --- ì¸ì¦ í›„ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ ---
current_user_info = st.session_state.get("user", {})

# --- í—¤ë” (ë¡œê³ , ë²„ì „, ë¡œê·¸ì•„ì›ƒ ë²„íŠ¼) ---
# ... (ì´ì „ ë‹µë³€ì˜ í—¤ë” UI ë¡œì§ê³¼ ë™ì¼, COMPANY_LOGO_PATH_REPO ì‚¬ìš©)
top_cols = st.columns([0.7, 0.3])
with top_cols[0]:
    if os.path.exists(COMPANY_LOGO_PATH_REPO): # ë¡œì»¬/ë¦¬í¬ì§€í† ë¦¬ ê²½ë¡œ ì‚¬ìš©
        logo_b64 = get_base64_of_bin_file(COMPANY_LOGO_PATH_REPO)
        if logo_b64:
            st.markdown(f"""
            <div class="logo-container">
                <img src="data:image/png;base64,{logo_b64}" class="logo-image" width="150">
                <span class="version-text">ver 1.8 (Full Blob Sync)</span>
            </div>""", unsafe_allow_html=True)
        else:
            st.markdown(f"""<div class="logo-container"><span class="version-text" style="font-weight:bold;">ìœ ì•¤ìƒëª…ê³¼í•™</span> <span class="version-text" style="margin-left:10px;">ver 1.8 (Full Blob Sync)</span></div>""", unsafe_allow_html=True)
    else:
        print(f"WARNING: Company logo file not found at {COMPANY_LOGO_PATH_REPO}")
        st.markdown(f"""<div class="logo-container"><span class="version-text" style="font-weight:bold;">ìœ ì•¤ìƒëª…ê³¼í•™</span> <span class="version-text" style="margin-left:10px;">ver 1.8 (Full Blob Sync)</span></div>""", unsafe_allow_html=True)

with top_cols[1]:
    st.markdown('<div style="text-align: right;">', unsafe_allow_html=True)
    if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_button_blob"):
        st.session_state["authenticated"] = False; st.session_state["user"] = {}
        if cookie_manager_ready:
            try:
                cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
                print("Logout successful. Cookies cleared (logout block).")
            except Exception as e_logout_cookie: print(f"ERROR: Failed to clear cookies on logout: {e_logout_cookie}")
        st.rerun()
    st.markdown('</div>', unsafe_allow_html=True)


# --- ë²¡í„° DB ë¡œë“œ (Azure Blob Storage ê¸°ë°˜) ---
@st.cache_resource
def load_vector_db_from_blob_cached(_container_client): # í•¨ìˆ˜ëª… ë³€ê²½í•˜ì—¬ cache êµ¬ë¶„
    # ... (ì´ì „ ë‹µë³€ì˜ load_vector_db_from_blob í•¨ìˆ˜ ë‚´ìš©ê³¼ ë™ì¼)
    if not _container_client: return faiss.IndexFlatL2(1536), []
    idx, meta = faiss.IndexFlatL2(1536), []
    print(f"Attempting to load vector DB from Blob: '{INDEX_BLOB_NAME}', '{METADATA_BLOB_NAME}'")
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            # ... (ì´í•˜ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ ë¡œì§ ë™ì¼)
            local_index_path = os.path.join(tmpdir, os.path.basename(INDEX_BLOB_NAME)) # ê²½ë¡œ ìƒì„± ì‹œ basename ì‚¬ìš©
            local_metadata_path = os.path.join(tmpdir, os.path.basename(METADATA_BLOB_NAME))

            index_blob_client = _container_client.get_blob_client(INDEX_BLOB_NAME)
            if index_blob_client.exists():
                with open(local_index_path, "wb") as download_file:
                    download_file.write(index_blob_client.download_blob().readall())
                idx = faiss.read_index(local_index_path)
                print(f"'{INDEX_BLOB_NAME}' loaded successfully from Blob Storage.")
            else:
                st.warning(f"Blob Storageì— '{INDEX_BLOB_NAME}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ì¸ë±ìŠ¤ê°€ ìƒì„±ë©ë‹ˆë‹¤.")

            metadata_blob_client = _container_client.get_blob_client(METADATA_BLOB_NAME)
            if metadata_blob_client.exists():
                with open(local_metadata_path, "wb") as download_file:
                    download_file.write(metadata_blob_client.download_blob().readall())
                if os.path.getsize(local_metadata_path) > 0 :
                    with open(local_metadata_path, "r", encoding="utf-8") as f: meta = json.load(f)
                else: meta = [] # íŒŒì¼ì€ ìˆìœ¼ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°
                print(f"'{METADATA_BLOB_NAME}' loaded successfully from Blob Storage.")
            else:
                st.warning(f"Blob Storageì— '{METADATA_BLOB_NAME}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ë©”íƒ€ë°ì´í„°ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
                meta = []
    except Exception as e: st.error(f"Azure Blob Storageì—ì„œ ë²¡í„°DB ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    return idx, meta

if container_client:
    index, metadata = load_vector_db_from_blob_cached(container_client)
else:
    index, metadata = faiss.IndexFlatL2(1536), []
    st.error("Azure Blob Storage ì—°ê²° ì‹¤íŒ¨ë¡œ ë²¡í„° DBë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


# --- ê·œì¹™ íŒŒì¼ ë¡œë“œ ---
@st.cache_data
def load_prompt_rules_cached(): # í•¨ìˆ˜ëª… ë³€ê²½í•˜ì—¬ cache êµ¬ë¶„
    # ... (ì´ì „ ë‹µë³€ì˜ load_prompt_rules í•¨ìˆ˜ ë‚´ìš©ê³¼ ë™ì¼, RULES_PATH_REPO ì‚¬ìš©)
    if os.path.exists(RULES_PATH_REPO): # ë¦¬í¬ì§€í† ë¦¬ ê²½ë¡œ ì‚¬ìš©
        try:
            with open(RULES_PATH_REPO, "r", encoding="utf-8") as f: rules_content = f.read()
            print(f"Prompt rules loaded successfully from '{RULES_PATH_REPO}'.")
            return rules_content
        except Exception as e: st.warning(f"'{RULES_PATH_REPO}' íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}. ê¸°ë³¸ ê·œì¹™ ì‚¬ìš©.")
    return "ë‹¹ì‹ ì€ ì œì•½íšŒì‚¬ DI/GMP ì „ë¬¸ê°€ ì±—ë´‡ì…ë‹ˆë‹¤... (ê¸°ë³¸ ê·œì¹™)"

PROMPT_RULES_CONTENT = load_prompt_rules_cached()

# --- í…ìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (extract_text_from_file, chunk_text_into_pieces, get_text_embedding) ---
# ... (ì´ì „ ë‹µë³€ì˜ í•´ë‹¹ í•¨ìˆ˜ë“¤ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)
def extract_text_from_file(uploaded_file_obj):
    ext = os.path.splitext(uploaded_file_obj.name)[1].lower(); text_content = ""
    try:
        uploaded_file_obj.seek(0); file_bytes = uploaded_file_obj.read()
        if ext == ".pdf":
            with fitz.open(stream=file_bytes, filetype="pdf") as doc: text_content = "\n".join(p.get_text() for p in doc)
        elif ext == ".docx":
            with io.BytesIO(file_bytes) as doc_io: doc = docx.Document(doc_io); text_content = "\n".join(p.text for p in doc.paragraphs)
        elif ext in (".xlsx", ".xlsm"):
            with io.BytesIO(file_bytes) as excel_io: df = pd.read_excel(excel_io); text_content = df.to_string(index=False)
        elif ext == ".csv":
            with io.BytesIO(file_bytes) as csv_io:
                try: df = pd.read_csv(csv_io)
                except UnicodeDecodeError: df = pd.read_csv(csv_io, encoding='cp949')
                text_content = df.to_string(index=False)
        elif ext == ".pptx":
            with io.BytesIO(file_bytes) as ppt_io: prs = Presentation(ppt_io); text_content = "\n".join(s.text for slide in prs.slides for s in slide.shapes if hasattr(s, "text"))
        else: st.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {ext}"); return ""
    except Exception as e: st.error(f"'{uploaded_file_obj.name}' íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}"); return ""
    return text_content.strip()

def chunk_text_into_pieces(text_to_chunk, chunk_size=500):
    if not text_to_chunk or not text_to_chunk.strip(): return []; chunks_list, current_buffer = [], ""
    for line in text_to_chunk.split("\n"):
        stripped_line = line.strip()
        if not stripped_line and not current_buffer.strip(): continue
        if len(current_buffer) + len(stripped_line) < chunk_size: current_buffer += stripped_line + "\n"
        else:
            if current_buffer.strip(): chunks_list.append(current_buffer.strip())
            current_buffer = stripped_line + "\n"
    if current_buffer.strip(): chunks_list.append(current_buffer.strip())
    return [c for c in chunks_list if c]

def get_text_embedding(text_to_embed):
    if not openai_client or not EMBEDDING_MODEL: return None
    if not text_to_embed or not text_to_embed.strip(): return None
    try:
        response = openai_client.embeddings.create(input=[text_to_embed], model=EMBEDDING_MODEL)
        return response.data[0].embedding
    except Exception as e: st.error(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"); return None

# --- ìœ ì‚¬ë„ ê²€ìƒ‰ ë° ë¬¸ì„œ ì¶”ê°€ (Blob ì—°ë™) ---
def search_similar_chunks(query_text, k_results=5):
    # ... (ì´ì „ ë‹µë³€ì˜ search_similar_chunks í•¨ìˆ˜ ë‚´ìš©ê³¼ ë™ì¼)
    if index is None or index.ntotal == 0 or not metadata: return []
    query_vector = get_text_embedding(query_text)
    if query_vector is None: return []
    try:
        _, indices_found = index.search(np.array([query_vector]).astype("float32"), k_results)
        return [metadata[i]["content"] for i in indices_found[0] if 0 <= i < len(metadata)]
    except Exception as e: st.error(f"ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}"); return []


def add_document_to_vector_db_and_blob(uploaded_file_obj, text_content, text_chunks, _container_client): # í•¨ìˆ˜ëª… ë³€ê²½
    global index, metadata # ì „ì—­ index, metadata ì§ì ‘ ìˆ˜ì •
    if not text_chunks: st.warning(f"'{uploaded_file_obj.name}' íŒŒì¼ì—ì„œ ì²˜ë¦¬í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."); return False
    if not _container_client: st.error("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ í•™ìŠµ ê²°ê³¼ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return False

    # ... (ì´ì „ ë‹µë³€ì˜ add_document_to_vector_db í•¨ìˆ˜ ë‚´ìš©ê³¼ ìœ ì‚¬í•˜ê²Œ Blob ì €ì¥ ë¡œì§ í¬í•¨)
    # upload_log.jsonë„ Blobì— ì €ì¥í•˜ë„ë¡ ìˆ˜ì •
    vectors_to_add, new_metadata_entries_for_current_file = [], []
    for chunk in text_chunks:
        embedding = get_text_embedding(chunk)
        if embedding is not None:
            vectors_to_add.append(embedding)
            new_metadata_entries_for_current_file.append({"file_name": uploaded_file_obj.name, "content": chunk})

    if not vectors_to_add: st.warning(f"'{uploaded_file_obj.name}' íŒŒì¼ì—ì„œ ìœ íš¨í•œ ì„ë² ë”©ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); return False

    try:
        if vectors_to_add: index.add(np.array(vectors_to_add).astype("float32"))
        metadata.extend(new_metadata_entries_for_current_file)
        print(f"Added {len(vectors_to_add)} new chunks to in-memory DB from '{uploaded_file_obj.name}'.")

        if not save_data_to_blob(index.ntotal > 0 and faiss.serialize_index(index).tobytes(), INDEX_BLOB_NAME, _container_client, "ë²¡í„° ì¸ë±ìŠ¤", is_binary=True): # ë°”ì´ë„ˆë¦¬ ì €ì¥ í•¨ìˆ˜ í•„ìš”
             st.error("ë²¡í„° ì¸ë±ìŠ¤ Blob ì €ì¥ ì‹¤íŒ¨"); return False # ë°”ì´ë„ˆë¦¬ ì €ì¥ì„ ìœ„í•œ save_data_to_blob ìˆ˜ì • í•„ìš” ë˜ëŠ” ë³„ë„ í•¨ìˆ˜
        # faiss.serialize_index ëŒ€ì‹  ì„ì‹œíŒŒì¼ ì‚¬ìš©
        with tempfile.TemporaryDirectory() as tmpdir:
            temp_index_path = os.path.join(tmpdir, "temp.index")
            faiss.write_index(index, temp_index_path)
            if not save_binary_data_to_blob(temp_index_path, INDEX_BLOB_NAME, _container_client, "ë²¡í„° ì¸ë±ìŠ¤"):
                 st.error("ë²¡í„° ì¸ë±ìŠ¤ Blob ì €ì¥ ì‹¤íŒ¨"); return False

        if not save_data_to_blob(metadata, METADATA_BLOB_NAME, _container_client, "ë©”íƒ€ë°ì´í„°"):
            st.error("ë©”íƒ€ë°ì´í„° Blob ì €ì¥ ì‹¤íŒ¨"); return False

        # ì—…ë¡œë“œ ë¡œê·¸ë„ Blobì— ì €ì¥
        user_info = st.session_state.get("user", {}); uploader_name = user_info.get("name", "N/A")
        new_log_entry = {"file": uploaded_file_obj.name, "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                         "chunks_added": len(vectors_to_add), "uploader": uploader_name}
        
        current_upload_logs = load_data_from_blob(UPLOAD_LOG_BLOB_NAME, _container_client, "ì—…ë¡œë“œ ë¡œê·¸", default_value=[])
        if not isinstance(current_upload_logs, list): current_upload_logs = [] # íƒ€ì… ì²´í¬
        current_upload_logs.append(new_log_entry)
        if not save_data_to_blob(current_upload_logs, UPLOAD_LOG_BLOB_NAME, _container_client, "ì—…ë¡œë“œ ë¡œê·¸"):
            st.warning("ì—…ë¡œë“œ ë¡œê·¸ë¥¼ Blobì— ì €ì¥í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return True
    except Exception as e: st.error(f"ë¬¸ì„œ í•™ìŠµ ë˜ëŠ” Azure Blob ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}"); return False

def save_binary_data_to_blob(local_file_path, blob_name, _container_client, data_description="ë°”ì´ë„ˆë¦¬ ë°ì´í„°"):
    if not _container_client: return False
    try:
        blob_client_instance = _container_client.get_blob_client(blob_name)
        with open(local_file_path, "rb") as data_stream:
            blob_client_instance.upload_blob(data_stream, overwrite=True)
        print(f"Successfully saved binary '{data_description}' to Blob: '{blob_name}'")
        return True
    except Exception as e: st.error(f"Azure Blobì— '{data_description}' ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}"); return False


def load_data_from_blob(blob_name, _container_client, data_description="ë°ì´í„°", default_value=None, is_binary=False):
    if not _container_client: return default_value
    try:
        blob_client_instance = _container_client.get_blob_client(blob_name)
        if blob_client_instance.exists():
            with tempfile.TemporaryDirectory() as tmpdir:
                local_temp_path = os.path.join(tmpdir, os.path.basename(blob_name))
                with open(local_temp_path, "wb") as download_file:
                    download_file.write(blob_client_instance.download_blob().readall())
                if os.path.getsize(local_temp_path) > 0:
                    if is_binary: # ë°”ì´ë„ˆë¦¬ íŒŒì¼ ì²˜ë¦¬ (ì˜ˆ: Faiss ì¸ë±ìŠ¤) - ì´ í•¨ìˆ˜ì—ì„œëŠ” JSONë§Œ ê°€ì •
                        # ì´ ë¶€ë¶„ì€ load_vector_db_from_blob_cachedì—ì„œ ì§ì ‘ ì²˜ë¦¬
                        print(f"Binary data '{data_description}' should be loaded by a specific function.")
                        return local_temp_path # ì„ì‹œ ê²½ë¡œ ë°˜í™˜ ë˜ëŠ” ì‹¤ì œ ë°ì´í„° ë¡œë“œ
                    else:
                        with open(local_temp_path, "r", encoding="utf-8") as f:
                            loaded_data = json.load(f)
                        print(f"'{data_description}' loaded from Blob: '{blob_name}'")
                        return loaded_data
                else: return default_value if default_value is not None else {} if not is_binary else None # ë¹ˆ íŒŒì¼
        else: print(f"'{data_description}' not found in Blob: '{blob_name}'. Returning default.")
    except Exception as e: print(f"Error loading '{data_description}' from Blob '{blob_name}': {e}")
    return default_value if default_value is not None else {} if not is_binary else None


def save_original_file_to_blob(uploaded_file_obj, _container_client): # _container_client ì¸ì ì¶”ê°€
    # ... (ì´ì „ ë‹µë³€ì˜ save_original_file_to_blob í•¨ìˆ˜ ë‚´ìš©ê³¼ ë™ì¼, _container_client ì‚¬ìš©)
    if not _container_client: st.error("Azure Blob í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ ì•ˆë¨"); return None
    try:
        uploaded_file_obj.seek(0)
        blob_client_for_original = _container_client.get_blob_client(blob=f"uploaded_originals/{uploaded_file_obj.name}") # ê²½ë¡œ ì¶”ê°€
        blob_client_for_original.upload_blob(uploaded_file_obj.getvalue(), overwrite=True)
        file_url = f"Original file '{uploaded_file_obj.name}' saved to Blob." # URL ìƒì„±ì€ ë³µì¡í•˜ë¯€ë¡œ ë‹¨ìˆœ ë©”ì‹œì§€
        print(file_url)
        return file_url
    except Exception as e: st.error(f"'{uploaded_file_obj.name}' ì›ë³¸ íŒŒì¼ Blob ì—…ë¡œë“œ ì˜¤ë¥˜: {e}"); return None

# --- ì‚¬ìš©ëŸ‰ ë¡œê¹… í•¨ìˆ˜ (Blob ì—°ë™) ---
def log_openai_api_usage_to_blob(user_id_str, model_name_str, usage_stats_obj, _container_client): # _container_client ì¸ì ì¶”ê°€
    # ... (ì´ì „ ë‹µë³€ì˜ log_openai_api_usage_to_blob í•¨ìˆ˜ ë‚´ìš©ê³¼ ë™ì¼, _container_client ì‚¬ìš©)
    if not _container_client: print("ERROR: Blob Container client is None for API usage log."); return

    new_log_entry = {
        "user_id": user_id_str, "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "model_used": model_name_str, "prompt_tokens": usage_stats_obj.prompt_tokens,
        "completion_tokens": usage_stats_obj.completion_tokens, "total_tokens": usage_stats_obj.total_tokens
    }
    current_usage_logs = load_data_from_blob(USAGE_LOG_BLOB_NAME, _container_client, "API ì‚¬ìš©ëŸ‰ ë¡œê·¸", default_value=[])
    if not isinstance(current_usage_logs, list): current_usage_logs = [] # íƒ€ì… ë³´ì¥
    current_usage_logs.append(new_log_entry)
    if not save_data_to_blob(current_usage_logs, USAGE_LOG_BLOB_NAME, _container_client, "API ì‚¬ìš©ëŸ‰ ë¡œê·¸"):
        st.warning("API ì‚¬ìš©ëŸ‰ ë¡œê·¸ë¥¼ Blobì— ì €ì¥í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


# --- ë©”ì¸ UI êµ¬ì„± ---
# ... (ì´ì „ ë‹µë³€ì˜ ë©”ì¸ UI êµ¬ì„±ê³¼ ë™ì¼)
# ë‹¨, add_document... í˜¸ì¶œ ì‹œ _container_client ì „ë‹¬
# log_openai_api_usage... í˜¸ì¶œ ì‹œ _container_client ì „ë‹¬
# ê´€ë¦¬ì íƒ­ì˜ ì‚¬ìš©ì ìŠ¹ì¸/ê±°ì ˆ ì‹œ save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´") í˜¸ì¶œ
# ê´€ë¦¬ì íƒ­ì˜ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ì‹œ load_data_from_blob(USAGE_LOG_BLOB_NAME, container_client, ...) í˜¸ì¶œ

st.markdown("""
<div class="main-title-container">
  <span class="main-title">ìœ ì•¤ìƒëª…ê³¼í•™ GMP/SOP ì—…ë¬´ ê°€ì´ë“œ ë´‡</span>
  <span class="sub-title">Made by DI.PART</span>
</div>
""", unsafe_allow_html=True)

tab_labels_list = ["ğŸ’¬ ì—…ë¬´ ì§ˆë¬¸"]
if current_user_info.get("role") == "admin":
    tab_labels_list.append("âš™ï¸ ê´€ë¦¬ì ì„¤ì •")

main_tabs_list = st.tabs(tab_labels_list)
chat_interface_tab = main_tabs_list[0]
admin_settings_tab = main_tabs_list[1] if len(main_tabs_list) > 1 else None

with chat_interface_tab:
    # ... (ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ UI ë¡œì§ - ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)
    # ë‹¨, log_openai_api_usage_to_blob í˜¸ì¶œ ì‹œ container_client ì „ë‹¬
    st.header("ì—…ë¬´ ì§ˆë¬¸")
    st.markdown("ğŸ’¡ ì˜ˆì‹œ: SOP ë°±ì—… ì£¼ê¸°, PIC/S Annex 11 ì°¨ì´ ë“±")

    if "messages" not in st.session_state: st.session_state["messages"] = []
    for msg_item in st.session_state["messages"]:
        # ... (ë©”ì‹œì§€ í‘œì‹œ ë¡œì§)
        role, content, time_str = msg_item.get("role"), msg_item.get("content", ""), msg_item.get("time", "")
        align_class = "user-align" if role == "user" else "assistant-align"
        bubble_class = "user-bubble" if role == "user" else "assistant-bubble"
        st.markdown(f"""<div class="chat-bubble-container {align_class}"><div class="bubble {bubble_class}">{content}</div><div class="timestamp">{time_str}</div></div>""", unsafe_allow_html=True)


    st.markdown("<div style='height:16px'></div>", unsafe_allow_html=True)
    if st.button("ğŸ“‚ íŒŒì¼ ì²¨ë¶€/ìˆ¨ê¸°ê¸°", key="toggle_chat_uploader_button_blob"):
        st.session_state.show_uploader = not st.session_state.get("show_uploader", False)

    chat_file_uploader_key = "chat_file_uploader_widget_blob"
    uploaded_chat_file_runtime = None # form ì œì¶œê³¼ ë¬´ê´€í•˜ê²Œ í˜„ì¬ ìœ„ì ¯ ìƒíƒœ ë°˜ì˜
    if st.session_state.get("show_uploader", False):
        uploaded_chat_file_runtime = st.file_uploader("ì§ˆë¬¸ê³¼ í•¨ê»˜ ì°¸ê³ í•  íŒŒì¼ ì²¨ë¶€ (ì„ íƒ ì‚¬í•­)",
                                     type=["pdf","docx","xlsx","xlsm","csv","pptx"],
                                     key=chat_file_uploader_key)
        if uploaded_chat_file_runtime: st.caption(f"ì²¨ë¶€ë¨: {uploaded_chat_file_runtime.name}")

    with st.form("chat_input_form_blob", clear_on_submit=True):
        query_input_col, send_button_col = st.columns([4,1])
        with query_input_col:
            user_query_input = st.text_input("ì§ˆë¬¸ ì…ë ¥:", placeholder="ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
                                             key="user_query_text_input_blob", label_visibility="collapsed")
        with send_button_col:
            send_query_button = st.form_submit_button("ì „ì†¡")

    if send_query_button and user_query_input.strip() and openai_client:
        timestamp_now_str = datetime.now().strftime("%Y-%m-%d %H:%M")
        st.session_state["messages"].append({"role":"user", "content":user_query_input, "time":timestamp_now_str})
        
        user_id_for_log = current_user_info.get("name", "anonymous_chat_user") # í˜„ì¬ ë¡œê·¸ì¸ ì‚¬ìš©ì ì´ë¦„ ì‚¬ìš©

        # íŒŒì¼ ì—…ë¡œë”ì˜ í˜„ì¬ ê°’ (form ì œì¶œ ì‹œì )ì„ ì‚¬ìš©
        # uploaded_chat_file_runtimeëŠ” ìœ„ì ¯ì˜ ì‹¤ì‹œê°„ ìƒíƒœë¥¼ ë°˜ì˜í•˜ë¯€ë¡œ, form ì œì¶œ ì‹œì ì˜ íŒŒì¼ì€
        # í•´ë‹¹ í‚¤ë¡œ session_stateì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ ë” ëª…í™•í•  ìˆ˜ ìˆìœ¼ë‚˜, í˜„ì¬ êµ¬ì¡°ì—ì„œëŠ” uploaded_chat_file_runtime ì‚¬ìš©ë„ ê°€ëŠ¥
        
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            try:
                context_chunks_for_prompt = []
                if uploaded_chat_file_runtime: # ìœ„ì—ì„œ ì •ì˜ëœ ë³€ìˆ˜ ì‚¬ìš©
                    temp_file_text = extract_text_from_file(uploaded_chat_file_runtime)
                    if temp_file_text: # .strip()ì€ chunk_text_into_pieces ë‚´ë¶€ì—ì„œ ì²˜ë¦¬
                        temp_file_chunks = chunk_text_into_pieces(temp_file_text)
                        if temp_file_chunks:
                            for chunk_piece in temp_file_chunks:
                                context_chunks_for_prompt.extend(search_similar_chunks(chunk_piece, k_results=2))
                            if not context_chunks_for_prompt: context_chunks_for_prompt.append(temp_file_text[:2000])
                        else: st.info(f"'{uploaded_chat_file_runtime.name}' íŒŒì¼ì—ì„œ ìœ ì˜ë¯¸í•œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    else: st.info(f"'{uploaded_chat_file_runtime.name}' íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‚´ìš©ì…ë‹ˆë‹¤.")

                if not context_chunks_for_prompt or len(context_chunks_for_prompt) < 3:
                    needed_k = max(1, 3 - len(context_chunks_for_prompt))
                    context_chunks_for_prompt.extend(search_similar_chunks(user_query_input, k_results=needed_k))

                final_unique_context = list(set(c for c in context_chunks_for_prompt if c and c.strip()))
                if not final_unique_context: st.info("ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì°¸ê³  ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ë‹µë³€ì„ ì‹œë„í•©ë‹ˆë‹¤.")

                context_string_for_llm = "\n\n---\n\n".join(final_unique_context) if final_unique_context else "í˜„ì¬ ì°¸ê³ í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
                system_prompt_content = f"{PROMPT_RULES_CONTENT}\n\nìœ„ì˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë° ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ë¬¸ì„œì˜ ë‚´ìš©ì…ë‹ˆë‹¤:\n<ë¬¸ì„œ ì‹œì‘>\n{context_string_for_llm}\n<ë¬¸ì„œ ë>"
                
                chat_messages = [{"role":"system", "content": system_prompt_content}, {"role":"user", "content": user_query_input}]
                chat_completion_response = openai_client.chat.completions.create(
                    model=st.secrets["AZURE_OPENAI_DEPLOYMENT"], messages=chat_messages, max_tokens=4000, temperature=0.1)
                assistant_response_content = chat_completion_response.choices[0].message.content.strip()
                st.session_state["messages"].append({"role":"assistant", "content":assistant_response_content, "time":timestamp_now_str})
                
                if chat_completion_response.usage and container_client: # container_client í™•ì¸
                    log_openai_api_usage_to_blob(user_id_for_log, st.secrets["AZURE_OPENAI_DEPLOYMENT"], chat_completion_response.usage, container_client)

            except Exception as gen_err: # ë” í¬ê´„ì ì¸ ì˜ˆì™¸ ì²˜ë¦¬
                st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {gen_err}")
                st.session_state["messages"].append({"role":"assistant", "content":"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "time":timestamp_now_str})
                print(f"ERROR: General error during response generation: {gen_err}\n{traceback.format_exc()}")
        st.rerun()
    elif send_query_button and not openai_client:
         st.error("OpenAI ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")


if admin_settings_tab:
    with admin_settings_tab:
        st.header("âš™ï¸ ê´€ë¦¬ì ì„¤ì •")
        st.subheader("ğŸ‘¥ ê°€ì… ìŠ¹ì¸ ëŒ€ê¸°ì")
        if not USERS: st.warning("ì‚¬ìš©ì ì •ë³´ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (USERS ë”•ì…”ë„ˆë¦¬ ë¹„ì–´ìˆìŒ).")
        else:
            pending_approval_users = {uid:udata for uid,udata in USERS.items() if not udata.get("approved")}
            if pending_approval_users:
                for pending_uid, pending_user_data in pending_approval_users.items():
                    with st.expander(f"{pending_user_data.get('name','N/A')} ({pending_uid}) - {pending_user_data.get('department','N/A')}"):
                        approve_col, reject_col = st.columns(2)
                        if approve_col.button("ìŠ¹ì¸", key=f"admin_approve_user_blob_{pending_uid}"):
                            USERS[pending_uid]["approved"] = True
                            if save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´"):
                                st.success(f"'{pending_uid}' ì‚¬ìš©ìë¥¼ ìŠ¹ì¸í•˜ê³  Blobì— ì €ì¥í–ˆìŠµë‹ˆë‹¤."); st.rerun()
                            else: st.error("ì‚¬ìš©ì ìŠ¹ì¸ ì •ë³´ Blob ì €ì¥ ì‹¤íŒ¨.")
                        if reject_col.button("ê±°ì ˆ", key=f"admin_reject_user_blob_{pending_uid}"):
                            USERS.pop(pending_uid)
                            if save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´"):
                                st.info(f"'{pending_uid}' ì‚¬ìš©ìì˜ ê°€ì… ì‹ ì²­ì„ ê±°ì ˆí•˜ê³  Blobì— ì €ì¥í–ˆìŠµë‹ˆë‹¤."); st.rerun()
                            else: st.error("ì‚¬ìš©ì ê±°ì ˆ ì •ë³´ Blob ì €ì¥ ì‹¤íŒ¨.")
            else: st.info("ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")

        st.subheader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ë° í•™ìŠµ (Azure Blob Storage)")
        admin_file_uploader_key = "admin_file_uploader_widget_blob"
        admin_uploaded_file = st.file_uploader("í•™ìŠµí•  íŒŒì¼ ì—…ë¡œë“œ", type=["pdf","docx","xlsx","xlsm","csv","pptx"], key=admin_file_uploader_key)

        if admin_uploaded_file and container_client:
            with st.spinner(f"'{admin_uploaded_file.name}' íŒŒì¼ ì²˜ë¦¬ ë° í•™ìŠµ ì¤‘..."):
                extracted_content = extract_text_from_file(admin_uploaded_file)
                if extracted_content:
                    content_chunks = chunk_text_into_pieces(extracted_content)
                    if content_chunks:
                        original_file_blob_url = save_original_file_to_blob(admin_uploaded_file, container_client)
                        if original_file_blob_url: st.caption(f"ì›ë³¸ íŒŒì¼ Blob ì €ì¥ë¨ (ë©”ì‹œì§€ ë‹¨ìˆœí™”)")

                        if add_document_to_vector_db_and_blob(admin_uploaded_file, extracted_content, content_chunks, container_client):
                            st.success(f"'{admin_uploaded_file.name}' íŒŒì¼ í•™ìŠµ ë° Azure Blob Storageì— ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
                        else: st.error(f"'{admin_uploaded_file.name}' í•™ìŠµ ë˜ëŠ” Blob ì—…ë°ì´íŠ¸ ì˜¤ë¥˜.")
                    else: st.warning(f"'{admin_uploaded_file.name}' íŒŒì¼ì—ì„œ ìœ ì˜ë¯¸í•œ ì²­í¬ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else: st.warning(f"'{admin_uploaded_file.name}' íŒŒì¼ì´ ë¹„ì—ˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‚´ìš©ì…ë‹ˆë‹¤.")
            st.rerun()
        elif admin_uploaded_file and not container_client:
            st.error("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  í•™ìŠµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")

        st.subheader("ğŸ“Š API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (Blob ë¡œê·¸ ê¸°ë°˜)")
        if container_client:
            usage_data_from_blob = load_data_from_blob(USAGE_LOG_BLOB_NAME, container_client, "API ì‚¬ìš©ëŸ‰ ë¡œê·¸", default_value=[])
            if usage_data_from_blob and isinstance(usage_data_from_blob, list):
                df_usage_stats=pd.DataFrame(usage_data_from_blob)
                if not df_usage_stats.empty:
                    total_tokens_used = df_usage_stats["total_tokens"].sum() if "total_tokens" in df_usage_stats.columns else 0
                    st.metric("ì´ API í˜¸ì¶œ ìˆ˜", len(df_usage_stats))
                    st.metric("ì´ ì‚¬ìš© í† í° ìˆ˜", f"{int(total_tokens_used):,}") # ì •ìˆ˜ë¡œ ë³€í™˜
                    token_cost_per_unit = 0.0
                    try: token_cost_per_unit=float(st.secrets.get("TOKEN_COST","0"))
                    except: pass
                    st.metric("ì˜ˆìƒ ë¹„ìš© (USD)", f"${int(total_tokens_used) * token_cost_per_unit:.4f}")
                    if "timestamp" in df_usage_stats.columns:
                        st.dataframe(df_usage_stats.sort_values(by="timestamp",ascending=False), use_container_width=True)
                    else: st.dataframe(df_usage_stats, use_container_width=True)
                else: st.info("ê¸°ë¡ëœ API ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ Blobì— ì—†ìŠµë‹ˆë‹¤.")
            else: st.info("Blobì—ì„œ API ì‚¬ìš©ëŸ‰ ë¡œê·¸ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else: st.warning("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")

        st.subheader("ğŸ“‚ Azure Blob Storage íŒŒì¼ ëª©ë¡ (ìµœê·¼ 100ê°œ)")
        # ... (ì´ì „ ë‹µë³€ì˜ Blob íŒŒì¼ ëª©ë¡ UIì™€ ë™ì¼í•˜ê²Œ ìœ ì§€)
        if container_client:
            try:
                blob_list_display = []
                for blob_item in container_client.list_blobs(results_per_page=100): # name_starts_with="app_data/" ë“±ìœ¼ë¡œ í•„í„°ë§ ê°€ëŠ¥
                    blob_list_display.append({
                        "íŒŒì¼ëª…": blob_item.name, 
                        "í¬ê¸° (bytes)": blob_item.size, 
                        "ìˆ˜ì •ì¼": blob_item.last_modified.strftime('%Y-%m-%d %H:%M:%S') if blob_item.last_modified else 'N/A'
                    })
                if blob_list_display:
                    df_blobs_display = pd.DataFrame(blob_list_display)
                    st.dataframe(df_blobs_display.sort_values(by="ìˆ˜ì •ì¼", ascending=False), use_container_width=True)
                else: st.info("Azure Blob Storageì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ (ë˜ëŠ” ì§€ì •ëœ ê²½ë¡œì—).")
            except Exception as e: st.error(f"Azure Blob íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        else: st.warning("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ íŒŒì¼ ëª©ë¡ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")