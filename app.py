import streamlit as st # ì²« ë²ˆì§¸ ë¼ì¸ ë˜ëŠ” ì£¼ì„/ë¹ˆ ì¤„ ì œì™¸ ì²« ë¼ì¸
# st.set_page_config ë³´ë‹¤ ë¨¼ì € ì‹¤í–‰ë˜ë©´ ì•ˆ ë˜ëŠ” importëŠ” ì•„ë˜ë¡œ ì´ë™

import os
import io
import fitz  # PyMuPDF
import pandas as pd
import docx
from pptx import Presentation
import faiss
import openai # openai íŒ¨í‚¤ì§€ ì§ì ‘ ì„í¬íŠ¸
import numpy as np
import json
import time
from datetime import datetime
from openai import AzureOpenAI, APIConnectionError, APITimeoutError, RateLimitError, APIStatusError # êµ¬ì²´ì ì¸ ì˜ˆì™¸ íƒ€ì… ì„í¬íŠ¸
from azure.core.exceptions import AzureError # Azure SDK ê³µí†µ ì˜ˆì™¸
from azure.storage.blob import BlobServiceClient
import tempfile
from werkzeug.security import check_password_hash, generate_password_hash
# from streamlit_cookies_manager import EncryptedCookieManager # ì•„ë˜ë¡œ ì´ë™
import traceback
import base64 # ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€
import tiktoken

# Streamlit ì•±ì˜ ê°€ì¥ ì²« ë²ˆì§¸ ëª…ë ¹ìœ¼ë¡œ st.set_page_config() í˜¸ì¶œ
st.set_page_config(
    page_title="ìœ ì•¤ìƒëª…ê³¼í•™ ì—…ë¬´ ê°€ì´ë“œ ë´‡",
    layout="centered",
    initial_sidebar_state="auto"
)

# --- st.set_page_config() í˜¸ì¶œ ì´í›„ì— ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ---
from streamlit_cookies_manager import EncryptedCookieManager
print("Imported streamlit_cookies_manager after set_page_config.")

# --- Tiktoken ì¸ì½”ë” ë¡œë“œ ---
try:
    tokenizer = tiktoken.get_encoding("o200k_base")
    print("Tiktoken 'o200k_base' encoder loaded successfully.")
except Exception as e:
    st.error(f"Tiktoken ì¸ì½”ë” ë¡œë“œ ì‹¤íŒ¨: {e}. í† í° ê¸°ë°˜ ê¸¸ì´ ì œí•œì´ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print(f"ERROR: Failed to load tiktoken encoder: {e}")
    tokenizer = None

# --- Base64 ì¸ì½”ë”© í•¨ìˆ˜ ì •ì˜ ---
def get_base64_of_bin_file(bin_file_path):
    try:
        with open(bin_file_path, 'rb') as f:
            data = f.read()
        return base64.b64encode(data).decode()
    except FileNotFoundError:
        print(f"ERROR: ë¡œê³  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {bin_file_path}")
        return None
    except Exception as e:
        print(f"ERROR: ë¡œê³  íŒŒì¼ '{bin_file_path}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# --- ì „ì—­ ë³€ìˆ˜ ë° ê²½ë¡œ ì„¤ì • ---
RULES_PATH_REPO = ".streamlit/prompt_rules.txt"
COMPANY_LOGO_PATH_REPO = "company_logo.png"
INDEX_BLOB_NAME = "vector_db/vector.index"
METADATA_BLOB_NAME = "vector_db/metadata.json"
USERS_BLOB_NAME = "app_data/users.json"
UPLOAD_LOG_BLOB_NAME = "app_logs/upload_log.json"
USAGE_LOG_BLOB_NAME = "app_logs/usage_log.json"
AZURE_OPENAI_TIMEOUT = 60.0
MODEL_MAX_INPUT_TOKENS = 128000
MODEL_MAX_OUTPUT_TOKENS = 16384 # GPT-4o-miniì˜ ê²½ìš° 16kê°€ ì•„ë‹ ìˆ˜ ìˆìŒ, ëª¨ë¸ ìŠ¤í™ í™•ì¸ í•„ìš” (ì˜ˆ: 4k ë˜ëŠ” 8k)
                                # ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ ìš”ì²­í•˜ì‹ ëŒ€ë¡œ ìœ ì§€í•˜ë‚˜, ì‹¤ì œ ëª¨ë¸ì˜ ìµœëŒ€ ì¶œë ¥ í† í°ìœ¼ë¡œ ì¡°ì • í•„ìš”
BUFFER_TOKENS = 500
TARGET_INPUT_TOKENS_FOR_PROMPT = MODEL_MAX_INPUT_TOKENS - MODEL_MAX_OUTPUT_TOKENS - BUFFER_TOKENS
IMAGE_DESCRIPTION_MAX_TOKENS = 500 # ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì‹œ ìµœëŒ€ í† í°


# --- CSS ìŠ¤íƒ€ì¼ ---
st.markdown("""
<style>
    /* (CSS ë‚´ìš©ì€ ì´ì „ ë‹µë³€ê³¼ ë™ì¼) */
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button {
        background-color: #FFFFFF; color: #333F48; border: 1px solid #BCC0C4;
        border-radius: 8px; padding: 8px 12px; font-weight: 500;
        width: auto; min-width: 100px; white-space: nowrap; display: inline-block;
        transition: background-color 0.3s ease, border-color 0.3s ease;
    }
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button:hover {
        background-color: #F0F2F5; border-color: #A0A4A8;
    }
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button:active {
        background-color: #E0E2E5;
    }
    .chat-bubble-container { display: flex; flex-direction: column; margin-bottom: 15px; }
    .user-align { align-items: flex-end; }
    .assistant-align { align-items: flex-start; }
    .bubble { padding: 10px 15px; border-radius: 18px; max-width: 75%; word-wrap: break-word; display: inline-block; color: black; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.08); position: relative; }
    .user-bubble { background-color: #90EE90; color: black; border-bottom-right-radius: 5px; }
    .assistant-bubble { background-color: #E9E9EB; border-bottom-left-radius: 5px; }
    .timestamp { font-size: 0.7rem; color: #8E8E93; padding: 2px 5px 0px 5px; }
    .main-app-title-container { text-align: center; margin-bottom: 24px; }
    .main-app-title { font-size: 2.1rem; font-weight: bold; display: block; }
    .main-app-subtitle { font-size: 0.9rem; color: gray; display: block; margin-top: 4px;}
    .logo-container { display: flex; align-items: center; }
    .logo-image { margin-right: 10px; }
    .version-text { font-size: 0.9rem; color: gray; }
    .login-page-header-container { text-align: center; margin-top: 20px; margin-bottom: 10px;}
    .login-page-main-title { font-size: 1.8rem; font-weight: bold; display: block; color: #333F48; }
    .login-page-sub-title { font-size: 0.85rem; color: gray; display: block; margin-top: 2px; margin-bottom: 20px;}
    .login-form-title { font-size: 1.6rem; font-weight: bold; text-align: center; margin-top: 10px; margin-bottom: 25px; }
    @media (max-width: 768px) {
        .main-app-title { font-size: 1.8rem; }
        .main-app-subtitle { font-size: 0.8rem; }
        .login-page-main-title { font-size: 1.5rem; }
        .login-page-sub-title { font-size: 0.8rem; }
        .login-form-title { font-size: 1.3rem; margin-bottom: 20px; }
    }
</style>
""", unsafe_allow_html=True)

# --- Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
@st.cache_resource
def get_azure_openai_client_cached():
    print("Attempting to initialize Azure OpenAI client...")
    try:
        api_version_to_use = st.secrets.get("AZURE_OPENAI_VERSION", "2024-02-15-preview") 
        print(f"DEBUG: Initializing AzureOpenAI client with API version: {api_version_to_use}")
        client = AzureOpenAI(
            api_key=st.secrets["AZURE_OPENAI_KEY"],
            azure_endpoint=st.secrets["AZURE_OPENAI_ENDPOINT"],
            api_version=api_version_to_use,
            timeout=AZURE_OPENAI_TIMEOUT
        )
        print("Azure OpenAI client initialized successfully.")
        return client
    except KeyError as e:
        st.error(f"Azure OpenAI ì„¤ì • ì˜¤ë¥˜: secretsì— '{e.args[0]}' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.") 
        print(f"ERROR: Missing Azure OpenAI secret: {e.args[0]}")
        return None
    except Exception as e:
        st.error(f"Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}.") 
        print(f"ERROR: Azure OpenAI client initialization failed: {e}\n{traceback.format_exc()}")
        return None

@st.cache_resource
def get_azure_blob_clients_cached():
    print("Attempting to initialize Azure Blob Service client...")
    try:
        conn_str = st.secrets["AZURE_BLOB_CONN"]
        blob_service_client = BlobServiceClient.from_connection_string(conn_str, connection_timeout=60, read_timeout=120)
        container_name = st.secrets["BLOB_CONTAINER"]
        container_client = blob_service_client.get_container_client(container_name)
        print(f"Azure Blob Service client and container client for '{container_name}' initialized successfully.")
        return blob_service_client, container_client
    except KeyError as e:
        st.error(f"Azure Blob Storage ì„¤ì • ì˜¤ë¥˜: secretsì— '{e.args[0]}' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.") 
        print(f"ERROR: Missing Azure Blob Storage secret: {e.args[0]}")
        return None, None
    except Exception as e:
        st.error(f"Azure Blob í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}.") 
        print(f"ERROR: Azure Blob client initialization failed: {e}\n{traceback.format_exc()}")
        return None, None

openai_client = get_azure_openai_client_cached()
blob_service, container_client = get_azure_blob_clients_cached()

EMBEDDING_MODEL = None
if openai_client:
    try:
        EMBEDDING_MODEL = st.secrets["AZURE_OPENAI_EMBEDDING_DEPLOYMENT"]
        print(f"Embedding model set to: {EMBEDDING_MODEL}")
    except KeyError:
        st.error("secretsì— 'AZURE_OPENAI_EMBEDDING_DEPLOYMENT' ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.") 
        print("ERROR: Missing AZURE_OPENAI_EMBEDDING_DEPLOYMENT secret.")
        openai_client = None # ì„ë² ë”© ëª¨ë¸ ì—†ì´ëŠ” ì£¼ìš” ê¸°ëŠ¥ ë¶ˆê°€
    except Exception as e:
        st.error(f"ì„ë² ë”© ëª¨ë¸ ì„¤ì • ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"ERROR: Loading AZURE_OPENAI_EMBEDDING_DEPLOYMENT secret: {e}")
        openai_client = None


# --- ë°ì´í„° ë¡œë“œ/ì €ì¥ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (Blob ì—°ë™) ---
# (load_data_from_blob, save_data_to_blob, save_binary_data_to_blob ì´ì „ê³¼ ë™ì¼)
def load_data_from_blob(blob_name, _container_client, data_description="ë°ì´í„°", default_value=None):
    if not _container_client:
        print(f"ERROR: Blob Container client is None for load_data_from_blob ('{data_description}'). Returning default.")
        return default_value if default_value is not None else {}
    print(f"Attempting to load '{data_description}' from Blob: '{blob_name}'")
    try:
        blob_client_instance = _container_client.get_blob_client(blob_name)
        if blob_client_instance.exists():
            with tempfile.TemporaryDirectory() as tmpdir:
                local_temp_path = os.path.join(tmpdir, os.path.basename(blob_name))
                print(f"Downloading '{blob_name}' to '{local_temp_path}'...")
                with open(local_temp_path, "wb") as download_file:
                    download_stream = blob_client_instance.download_blob(timeout=60)
                    download_file.write(download_stream.readall())
                if os.path.getsize(local_temp_path) > 0:
                    with open(local_temp_path, "r", encoding="utf-8") as f:
                        loaded_data = json.load(f)
                    print(f"'{data_description}' loaded successfully from Blob: '{blob_name}'")
                    return loaded_data
                else:
                    print(f"WARNING: '{data_description}' file '{blob_name}' exists in Blob but is empty. Returning default.")
                    return default_value if default_value is not None else {}
        else:
            print(f"WARNING: '{data_description}' file '{blob_name}' not found in Blob Storage. Returning default.")
            return default_value if default_value is not None else {}
    except json.JSONDecodeError:
        print(f"ERROR: Failed to decode JSON for '{data_description}' from Blob '{blob_name}'. Returning default.")
        st.warning(f"'{data_description}' íŒŒì¼({blob_name})ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        return default_value if default_value is not None else {}
    except AzureError as ae:
        print(f"AZURE ERROR loading '{data_description}' from Blob '{blob_name}': {ae}\n{traceback.format_exc()}")
        st.warning(f"'{data_description}' ë¡œë“œ ì¤‘ Azure ì„œë¹„ìŠ¤ ì˜¤ë¥˜ ë°œìƒ: {ae}. ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        return default_value if default_value is not None else {}
    except Exception as e:
        print(f"GENERAL ERROR loading '{data_description}' from Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        st.warning(f"'{data_description}' ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}. ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        return default_value if default_value is not None else {}

def save_data_to_blob(data_to_save, blob_name, _container_client, data_description="ë°ì´í„°"):
    if not _container_client:
        st.error(f"Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ '{data_description}'ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ERROR: Blob Container client is None, cannot save '{blob_name}'.")
        return False
    print(f"Attempting to save '{data_description}' to Blob Storage: '{blob_name}'")
    try:
        if not isinstance(data_to_save, (dict, list)):
            st.error(f"'{data_description}' ì €ì¥ ì‹¤íŒ¨: ë°ì´í„°ê°€ JSONìœ¼ë¡œ ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…(dict ë˜ëŠ” list)ì´ ì•„ë‹™ë‹ˆë‹¤.")
            print(f"ERROR: Data for '{blob_name}' is not JSON serializable (type: {type(data_to_save)}).")
            return False
        with tempfile.TemporaryDirectory() as tmpdir:
            local_temp_path = os.path.join(tmpdir, os.path.basename(blob_name))
            with open(local_temp_path, "w", encoding="utf-8") as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
            blob_client_instance = _container_client.get_blob_client(blob_name)
            print(f"Uploading '{local_temp_path}' to Blob '{blob_name}'...")
            with open(local_temp_path, "rb") as data_stream:
                blob_client_instance.upload_blob(data_stream, overwrite=True, timeout=60)
            print(f"Successfully saved '{data_description}' to Blob: '{blob_name}'")
        return True
    except AzureError as ae:
        st.error(f"Azure Blobì— '{data_description}' ì €ì¥ ì¤‘ Azure ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {ae}")
        print(f"AZURE ERROR saving '{data_description}' to Blob '{blob_name}': {ae}\n{traceback.format_exc()}")
        return False
    except Exception as e:
        st.error(f"Azure Blobì— '{data_description}' ì €ì¥ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
        print(f"GENERAL ERROR saving '{data_description}' to Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        return False

def save_binary_data_to_blob(local_file_path, blob_name, _container_client, data_description="ë°”ì´ë„ˆë¦¬ ë°ì´í„°"):
    if not _container_client:
        st.error(f"Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ '{data_description}' ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ERROR: Blob Container client is None, cannot save binary '{blob_name}'.")
        return False
    if not os.path.exists(local_file_path):
        st.error(f"'{data_description}' ì €ì¥ì„ ìœ„í•œ ë¡œì»¬ íŒŒì¼ '{local_file_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ERROR: Local file for binary data not found: '{local_file_path}'")
        return False
    print(f"Attempting to save binary '{data_description}' from '{local_file_path}' to Blob: '{blob_name}'")
    try:
        blob_client_instance = _container_client.get_blob_client(blob_name)
        with open(local_file_path, "rb") as data_stream:
            blob_client_instance.upload_blob(data_stream, overwrite=True, timeout=120)
        print(f"Successfully saved binary '{data_description}' to Blob: '{blob_name}'")
        return True
    except AzureError as ae:
        st.error(f"Azure Blobì— ë°”ì´ë„ˆë¦¬ '{data_description}' ì €ì¥ ì¤‘ Azure ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {ae}")
        print(f"AZURE ERROR saving binary '{data_description}' to Blob '{blob_name}': {ae}\n{traceback.format_exc()}")
        return False
    except Exception as e:
        st.error(f"Azure Blobì— ë°”ì´ë„ˆë¦¬ '{data_description}' ì €ì¥ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
        print(f"GENERAL ERROR saving binary '{data_description}' to Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        return False

# --- ì‚¬ìš©ì ì •ë³´ ë¡œë“œ ---
# (ì´ì „ê³¼ ë™ì¼)
USERS = {}
if container_client:
    USERS = load_data_from_blob(USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´", default_value={})
    if not isinstance(USERS, dict) :
        print(f"ERROR: USERS loaded from blob is not a dict ({type(USERS)}). Re-initializing.")
        USERS = {}
    if "admin" not in USERS:
        print(f"'{USERS_BLOB_NAME}' from Blob is empty or admin is missing. Creating default admin.")
        USERS["admin"] = {
            "name": "ê´€ë¦¬ì", "department": "í’ˆì§ˆë³´ì¦íŒ€",
            "password_hash": generate_password_hash(st.secrets.get("ADMIN_PASSWORD", "diteam_fallback_secret")), # secretsì—ì„œ ì½ë„ë¡ ìˆ˜ì •
            "approved": True, "role": "admin"
        }
        if not save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì´ˆê¸° ì‚¬ìš©ì ì •ë³´"):
             st.warning("ê¸°ë³¸ ê´€ë¦¬ì ì •ë³´ë¥¼ Blobì— ì €ì¥í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹¤í–‰ ì‹œ ë‹¤ì‹œ ì‹œë„ë©ë‹ˆë‹¤.")
else:
    st.error("Azure Blob Storage ì—°ê²° ì‹¤íŒ¨. ì‚¬ìš©ì ì •ë³´ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•±ì´ ì •ìƒ ë™ì‘í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("CRITICAL: Cannot initialize USERS due to Blob client failure.")
    USERS = {"admin": {"name": "ê´€ë¦¬ì(ì—°ê²°ì‹¤íŒ¨)", "department": "ì‹œìŠ¤í…œ", "password_hash": generate_password_hash("fallback"), "approved": True, "role": "admin"}}


# --- ì¿ í‚¤ ë§¤ë‹ˆì € ë° ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì•ˆì •ì„± ê°•í™” ë²„ì „) ---
# (ì´ì „ê³¼ ë™ì¼)
cookies = None
cookie_manager_ready = False
print(f"Attempting to load COOKIE_SECRET from st.secrets: {st.secrets.get('COOKIE_SECRET')}")
try:
    cookie_secret_key = st.secrets.get("COOKIE_SECRET")
    if not cookie_secret_key:
        st.error("secretsì— 'COOKIE_SECRET'ì´(ê°€) ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.") 
        print("ERROR: COOKIE_SECRET is not set or empty in st.secrets.")
    else:
        cookies = EncryptedCookieManager(
            prefix="gmp_chatbot_auth_v5_1/", # ë²„ì „ì—…ë°ì´íŠ¸ (ì„ íƒì‚¬í•­)
            password=cookie_secret_key
        )
        try:
            if cookies.ready():
                cookie_manager_ready = True
                print("CookieManager is ready on initial setup try.")
            else:
                print("CookieManager not ready on initial setup try (may resolve on first interaction).")
        except Exception as e_ready_init: 
            print(f"WARNING: cookies.ready() call during initial setup failed: {e_ready_init}")
            cookie_manager_ready = False 
except Exception as e:
    st.error(f"ì¿ í‚¤ ë§¤ë‹ˆì € ê°ì²´ ìƒì„± ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
    print(f"CRITICAL: CookieManager object creation error: {e}\n{traceback.format_exc()}")

SESSION_TIMEOUT = 1800
try:
    session_timeout_secret = st.secrets.get("SESSION_TIMEOUT")
    if session_timeout_secret: SESSION_TIMEOUT = int(session_timeout_secret)
    print(f"Session timeout set to: {SESSION_TIMEOUT} seconds.")
except (ValueError, TypeError):
    print(f"WARNING: SESSION_TIMEOUT in secrets ('{session_timeout_secret}') is not a valid integer. Using default {SESSION_TIMEOUT}s.")
except Exception as e:
     print(f"WARNING: Error reading SESSION_TIMEOUT from secrets: {e}. Using default {SESSION_TIMEOUT}s.")

if "authenticated" not in st.session_state:
    print("Initializing st.session_state: 'authenticated', 'user', and 'messages'")
    st.session_state["authenticated"] = False
    st.session_state["user"] = {}
    st.session_state["messages"] = []
    if cookies:
        is_ready_for_cookie_load = False
        try:
            if cookies.ready():
                is_ready_for_cookie_load = True
                print("CookieManager became ready before attempting to load cookies from browser.")
        except Exception as e_ready_check:
            print(f"WARNING: cookies.ready() check before loading cookies failed: {e_ready_check}")

        if is_ready_for_cookie_load:
            try:
                auth_cookie_val = cookies.get("authenticated")
                print(f"Cookie 'authenticated' value on session init: {auth_cookie_val}")
                if auth_cookie_val == "true":
                    login_time_str = cookies.get("login_time", "0")
                    try:
                        login_time = float(login_time_str if login_time_str and login_time_str.replace('.', '', 1).isdigit() else "0")
                    except ValueError:
                        print(f"WARNING: Invalid login_time_str from cookie: {login_time_str}. Defaulting to 0.")
                        login_time = 0.0
                    if (time.time() - login_time) < SESSION_TIMEOUT:
                        user_json_cookie = cookies.get("user", "{}")
                        try:
                            user_data_from_cookie = json.loads(user_json_cookie if user_json_cookie else "{}")
                            if user_data_from_cookie and isinstance(user_data_from_cookie, dict):
                                st.session_state["user"] = user_data_from_cookie
                                st.session_state["authenticated"] = True
                                print(f"User '{user_data_from_cookie.get('name')}' authenticated from cookie.")
                            else:
                                print("User data in cookie is empty or invalid. Clearing auth state for cookie.")
                                st.session_state["authenticated"] = False
                                if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save(key="cookie_save_on_invalid_user_data")
                        except json.JSONDecodeError:
                            print("ERROR: Failed to decode user JSON from cookie. Clearing auth state for cookie.")
                            st.session_state["authenticated"] = False
                            if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save(key="cookie_save_on_json_decode_error")
                    else:
                        print("Session timeout detected from cookie. Clearing auth state for cookie.")
                        st.session_state["authenticated"] = False
                        st.session_state["messages"] = []
                        if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save(key="cookie_save_on_session_timeout")
                else:
                    print("Authenticated cookie not set to 'true'.")
                    st.session_state["authenticated"] = False
            except Exception as e_cookie_load:
                print(f"ERROR during cookie processing (get/save): {e_cookie_load}\n{traceback.format_exc()}")
                st.session_state["authenticated"] = False
        else:
            print("CookieManager not ready when attempting to load cookies from browser (after initial check).")
            st.session_state["authenticated"] = False
    else:
         print("CookieManager object is None, cannot restore session.")
         st.session_state["authenticated"] = False

if "messages" not in st.session_state:
    st.session_state["messages"] = []
    print("Double check: Initializing messages as it was not in session_state before login UI.")

if cookies and not cookie_manager_ready: 
    try:
        if cookies.ready():
            cookie_manager_ready = True
            print("CookieManager became ready just before login UI check.")
        else:
            print("CookieManager still not ready just before login UI check.")
    except Exception as e_ready_login_ui:
        print(f"WARNING: cookies.ready() call just before login UI check failed: {e_ready_login_ui}")

# --- ë¡œê·¸ì¸ UI ë° ë¡œì§ ---
# (ì´ì „ê³¼ ë™ì¼)
if not st.session_state.get("authenticated", False):
    st.markdown("""
    <div class="login-page-header-container">
      <span class="login-page-main-title">ìœ ì•¤ìƒëª…ê³¼í•™ GMP/SOP ì—…ë¬´ ê°€ì´ë“œ ë´‡</span>
      <span class="login-page-sub-title">Made by DI.PART</span>
    </div>
    """, unsafe_allow_html=True)
    st.markdown('<p class="login-form-title">ğŸ” ë¡œê·¸ì¸ ë˜ëŠ” íšŒì›ê°€ì…</p>', unsafe_allow_html=True)
    if not cookie_manager_ready and st.secrets.get("COOKIE_SECRET"):
        st.warning("ì¿ í‚¤ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    with st.form("auth_form_final_v5_img_txt", clear_on_submit=False): # í‚¤ ë³€ê²½
        mode = st.radio("ì„ íƒ", ["ë¡œê·¸ì¸", "íšŒì›ê°€ì…"], key="auth_mode_final_v5_img_txt")
        uid = st.text_input("ID", key="auth_uid_final_v5_img_txt")
        pwd = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="auth_pwd_final_v5_img_txt")
        name, dept = "", ""
        if mode == "íšŒì›ê°€ì…":
            name = st.text_input("ì´ë¦„", key="auth_name_final_v5_img_txt")
            dept = st.text_input("ë¶€ì„œ", key="auth_dept_final_v5_img_txt")
        submit_button = st.form_submit_button("í™•ì¸")

    if submit_button:
        if not uid or not pwd: st.error("IDì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif mode == "íšŒì›ê°€ì…" and (not name or not dept): st.error("ì´ë¦„ê³¼ ë¶€ì„œë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            if mode == "ë¡œê·¸ì¸":
                user_data_login = USERS.get(uid)
                if not user_data_login: st.error("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” IDì…ë‹ˆë‹¤.")
                elif not user_data_login.get("approved", False): st.warning("ê°€ì… ìŠ¹ì¸ì´ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.")
                elif check_password_hash(user_data_login["password_hash"], pwd):
                    st.session_state["authenticated"] = True
                    st.session_state["user"] = user_data_login
                    st.session_state["messages"] = [] # ë¡œê·¸ì¸ ì‹œ ë©”ì‹œì§€ ì´ˆê¸°í™”
                    print(f"Login successful for user '{uid}'. Chat messages cleared.")
                    if cookies and cookies.ready(): 
                        try:
                            cookies["authenticated"] = "true"; cookies["user"] = json.dumps(user_data_login)
                            cookies["login_time"] = str(time.time()); cookies.save(key="cookie_save_on_login")
                            print(f"Cookies saved for user '{uid}'.")
                        except Exception as e_cookie_save:
                            st.warning(f"ë¡œê·¸ì¸ ì¿ í‚¤ ì €ì¥ ì¤‘ ë¬¸ì œ ë°œìƒ: {e_cookie_save}")
                            print(f"ERROR: Failed to save login cookies: {e_cookie_save}")
                    else:
                        st.warning("ì¿ í‚¤ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë¡œê·¸ì¸ ìƒíƒœë¥¼ ë¸Œë¼ìš°ì €ì— ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        print("WARNING: CookieManager not ready during login, cannot save cookies.")
                    st.success(f"{user_data_login.get('name', uid)}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤!"); st.rerun()
                else: st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            elif mode == "íšŒì›ê°€ì…":
                if uid in USERS: st.error("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” IDì…ë‹ˆë‹¤.")
                else:
                    USERS[uid] = {"name": name, "department": dept,
                                  "password_hash": generate_password_hash(pwd),
                                  "approved": False, "role": "user"}
                    if not save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´"):
                        st.error("ì‚¬ìš©ì ì •ë³´ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
                        USERS.pop(uid, None) # ì €ì¥ ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
                    else:
                        st.success("ê°€ì… ì‹ ì²­ ì™„ë£Œ! ê´€ë¦¬ì ìŠ¹ì¸ í›„ ë¡œê·¸ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.stop()

# --- ì¸ì¦ í›„ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ ---
current_user_info = st.session_state.get("user", {})

# --- í—¤ë” (ë¡œê³ , ë²„ì „, ë¡œê·¸ì•„ì›ƒ ë²„íŠ¼) ---
# (ì´ì „ê³¼ ë™ì¼)
top_cols_main = st.columns([0.7, 0.3])
with top_cols_main[0]:
    if os.path.exists(COMPANY_LOGO_PATH_REPO):
        logo_b64 = get_base64_of_bin_file(COMPANY_LOGO_PATH_REPO)
        if logo_b64:
            st.markdown(f"""
            <div class="logo-container">
                <img src="data:image/png;base64,{logo_b64}" class="logo-image" width="150">
                <span class="version-text">ver 0.9.7 (Image/TXT Support)</span>
            </div>""", unsafe_allow_html=True)
        else: # ë¡œê³  íŒŒì¼ì€ ìˆìœ¼ë‚˜ base64 ë³€í™˜ ì‹¤íŒ¨ ì‹œ
            st.markdown(f"""<div class="logo-container"><span class="version-text" style="font-weight:bold;">ìœ ì•¤ìƒëª…ê³¼í•™</span> <span class="version-text" style="margin-left:10px;">ver 0.9.7 (Image/TXT Support)</span></div>""", unsafe_allow_html=True)
    else: # ë¡œê³  íŒŒì¼ ìì²´ê°€ ì—†ì„ ì‹œ
        print(f"WARNING: Company logo file not found at {COMPANY_LOGO_PATH_REPO}")
        st.markdown(f"""<div class="logo-container"><span class="version-text" style="font-weight:bold;">ìœ ì•¤ìƒëª…ê³¼í•™</span> <span class="version-text" style="margin-left:10px;">ver 0.9.7 (Image/TXT Support)</span></div>""", unsafe_allow_html=True)


with top_cols_main[1]:
    st.markdown('<div style="text-align: right;">', unsafe_allow_html=True)
    if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_button_final_v5_img_txt"): # í‚¤ ë³€ê²½
        st.session_state["authenticated"] = False
        st.session_state["user"] = {}
        st.session_state["messages"] = [] # ë¡œê·¸ì•„ì›ƒ ì‹œ ë©”ì‹œì§€ ì´ˆê¸°í™”
        print("Logout successful. Chat messages cleared.")
        if cookies and cookies.ready(): 
             try:
                 # ì¿ í‚¤ ì‚­ì œ ì‹œì—ëŠ” del ë³´ë‹¤ ë¹ˆ ê°’ìœ¼ë¡œ ë®ì–´ì“°ëŠ” ê²ƒì´ ì¼ë¶€ í™˜ê²½ì—ì„œ ë” ì•ˆì •ì ì¼ ìˆ˜ ìˆìŒ
                 cookies["authenticated"] = "false"
                 cookies["user"] = ""
                 cookies["login_time"] = ""
                 cookies.save(key="cookie_save_on_logout")
                 print("Cookies cleared on logout.")
             except Exception as e_logout_cookie:
                 print(f"ERROR: Failed to clear cookies on logout: {e_logout_cookie}")
        else:
              print("WARNING: CookieManager not ready during logout, cannot clear cookies.")
        st.rerun()
    st.markdown('</div>', unsafe_allow_html=True)


# --- ë©”ì¸ ì•± ì œëª© (ë¡œê·¸ì¸ í›„) ---
# (ì´ì „ê³¼ ë™ì¼)
st.markdown("""
<div class="main-app-title-container">
  <span class="main-app-title">ìœ ì•¤ìƒëª…ê³¼í•™ GMP/SOP ì—…ë¬´ ê°€ì´ë“œ ë´‡</span>
  <span class="main-app-subtitle">Made by DI.PART</span>
</div>
""", unsafe_allow_html=True)

# --- ë²¡í„° DB ë¡œë“œ (Azure Blob Storage ê¸°ë°˜) ---
# (ì´ì „ê³¼ ë™ì¼, current_embedding_dimension ì‚¬ìš© ë° ì°¨ì› ê²€ì¦ ë¡œì§ í¬í•¨)
@st.cache_resource
def load_vector_db_from_blob_cached(_container_client):
    if not _container_client:
        print("ERROR: Blob Container client is None for load_vector_db_from_blob_cached.")
        return faiss.IndexFlatL2(1536), [] # ê¸°ë³¸ ì„ë² ë”© ì°¨ì› (text-embedding-3-small)
    current_embedding_dimension = 1536 
    idx, meta = faiss.IndexFlatL2(current_embedding_dimension), []
    print(f"Attempting to load vector DB from Blob: '{INDEX_BLOB_NAME}', '{METADATA_BLOB_NAME}' with dimension {current_embedding_dimension}")
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            local_index_path = os.path.join(tmpdir, os.path.basename(INDEX_BLOB_NAME))
            local_metadata_path = os.path.join(tmpdir, os.path.basename(METADATA_BLOB_NAME))
            
            index_blob_client = _container_client.get_blob_client(INDEX_BLOB_NAME)
            if index_blob_client.exists():
                print(f"Downloading '{INDEX_BLOB_NAME}'...")
                with open(local_index_path, "wb") as download_file:
                    download_stream = index_blob_client.download_blob(timeout=60)
                    download_file.write(download_stream.readall())
                if os.path.getsize(local_index_path) > 0:
                    try:
                        idx = faiss.read_index(local_index_path)
                        if idx.d != current_embedding_dimension:
                            print(f"WARNING: Loaded FAISS index dimension ({idx.d}) does not match expected dimension ({current_embedding_dimension}). Re-initializing.")
                            idx = faiss.IndexFlatL2(current_embedding_dimension)
                            meta = [] # ë©”íƒ€ë°ì´í„°ë„ í•¨ê»˜ ì´ˆê¸°í™”
                        else:
                            print(f"'{INDEX_BLOB_NAME}' loaded successfully from Blob Storage. Dimension: {idx.d}")
                    except Exception as e_faiss_read:
                        print(f"ERROR reading FAISS index: {e_faiss_read}. Re-initializing index.")
                        idx = faiss.IndexFlatL2(current_embedding_dimension)
                        meta = []
                else:
                    print(f"WARNING: '{INDEX_BLOB_NAME}' is empty in Blob. Using new index.")
                    idx = faiss.IndexFlatL2(current_embedding_dimension) # ë©”íƒ€ë°ì´í„°ë„ ë¹„ì›Œì•¼ í•¨
                    meta = []
            else:
                print(f"WARNING: '{INDEX_BLOB_NAME}' not found in Blob Storage. New index will be used/created.")
                idx = faiss.IndexFlatL2(current_embedding_dimension)
                meta = [] # ìƒˆ ì¸ë±ìŠ¤ì´ë¯€ë¡œ ë©”íƒ€ë°ì´í„°ë„ ë¹„ì›€

            # ë©”íƒ€ë°ì´í„°ëŠ” ì¸ë±ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆê±°ë‚˜, ìƒˆë¡œ ìƒì„±ë˜ì—ˆì„ ë•Œë§Œ ë¡œë“œ/ì´ˆê¸°í™”
            if idx is not None: # idxê°€ Noneì¼ ê°€ëŠ¥ì„±ì€ ìœ„ì—ì„œ ì²˜ë¦¬í–ˆì§€ë§Œ, ë°©ì–´ì ìœ¼ë¡œ ì²´í¬
                metadata_blob_client = _container_client.get_blob_client(METADATA_BLOB_NAME)
                # ì¸ë±ìŠ¤ì— ì•„ì´í…œì´ ìˆê±°ë‚˜, ì¸ë±ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•´ì„œ ë¡œë“œ ì‹œë„í–ˆì„ ë•Œë§Œ ë©”íƒ€ë°ì´í„° ë¡œë“œ
                # (ì™„ì „íˆ ìƒˆë¡œ ìƒì„±ëœ ë¹ˆ ì¸ë±ìŠ¤ë©´ ë©”íƒ€ë°ì´í„°ë„ ë¹„ì–´ìˆì–´ì•¼ í•¨)
                if metadata_blob_client.exists() and (idx.ntotal > 0 or os.path.exists(local_index_path)): 
                    print(f"Downloading '{METADATA_BLOB_NAME}'...")
                    with open(local_metadata_path, "wb") as download_file: # wbë¡œ ë‹¤ìš´ë¡œë“œ í›„ rë¡œ ì½ê¸°
                        download_stream_meta = metadata_blob_client.download_blob(timeout=60)
                        download_file.write(download_stream_meta.readall())
                    if os.path.getsize(local_metadata_path) > 0 :
                        with open(local_metadata_path, "r", encoding="utf-8") as f_meta: meta = json.load(f_meta)
                    else: # ë©”íƒ€ë°ì´í„° íŒŒì¼ì€ ì¡´ì¬í•˜ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°
                        meta = []
                        print(f"WARNING: '{METADATA_BLOB_NAME}' is empty in Blob.")
                elif idx.ntotal == 0 and not index_blob_client.exists(): # ì¸ë±ìŠ¤ íŒŒì¼ë„ ì—†ê³ , ntotalë„ 0ì´ë©´ (ì™„ì „ ì²˜ìŒ)
                     print(f"WARNING: Index is new and empty, starting with empty metadata.")
                     meta = []
                else: # ì¸ë±ìŠ¤ íŒŒì¼ì€ ì—†ì§€ë§Œ (ìƒˆë¡œ ìƒì„±), ë©”íƒ€ë°ì´í„° íŒŒì¼ë„ ì—†ëŠ” ê²½ìš°
                    print(f"WARNING: '{METADATA_BLOB_NAME}' not found in Blob Storage. Starting with empty metadata.")
                    meta = []
            
            # ìµœì¢… ë™ê¸°í™”: ì¸ë±ìŠ¤ì— ì•„ì´í…œì´ ì—†ìœ¼ë©´ ë©”íƒ€ë°ì´í„°ë„ ë¹„ì–´ìˆì–´ì•¼ í•¨
            if idx is not None and idx.ntotal == 0 and len(meta) > 0:
                print(f"WARNING: FAISS index is empty (ntotal=0) but metadata is not. Clearing metadata for consistency.")
                meta = []
            elif idx is not None and idx.ntotal > 0 and not meta:
                print(f"CRITICAL WARNING: FAISS index has data (ntotal={idx.ntotal}) but metadata is empty. This may lead to errors. Consider re-indexing.")
                # st.error("ë²¡í„° DB ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ë¶ˆì¼ì¹˜ ë°œìƒ! ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ê±°ë‚˜ íŒŒì¼ ì¬í•™ìŠµ í•„ìš”.")
                # idx = faiss.IndexFlatL2(current_embedding_dimension); meta = [] # ì•ˆì „ì„ ìœ„í•´ ì´ˆê¸°í™”

    except AzureError as ae:
        st.error(f"Azure Blobì—ì„œ ë²¡í„°DB ë¡œë“œ ì¤‘ Azure ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {ae}")
        print(f"AZURE ERROR loading vector DB from Blob: {ae}\n{traceback.format_exc()}")
        idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []
    except Exception as e:
        st.error(f"Azure Blobì—ì„œ ë²¡í„°DB ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
        print(f"GENERAL ERROR loading vector DB from Blob: {e}\n{traceback.format_exc()}")
        idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []
    return idx, meta


index, metadata = faiss.IndexFlatL2(1536), [] # ê¸°ë³¸ê°’ ì„¤ì •
if container_client:
    index, metadata = load_vector_db_from_blob_cached(container_client)
    print(f"DEBUG: FAISS index loaded after cache. ntotal: {index.ntotal if index else 'Index is None'}, dimension: {index.d if index else 'N/A'}")
    print(f"DEBUG: Metadata loaded after cache. Length: {len(metadata) if metadata is not None else 'Metadata is None'}")
else:
    st.error("Azure Blob Storage ì—°ê²° ì‹¤íŒ¨ë¡œ ë²¡í„° DBë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í•™ìŠµ ë° ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("CRITICAL: Cannot load vector DB due to Blob client initialization failure (main section).")

# --- ê·œì¹™ íŒŒì¼ ë¡œë“œ ---
@st.cache_data
def load_prompt_rules_cached():
    default_rules = """1.ìš°ì„  ê¸°ì¤€
    1.1. ëª¨ë“  ë‹µë³€ì€ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µëœ ì°¸ê³  ë¬¸ì„œ(ì²¨ë¶€ íŒŒì¼, í•™ìŠµëœ SOP/ì´ë¯¸ì§€ ì„¤ëª… ë“±)ì˜ ë‚´ìš©ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ë©°, ê·¸ ë‹¤ìŒì€ MFDS ê·œì •, ê·¸ë¦¬ê³  ì‚¬ë‚´ SOP ìˆœì„œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ìŠµë‹ˆë‹¤.
    1.2. ê·œì •/ë²•ë ¹ ìœ„ë°˜ ë˜ëŠ” íšŒìƒ‰ì§€ëŒ€ì˜ ê²½ìš°, ê´€ë ¨ ë¬¸ì„œëª…, ì¡°í•­ë²ˆí˜¸, ì¡°í•­ë‚´ìš©ê³¼ í•¨ê»˜ ëª…í™•íˆ ê²½ê³ í•´ì•¼ í•©ë‹ˆë‹¤.
    1.3. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ê·¼ê±°ë¥¼ ì œê³µëœ ì°¸ê³  ë¬¸ì„œë‚˜ ê·œì •ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ì„ ê²½ìš°, "ëª…í™•í•œ ê·œì •ì´ë‚˜ ì°¸ê³  ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‚´ë¶€ QA ê²€í†  í•„ìš”"ì„ì„ ê³ ì§€í•©ë‹ˆë‹¤.
    1.4. ë‹µë³€ì„ ìƒì„±í•  ë•Œ, ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ì°¸ê³ í–ˆë‹¤ë©´ í•´ë‹¹ ë¬¸ì„œì˜ ë‚´ìš©ì—ì„œ íŒŒì•…ë˜ëŠ” ì£¼ìš” ì‹ë³„ ì •ë³´(ì˜ˆ: ë¬¸ì„œ ì œëª©, ë¬¸ì„œ ë²ˆí˜¸, ì„¹ì…˜ ì œëª©, ì´ë¯¸ì§€ íŒŒì¼ëª… ë“±)ì™€ í•¨ê»˜ [ì¶œì²˜: íŒŒì¼ëª….pdf ë˜ëŠ” ì´ë¯¸ì§€ ì„¤ëª…: ì´ë¯¸ì§€ëª….png] í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ íŒŒì¼ëª…ì„ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤. ë§Œì•½ ë¬¸ì„œ ë‚´ìš©ì—ì„œ ëª…í™•í•œ ì œëª©ì´ë‚˜ ë²ˆí˜¸ë¥¼ ì°¾ê¸° ì–´ë µë‹¤ë©´ [ì¶œì²˜: íŒŒì¼ëª….ext] ë˜ëŠ” [Image Description for: ì´ë¯¸ì§€ëª….ext]ë§Œ ì–¸ê¸‰í•©ë‹ˆë‹¤.

2.ì‘ë‹µ ë°©ì‹
    2.1. ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ë©°, ì „ë¬¸ì ì´ê³  ì¹œì ˆí•œ ì–´ì¡°ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
    2.2. ëª¨ë“  ë‹µë³€ì€ ë…¼ë¦¬ì  êµ¬ì¡°, ë†’ì€ ì •í™•ì„±, ì‹¤ìš©ì„±ì„ ê°–ì¶”ì–´ì•¼ í•˜ë©°, í•„ìš”í•œ ê²½ìš° ì˜ˆì‹œ ë° ì„¤ëª…ì„ í¬í•¨í•˜ì—¬ ì „ë¬¸ê°€ ìˆ˜ì¤€ì„ ìœ ì§€í•©ë‹ˆë‹¤. ë‹µë³€ì—ëŠ” ê°€ëŠ¥í•œ í•œ ì°¸ê³ í•œ ê·¼ê±°(ë¬¸ì„œ ë‚´ìš©ì—ì„œ íŒŒì•…ëœ SOP ì œëª©/ë²ˆí˜¸, ê·œì •ëª…, ì¡°í•­, ì´ë¯¸ì§€ ë‚´ìš© ë“±)ì™€ ì¶œì²˜(ê·œì¹™ 1.4 ì°¸ê³ )ë¥¼ í•¨ê»˜ ì œì‹œí•©ë‹ˆë‹¤.
    2.3. ë²ˆì—­ ì‹œ, ì¼ë°˜ì ì¸ ë²ˆì—­ì²´ ëŒ€ì‹  **í•œêµ­ ì œì•½ ì‚°ì—… ë° GMP ê·œì •/ê°€ì´ë“œë¼ì¸(MFDS, PIC/S, ICH ë“±)ì—ì„œ í†µìš©ë˜ëŠ” í‘œì¤€ ì „ë¬¸ ìš©ì–´**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­í•´ì•¼ í•©ë‹ˆë‹¤. (ì•„ë˜ 'ì£¼ìš” ë²ˆì—­ ìš©ì–´ ê°€ì´ë“œ' ì°¸ê³ )

3.ê¸°ëŠ¥ ì œí•œ ë° íŒŒì¼ ì²˜ë¦¬
    3.1. ë‹¤ë£¨ëŠ” ì£¼ì œ: ì‚¬ë‚´ SOP (Standard Operating Procedure) ë‚´ìš© ì§ˆì˜ì‘ë‹µ, GMP ê°€ì´ë“œë¼ì¸(FDA, PIC/S, EU-GMP, cGMP, MFDS ë“±), DI ê·œì •, ì™¸êµ­ ê·œì • ë²ˆì—­ ë“± ì—…ë¬´ ê´€ë ¨ ë‚´ìš© ë° ì‚¬ìš©ìê°€ ì²¨ë¶€í•œ íŒŒì¼(í…ìŠ¤íŠ¸ ë¬¸ì„œ ë˜ëŠ” ì´ë¯¸ì§€)ì˜ ë‚´ìš© ë¶„ì„ (ìš”ì•½, ì„¤ëª…, ë¹„êµ ë“±).
    3.2. íŒŒì¼ ì²¨ë¶€ ì‹œ(í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€) ë° ë‚´ë¶€ SOP ì°¸ê³  ì‹œ ì²˜ë¦¬:
        - ì‚¬ìš©ìê°€ íŒŒì¼ì„ ì²¨ë¶€í•˜ì—¬ ì§ˆë¬¸í•˜ê±°ë‚˜, ì§ˆë¬¸ì´ ë‚´ë¶€ì ìœ¼ë¡œ í•™ìŠµëœ SOP ë¬¸ì„œ(ë˜ëŠ” ì´ë¯¸ì§€ ì„¤ëª…)ì™€ ê´€ë ¨ëœ ê²½ìš°, í•´ë‹¹ íŒŒì¼ ë˜ëŠ” SOPì˜ ë‚´ìš©ì„ ìµœìš°ì„ ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
        - ì´ë¯¸ì§€ê°€ ì²¨ë¶€ëœ ê²½ìš°, ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ì´í•´í•˜ê³  ì„¤ëª…í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
        - ì‚¬ìš©ìê°€ 'ì „ì²´ ë²ˆì—­'ì„ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•˜ëŠ” ê²½ìš° (í…ìŠ¤íŠ¸ íŒŒì¼ì— í•œí•¨), ë‹¤ë¥¸ ëª¨ë“  ê·œì¹™(íŠ¹íˆ ê°„ê²°ì„± ê·œì¹™ ë° ì¶œì²˜ ëª…ì‹œ ê·œì¹™)ì— ìš°ì„ í•˜ì—¬ ì²¨ë¶€ëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì²˜ìŒë¶€í„° ëê¹Œì§€ ìˆœì„œëŒ€ë¡œ ë²ˆì—­í•´ì•¼ í•©ë‹ˆë‹¤. ë²ˆì—­ ê²°ê³¼ëŠ” ëª¨ë¸ì˜ ìµœëŒ€ ì¶œë ¥ í† í° ë‚´ì—ì„œ ìƒì„±ë˜ë©°, ë‚´ìš©ì´ ê¸¸ ê²½ìš° ë²ˆì—­ì´ ì¤‘ê°„ì— ì™„ë£Œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš°, ë²ˆì—­ëœ ë‚´ìš©ì˜ ì¶œì²˜ íŒŒì¼ëª… [ì¶œì²˜: íŒŒì¼ëª….pdf] ì •ë„ë§Œ ì–¸ê¸‰í•˜ê±°ë‚˜, ë¬¸ì„œ ì œëª©ì´ ëª…í™•í•˜ë‹¤ë©´ ì œëª©ê¹Œì§€ ì–¸ê¸‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        - ë²ˆì—­ ìš”ì²­ì´ ì•„ë‹ˆë”ë¼ë„, íŒŒì¼(í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ ì„¤ëª…) ë˜ëŠ” í•™ìŠµëœ SOP ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë§ì¶° ìš”ì•½, ì„¤ëª…, ë¹„êµ ë“±ì˜ ë‹µë³€ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë•Œ, ê·œì¹™ 1.4 ë° 2.2ì— ë”°ë¼ ì°¸ê³ í•œ ì¶œì²˜ë¥¼ ëª…ì‹œí•©ë‹ˆë‹¤.
        - ë§Œì•½ íŒŒì¼ ë˜ëŠ” í•™ìŠµëœ SOP ë‚´ìš©ì´ ë‹¤ë¥¸ ê·œì •(ì˜ˆ: MFDS ê·œì •)ê³¼ ìƒì¶©ë  ê°€ëŠ¥ì„±ì´ ìˆë‹¤ë©´, ê·¸ ì ì„ ëª…í™•íˆ ì–¸ê¸‰í•˜ê³  ì‚¬ìš©ìì—ê²Œ í™•ì¸ì„ ìš”ì²­í•´ì•¼ í•©ë‹ˆë‹¤.
    3.3. ì‚¬ìš©ìê°€ íŒŒì¼ì„ ì²¨ë¶€í•˜ê³  í•´ë‹¹ íŒŒì¼ì˜ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê±°ë‚˜, í•™ìŠµëœ SOP ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ëŠ” ê²½ìš°ëŠ” ì—…ë¬´ ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤. ì´ ê²½ìš°ë¥¼ ì œì™¸í•˜ê³ , ê°œì¸ì ì¸ ì§ˆë¬¸, ë‰´ìŠ¤, ì—¬ê°€ ë“± ì—…ë¬´ì™€ ì§ì ‘ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì€ â€œì—…ë¬´ ê´€ë ¨ ì§ˆë¬¸ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.â€ë¡œ ê°„ê²°íˆ ì‘ë‹µí•©ë‹ˆë‹¤.

4.ì±—ë´‡ ì†Œê°œ ì•ˆë‚´
    4.1. ì‚¬ìš©ìê°€ ì¸ì‚¬í•˜ê±°ë‚˜ ê¸°ëŠ¥ì„ ë¬¼ì„ ê²½ìš°, ë³¸ ì±—ë´‡ì˜ ì—­í• ("í•œêµ­ ì œì•½ ì‚°ì—…ì˜ DI/GMP ê·œì • ë° ì‚¬ë‚´ SOP ì „ë¬¸ê°€ ì±—ë´‡")ê³¼ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì—…ë¬´ ë²”ìœ„(í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ íŒŒì¼ ë‚´ìš© ë¶„ì„ í¬í•¨)ë¥¼ ê°„ë‹¨íˆ ì†Œê°œí•©ë‹ˆë‹¤.

5.í‘œí˜„ ë° í˜•ì‹ ê·œì¹™
    5.1. Markdown ìŠ¤íƒ€ì¼ ê°•ì¡°ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    5.2. ë²ˆí˜¸ í•­ëª©ì€ ë™ì¼í•œ ì„œì‹(ê¸€ê¼´ í¬ê¸°ì™€ êµµê¸°)ìœ¼ë¡œ í†µì¼í•©ë‹ˆë‹¤.
    5.3. ë‹µë³€ì€ í‘œ, ìš”ì•½, í•µì‹¬ ì •ë¦¬ ì¤‘ì‹¬ìœ¼ë¡œ ìì„¸í•˜ê²Œ êµ¬ì„±í•©ë‹ˆë‹¤. (ë‹¨, 'ì „ì²´ ë²ˆì—­' ìš”ì²­ ì‹œì—ëŠ” ê·œì¹™ 3.2ê°€ ìš°ì„ í•˜ë©°, ì´ë•ŒëŠ” ê·œì¹™ 1.4ì˜ ì¶œì²˜ ëª…ì‹œ ë°©ì‹ ì¤‘ íŒŒì¼ëª… ìœ„ì£¼ë¡œ ê°„ëµíˆ í•˜ê±°ë‚˜ ë‚´ìš© íë¦„ì— ë”°ë¼ ì¡°ì ˆ)

6. ì£¼ìš” ë²ˆì—­ ìš©ì–´ ê°€ì´ë“œ (ë²ˆì—­ ì‹œ ìµœìš°ì„  ì°¸ê³ )
    - Compliant / Compliance: ê·œì • ì¤€ìˆ˜
    - GxP: Good x Practice (GMP, GLP, GCP ë“± ìš°ìˆ˜ ê´€ë¦¬ ê¸°ì¤€)
    - Computerized System: ì»´í“¨í„°í™” ì‹œìŠ¤í…œ
    # ... (ì´í•˜ ìš©ì–´ ëª©ë¡)
    - Data Integrity (DI): ë°ì´í„° ì™„ì „ì„±
    # (í•„ìš”ì— ë”°ë¼ ì´ ëª©ë¡ì— ì¤‘ìš”í•œ ì œì•½ ìš©ì–´ë¥¼ ê³„ì† ì¶”ê°€í•´ì£¼ì„¸ìš”)
"""
    if os.path.exists(RULES_PATH_REPO):
        try:
            with open(RULES_PATH_REPO, "r", encoding="utf-8") as f: rules_content = f.read()
            print(f"Prompt rules loaded successfully from '{RULES_PATH_REPO}'.")
            return rules_content
        except Exception as e:
            st.warning(f"'{RULES_PATH_REPO}' íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}. ìœ„ ëª…ì‹œëœ ê¸°ë³¸ ê·œì¹™ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            print(f"WARNING: Error loading prompt rules from '{RULES_PATH_REPO}': {e}. Using default rules defined in code.")
            return default_rules
    else:
        print(f"WARNING: Prompt rules file not found at '{RULES_PATH_REPO}'. Using default rules defined in code.")
        return default_rules
PROMPT_RULES_CONTENT = load_prompt_rules_cached()

# --- í…ìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ---
def extract_text_from_file(uploaded_file_obj): # ì´ë¯¸ì§€ ì²˜ë¦¬ëŠ” ì´ í•¨ìˆ˜ ë°–ì—ì„œ ë¶„ê¸°
    ext = os.path.splitext(uploaded_file_obj.name)[1].lower()
    text_content = ""
    
    # ì´ë¯¸ì§€ í™•ì¥ìëŠ” ì—¬ê¸°ì„œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ (ë˜ëŠ” ëª…ì‹œì ìœ¼ë¡œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜)
    if ext in [".png", ".jpg", ".jpeg"]:
        # st.info(f"'{uploaded_file_obj.name}'ì€ ì´ë¯¸ì§€ íŒŒì¼ì…ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œ ì „ìš©ì…ë‹ˆë‹¤.")
        print(f"DEBUG extract_text_from_file: Skipped image file '{uploaded_file_obj.name}'.")
        return "" # ë˜ëŠ” None

    try:
        uploaded_file_obj.seek(0)
        file_bytes = uploaded_file_obj.read()
        
        if ext == ".pdf":
            with fitz.open(stream=file_bytes, filetype="pdf") as doc: text_content = "\n".join(page.get_text() for page in doc)
        elif ext == ".docx":
            with io.BytesIO(file_bytes) as doc_io: doc = docx.Document(doc_io); text_content = "\n".join(para.text for para in doc.paragraphs)
        elif ext in (".xlsx", ".xlsm"):
            with io.BytesIO(file_bytes) as excel_io: df = pd.read_excel(excel_io, sheet_name=None)
            text_content = ""
            for sheet_name, sheet_df in df.items():
                 text_content += f"--- ì‹œíŠ¸: {sheet_name} ---\n{sheet_df.to_string(index=False)}\n\n"
        elif ext == ".csv":
            with io.BytesIO(file_bytes) as csv_io:
                try: df = pd.read_csv(csv_io)
                except UnicodeDecodeError: df = pd.read_csv(csv_io, encoding='cp949')
                text_content = df.to_string(index=False)
        elif ext == ".pptx":
            with io.BytesIO(file_bytes) as ppt_io: prs = Presentation(ppt_io); text_content = "\n".join(shape.text for slide in prs.slides for shape in slide.shapes if hasattr(shape, "text"))
        elif ext == ".txt":
            try:
                text_content = file_bytes.decode('utf-8')
            except UnicodeDecodeError:
                try:
                    text_content = file_bytes.decode('cp949') # ë‹¤ë¥¸ ì¸ì½”ë”© ì‹œë„
                except Exception as e_txt_decode:
                    st.warning(f"'{uploaded_file_obj.name}' TXT íŒŒì¼ ë””ì½”ë”© ì‹¤íŒ¨: {e_txt_decode}. ë‚´ìš©ì„ ë¹„ì›Œë‘¡ë‹ˆë‹¤.")
                    text_content = "" 
        else: 
            st.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í…ìŠ¤íŠ¸ íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {ext} (íŒŒì¼ëª…: {uploaded_file_obj.name})")
            return "" # ì§€ì›í•˜ì§€ ì•ŠëŠ” í…ìŠ¤íŠ¸ íŒŒì¼ë„ ë¹ˆ ë‚´ìš© ë°˜í™˜
    except Exception as e:
        st.error(f"'{uploaded_file_obj.name}' íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"Error extracting text from '{uploaded_file_obj.name}': {e}\n{traceback.format_exc()}")
        return ""
    return text_content.strip()


def chunk_text_into_pieces(text_to_chunk, chunk_size=500): # ì²­í¬ í¬ê¸°ëŠ” í•„ìš”ì‹œ ì¡°ì ˆ
    if not text_to_chunk or not text_to_chunk.strip(): return [];
    chunks_list, current_buffer = [], ""
    # ë” ê¸´ ì¤„ë°”ê¿ˆì´ë‚˜ ë¬¸ë‹¨ êµ¬ë¶„ì„ ê¸°ì¤€ìœ¼ë¡œ ì²­í‚¹í•˜ë„ë¡ ê°œì„  (ì„ íƒì )
    # ì˜ˆ: sentences = text_to_chunk.split('. ') # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³  í•©ì¹˜ê¸°
    for line in text_to_chunk.split("\n"): # í˜„ì¬ëŠ” ì¤„ë°”ê¿ˆ ê¸°ì¤€
        stripped_line = line.strip()
        if not stripped_line and not current_buffer.strip(): continue # ì—°ì†ëœ ë¹ˆ ì¤„ ë¬´ì‹œ
        
        # í˜„ì¬ ë²„í¼ì— ì¶”ê°€í–ˆì„ ë•Œ ì²­í¬ í¬ê¸°ë¥¼ ë„˜ëŠ”ì§€ í™•ì¸
        if len(current_buffer) + len(stripped_line) + 1 < chunk_size: # +1 for newline
            current_buffer += stripped_line + "\n"
        else: # ì²­í¬ í¬ê¸°ë¥¼ ë„˜ìœ¼ë©´
            if current_buffer.strip(): # í˜„ì¬ ë²„í¼ì— ë‚´ìš©ì´ ìˆìœ¼ë©´ ì²­í¬ë¡œ ì¶”ê°€
                chunks_list.append(current_buffer.strip())
            current_buffer = stripped_line + "\n" # ìƒˆ ë²„í¼ ì‹œì‘
            
    if current_buffer.strip(): # ë§ˆì§€ë§‰ ë²„í¼ ë‚´ìš© ì¶”ê°€
        chunks_list.append(current_buffer.strip())
        
    return [c for c in chunks_list if c] # ìµœì¢…ì ìœ¼ë¡œ ë¹ˆ ì²­í¬ ì œê±°

# --- ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± í•¨ìˆ˜ ---
def get_image_description(image_bytes, image_filename, client_instance):
    if not client_instance:
        st.error("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ì´ë¯¸ì§€ ì„¤ëª…ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ERROR get_image_description: OpenAI client not ready.")
        return None
    
    print(f"DEBUG get_image_description: Requesting description for image '{image_filename}'")
    try:
        base64_image = base64.b64encode(image_bytes).decode('utf-8')
        
        # ì´ë¯¸ì§€ í™•ì¥ìì— ë”°ë¼ "image/jpeg" ë˜ëŠ” "image/png" ë“±ì„ ì‚¬ìš©
        image_ext_desc = os.path.splitext(image_filename)[1].lower()
        mime_type = "image/jpeg" # ê¸°ë³¸ê°’
        if image_ext_desc == ".png":
            mime_type = "image/png"
        elif image_ext_desc == ".jpg" or image_ext_desc == ".jpeg":
            mime_type = "image/jpeg"
        # ë‹¤ë¥¸ ì´ë¯¸ì§€ íƒ€ì…ì´ ìˆë‹¤ë©´ ì¶”ê°€ (ì˜ˆ: gif, webp ë“±)

        vision_model_deployment = st.secrets["AZURE_OPENAI_DEPLOYMENT"] 
        print(f"DEBUG get_image_description: Using vision model deployment: {vision_model_deployment}")

        response = client_instance.chat.completions.create(
            model=vision_model_deployment,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": f"ì´ ì´ë¯¸ì§€ë¥¼ ì—…ë¬´ì  ê´€ì ì—ì„œ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì´ ì„¤ëª…ì€ ë‚˜ì¤‘ì— í…ìŠ¤íŠ¸ ê²€ìƒ‰ì„ í†µí•´ ì´ë¯¸ì§€ë¥¼ ì°¾ê±°ë‚˜, ì´ë¯¸ì§€ ì† ìƒí™©ì„ íŒŒì•…í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ë¯¸ì§€ íŒŒì¼ëª…ì€ '{image_filename}'ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ì˜ ì£¼ìš” ê°ì²´, ìƒíƒœ, ê°€ëŠ¥í•œ ë§¥ë½, ê·¸ë¦¬ê³  ë§Œì•½ GMP/SOPì™€ ê´€ë ¨ëœ ìš”ì†Œê°€ ìˆë‹¤ë©´ ê·¸ê²ƒë„ ì–¸ê¸‰í•´ì£¼ì„¸ìš”."},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{mime_type};base64,{base64_image}" 
                            }
                        }
                    ]
                }
            ],
            max_tokens=IMAGE_DESCRIPTION_MAX_TOKENS, 
            temperature=0.2, # ì¢€ ë” ì‚¬ì‹¤ ê¸°ë°˜ì˜ ì„¤ëª…ì„ ìœ„í•´ ë‚®ì€ ê°’
            timeout=AZURE_OPENAI_TIMEOUT 
        )
        description = response.choices[0].message.content.strip()
        print(f"DEBUG get_image_description: Description for '{image_filename}' (len: {len(description)} chars) generated successfully.")
        return description
    except APIStatusError as ase:
        st.error(f"ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì¤‘ API ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ {ase.status_code}): {ase.message}.")
        print(f"API STATUS ERROR during image description for '{image_filename}' (Status {ase.status_code}): {ase.message}")
        if ase.response and ase.response.content:
            try:
                error_details = json.loads(ase.response.content.decode('utf-8'))
                print(f"DEBUG get_image_description: Azure API error details: {json.dumps(error_details, indent=2, ensure_ascii=False)}")
            except Exception as json_e:
                print(f"DEBUG get_image_description: Could not parse Azure API error content as JSON: {json_e}")
        return None
    except APITimeoutError:
        st.error(f"ì´ë¯¸ì§€ '{image_filename}' ì„¤ëª… ìƒì„± ì¤‘ ì‹œê°„ ì´ˆê³¼ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print(f"TIMEOUT ERROR during image description for '{image_filename}'.")
        return None
    except APIConnectionError as ace:
        st.error(f"ì´ë¯¸ì§€ '{image_filename}' ì„¤ëª… ìƒì„± ì¤‘ API ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {ace}.")
        print(f"API CONNECTION ERROR during image description for '{image_filename}': {ace}")
        return None
    except RateLimitError as rle:
        st.error(f"ì´ë¯¸ì§€ '{image_filename}' ì„¤ëª… ìƒì„± ì¤‘ API ìš”ì²­ëŸ‰ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤: {rle}.")
        print(f"RATE LIMIT ERROR during image description for '{image_filename}': {rle}")
        return None
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ '{image_filename}' ì„¤ëª… ìƒì„± ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}")
        print(f"UNEXPECTED ERROR during image description for '{image_filename}': {e}\n{traceback.format_exc()}")
        return None


# --- í…ìŠ¤íŠ¸ ì„ë² ë”© í•¨ìˆ˜ (ë””ë²„ê¹… ë¡œê·¸ ë° ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”) ---
def get_text_embedding(text_to_embed):
    # (ì´ì „ê³¼ ë™ì¼ - ë³€ê²½ ì—†ìŒ)
    if not openai_client or not EMBEDDING_MODEL:
        print("ERROR: OpenAI client or embedding model not ready for get_text_embedding (called).")
        return None
    if not text_to_embed or not text_to_embed.strip():
        print("WARNING: Attempted to embed empty or whitespace-only text in get_text_embedding.")
        return None

    print(f"DEBUG get_text_embedding: Requesting embedding for text (first 50 chars): '{text_to_embed[:50]}...'")
    print(f"DEBUG get_text_embedding: Using embedding model deployment name: {EMBEDDING_MODEL}")
    try:
        response = openai_client.embeddings.create(
            input=[text_to_embed],
            model=EMBEDDING_MODEL,
            timeout=AZURE_OPENAI_TIMEOUT / 2 
        )
        print("Embedding received.")
        return response.data[0].embedding
    except APIStatusError as ase:
        st.error(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘ API ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ {ase.status_code}): {ase.message}. ìš”ì²­ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        print(f"API STATUS ERROR during embedding (get_text_embedding - Status {ase.status_code}): {ase.message}")
        print(f"DEBUG get_text_embedding: Failing text (first 100 chars): {text_to_embed[:100]}")
        if ase.response and ase.response.content:
            try:
                error_details = json.loads(ase.response.content.decode('utf-8'))
                print(f"DEBUG get_text_embedding: Azure API error details: {json.dumps(error_details, indent=2, ensure_ascii=False)}")
            except Exception as json_e:
                print(f"DEBUG get_text_embedding: Could not parse Azure API error content as JSON: {json_e}")
                print(f"DEBUG get_text_embedding: Raw Azure API error content: {ase.response.content}")
        return None
    except APITimeoutError:
        st.error("í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘ ì‹œê°„ ì´ˆê³¼ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        print(f"TIMEOUT ERROR during embedding (get_text_embedding): Request for '{text_to_embed[:50]}...' timed out.")
        return None
    except APIConnectionError as ace:
        st.error(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘ API ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {ace}. ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        print(f"API CONNECTION ERROR during embedding (get_text_embedding): {ace}")
        return None
    except RateLimitError as rle:
        st.error(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘ API ìš”ì²­ëŸ‰ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤: {rle}. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        print(f"RATE LIMIT ERROR during embedding (get_text_embedding): {rle}")
        return None
    except Exception as e:
        st.error(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        print(f"UNEXPECTED ERROR during embedding (get_text_embedding): {e}\n{traceback.format_exc()}")
        return None

# --- ìœ ì‚¬ë„ ê²€ìƒ‰ í•¨ìˆ˜ (ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜) ---
def search_similar_chunks(query_text, k_results=3): # k_resultsëŠ” í•„ìš”ì‹œ ì¡°ì ˆ
    # (ì´ì „ê³¼ ë™ì¼ - ë³€ê²½ ì—†ìŒ)
    print(f"DEBUG search_similar_chunks: Called with query '{query_text[:30]}...', k_results={k_results}")
    if index is None:
        print("DEBUG search_similar_chunks: FAISS index is None.")
        return []
    if index.ntotal == 0:
        print("DEBUG search_similar_chunks: FAISS index is empty (ntotal=0).")
        return []
    if not metadata: # metadataê°€ Noneì´ê±°ë‚˜ ë¹„ì–´ìˆì„ ë•Œ
        print("DEBUG search_similar_chunks: Metadata is empty or None.")
        return []

    print(f"Searching for similar chunks for query: '{query_text[:30]}...'")
    query_vector = get_text_embedding(query_text)
    if query_vector is None:
        print("DEBUG search_similar_chunks: Failed to get query vector.")
        return []
    try:
        actual_k = min(k_results, index.ntotal)
        if actual_k == 0 :
            print("DEBUG search_similar_chunks: No items in index to search (actual_k=0).")
            return []

        distances, indices_found = index.search(np.array([query_vector]).astype("float32"), actual_k)
        print(f"DEBUG search_similar_chunks: FAISS search distances: {distances}")
        print(f"DEBUG search_similar_chunks: FAISS search indices_found: {indices_found}")

        results_with_source = []
        if len(indices_found[0]) > 0:
            for i_val in indices_found[0]:
                if 0 <= i_val < len(metadata): # metadata ì¸ë±ìŠ¤ ë²”ìœ„ í™•ì¸
                    meta_item = metadata[i_val]
                    # ë©”íƒ€ë°ì´í„°ê°€ ì˜ˆìƒëœ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ì§€ í™•ì¸ (ì„ íƒì  ê°•í™”)
                    if isinstance(meta_item, dict):
                        results_with_source.append({
                            "source": meta_item.get("file_name", "ì¶œì²˜ ë¶ˆëª…"), # ì›ë³¸ íŒŒì¼ëª…
                            "content": meta_item.get("content", ""), # ì²­í¬ ë‚´ìš© (í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ ì„¤ëª…)
                            "is_image_description": meta_item.get("is_image_description", False), # ì´ë¯¸ì§€ ì„¤ëª… ì—¬ë¶€ í”Œë˜ê·¸
                            "original_file_extension": meta_item.get("original_file_extension", "") # ì›ë³¸ í™•ì¥ì
                        })
                    else:
                        print(f"WARNING search_similar_chunks: Metadata item at index {i_val} is not a dict: {meta_item}")
        print(f"Similarity search found {len(results_with_source)} relevant chunks with source.")
        return results_with_source
    except Exception as e:
        st.error(f"ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"ERROR: Similarity search failed: {e}\n{traceback.format_exc()}")
        return []


# --- ë¬¸ì„œ ì¶”ê°€, ì›ë³¸ ì €ì¥, ì‚¬ìš©ëŸ‰ ë¡œê¹… í•¨ìˆ˜ ---
def add_document_to_vector_db_and_blob(uploaded_file_obj, processed_content, text_chunks, _container_client, is_image_description=False):
    global index, metadata
    if not text_chunks: 
        st.warning(f"'{uploaded_file_obj.name}' íŒŒì¼ì—ì„œ ì²˜ë¦¬í•  ë‚´ìš©(í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ ì„¤ëª…)ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    if not _container_client: 
        st.error("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ í•™ìŠµ ê²°ê³¼ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    vectors_to_add, new_metadata_entries_for_current_file = [], []
    embedding_failed_for_some_chunks = False
    
    file_type_for_log = "ì´ë¯¸ì§€ ì„¤ëª…" if is_image_description else "í…ìŠ¤íŠ¸"
    print(f"Adding '{file_type_for_log}' from '{uploaded_file_obj.name}' to vector DB.")

    for chunk_idx, chunk in enumerate(text_chunks):
        print(f"Processing chunk {chunk_idx+1}/{len(text_chunks)} for embedding from '{uploaded_file_obj.name}' ({file_type_for_log})...")
        embedding = get_text_embedding(chunk) # ì²­í¬ëŠ” í…ìŠ¤íŠ¸(ì›ë³¸ ë˜ëŠ” ì´ë¯¸ì§€ ì„¤ëª…)
        if embedding is not None:
            vectors_to_add.append(embedding)
            new_metadata_entries_for_current_file.append({
                "file_name": uploaded_file_obj.name, # ì›ë³¸ íŒŒì¼ëª… (ì´ë¯¸ì§€ ë˜ëŠ” í…ìŠ¤íŠ¸ ë¬¸ì„œ)
                "content": chunk, # ì‹¤ì œ ì„ë² ë”©ëœ ë‚´ìš© (í…ìŠ¤íŠ¸ ì²­í¬ ë˜ëŠ” ì´ë¯¸ì§€ ì„¤ëª… ì²­í¬)
                "is_image_description": is_image_description,
                "original_file_extension": os.path.splitext(uploaded_file_obj.name)[1].lower()
            })
        else:
            embedding_failed_for_some_chunks = True
            print(f"Warning: Failed to get embedding for a chunk in '{uploaded_file_obj.name}'. Skipping chunk.")

    if embedding_failed_for_some_chunks and not vectors_to_add:
        st.error(f"'{uploaded_file_obj.name}' íŒŒì¼ì˜ ëª¨ë“  ë‚´ìš©({file_type_for_log})ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    elif embedding_failed_for_some_chunks:
         st.warning(f"'{uploaded_file_obj.name}' íŒŒì¼ì˜ ì¼ë¶€ ë‚´ìš©({file_type_for_log})ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì„±ê³µí•œ ë¶€ë¶„ë§Œ í•™ìŠµë©ë‹ˆë‹¤.")

    if not vectors_to_add: # ì„ë² ë”©ëœ ë²¡í„°ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´
        st.warning(f"'{uploaded_file_obj.name}' íŒŒì¼ì—ì„œ ìœ íš¨í•œ ì„ë² ë”©ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
        return False

    try:
        current_embedding_dimension = np.array(vectors_to_add[0]).shape[0]
        if index is None or index.d != current_embedding_dimension:
            print(f"WARNING: FAISS index dimension ({index.d if index else 'None'}) mismatch or index is None. Re-initializing with dimension {current_embedding_dimension}.")
            index = faiss.IndexFlatL2(current_embedding_dimension)
            metadata = [] # ì¸ë±ìŠ¤ ì¬ìƒì„± ì‹œ ë©”íƒ€ë°ì´í„°ë„ ì´ˆê¸°í™”

        if vectors_to_add: index.add(np.array(vectors_to_add).astype("float32"))
        metadata.extend(new_metadata_entries_for_current_file)
        print(f"Added {len(vectors_to_add)} new chunks to in-memory DB from '{uploaded_file_obj.name}'. Index total: {index.ntotal}, Index dimension: {index.d}")

        with tempfile.TemporaryDirectory() as tmpdir:
            temp_index_path = os.path.join(tmpdir, "temp.index")
            if index.ntotal > 0 : # ì¸ë±ìŠ¤ì— ì•„ì´í…œì´ ìˆì„ ë•Œë§Œ ì €ì¥
                 faiss.write_index(index, temp_index_path)
                 if not save_binary_data_to_blob(temp_index_path, INDEX_BLOB_NAME, _container_client, "ë²¡í„° ì¸ë±ìŠ¤"):
                    st.error("ë²¡í„° ì¸ë±ìŠ¤ Blob ì €ì¥ ì‹¤íŒ¨"); return False # ì €ì¥ ì‹¤íŒ¨ ì‹œ False ë°˜í™˜
            else: # ë¹ˆ ì¸ë±ìŠ¤ë©´ ì €ì¥ ê±´ë„ˆë›°ê¸° (ë˜ëŠ” ë¹ˆ íŒŒì¼ë¡œ ë®ì–´ì“°ë„ë¡ í•  ìˆ˜ë„ ìˆìŒ)
                print(f"Skipping saving empty index to Blob: {INDEX_BLOB_NAME}")
                # ë§Œì•½ Blobì— ê¸°ì¡´ ì¸ë±ìŠ¤ íŒŒì¼ì´ ìˆë‹¤ë©´ ì‚­ì œí•˜ê±°ë‚˜ ë¹ˆ íŒŒì¼ë¡œ ë®ì–´ì“°ëŠ” ë¡œì§ ì¶”ê°€ ê°€ëŠ¥

        if not save_data_to_blob(metadata, METADATA_BLOB_NAME, _container_client, "ë©”íƒ€ë°ì´í„°"): # ë©”íƒ€ë°ì´í„°ëŠ” í•­ìƒ ì €ì¥ (ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆìŒ)
            st.error("ë©”íƒ€ë°ì´í„° Blob ì €ì¥ ì‹¤íŒ¨"); return False

        user_info = st.session_state.get("user", {}); uploader_name = user_info.get("name", "N/A")
        new_log_entry = {"file": uploaded_file_obj.name, 
                         "type": "image" if is_image_description else "text_document",
                         "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                         "chunks_added": len(vectors_to_add), "uploader": uploader_name}

        current_upload_logs = load_data_from_blob(UPLOAD_LOG_BLOB_NAME, _container_client, "ì—…ë¡œë“œ ë¡œê·¸", default_value=[])
        if not isinstance(current_upload_logs, list): current_upload_logs = [] # ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
        current_upload_logs.append(new_log_entry)
        if not save_data_to_blob(current_upload_logs, UPLOAD_LOG_BLOB_NAME, _container_client, "ì—…ë¡œë“œ ë¡œê·¸"):
            st.warning("ì—…ë¡œë“œ ë¡œê·¸ë¥¼ Blobì— ì €ì¥í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") # ë¡œê·¸ ì €ì¥ì€ ì‹¤íŒ¨í•´ë„ í•™ìŠµ ìì²´ëŠ” ì„±ê³µìœ¼ë¡œ ê°„ì£¼
        return True
    except Exception as e:
        st.error(f"ë¬¸ì„œ í•™ìŠµ ë˜ëŠ” Azure Blob ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"ERROR: Failed to add document or upload to Blob: {e}\n{traceback.format_exc()}")
        return False

def save_original_file_to_blob(uploaded_file_obj, _container_client):
    # (ì´ì „ê³¼ ë™ì¼ - ë³€ê²½ ì—†ìŒ)
    if not _container_client: st.error("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ì›ë³¸ íŒŒì¼ì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return None
    try:
        uploaded_file_obj.seek(0) # ìŠ¤íŠ¸ë¦¼ ìœ„ì¹˜ ì´ˆê¸°í™”
        # íŒŒì¼ëª…ì— ë‚ ì§œì‹œê°„ ì¶”ê°€í•˜ì—¬ ì¤‘ë³µ ë°©ì§€ ë° ì¶”ì  ìš©ì´
        original_blob_name = f"uploaded_originals/{datetime.now().strftime('%Y%m%d%H%M%S')}_{uploaded_file_obj.name}"
        blob_client_for_original = _container_client.get_blob_client(blob=original_blob_name)
        # getvalue()ë¥¼ ì‚¬ìš©í•˜ì—¬ BytesIO ê°ì²´ì˜ ì „ì²´ ë‚´ìš©ì„ ì „ë‹¬
        blob_client_for_original.upload_blob(uploaded_file_obj.getvalue(), overwrite=False, timeout=120) 
        print(f"Original file '{uploaded_file_obj.name}' saved to Blob as '{original_blob_name}'.")
        return original_blob_name
    except AzureError as ae:
        st.error(f"'{uploaded_file_obj.name}' ì›ë³¸ íŒŒì¼ Blob ì—…ë¡œë“œ ì¤‘ Azure ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {ae}")
        print(f"AZURE ERROR saving original file to Blob: {ae}\n{traceback.format_exc()}")
        return None
    except Exception as e:
        st.error(f"'{uploaded_file_obj.name}' ì›ë³¸ íŒŒì¼ Blob ì—…ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
        print(f"GENERAL ERROR saving original file to Blob: {e}\n{traceback.format_exc()}")
        return None

def log_openai_api_usage_to_blob(user_id_str, model_name_str, usage_stats_obj, _container_client, request_type="chat_completion"):
    # (ì´ì „ê³¼ ë™ì¼, request_type íŒŒë¼ë¯¸í„° ì¶”ê°€í•˜ì—¬ êµ¬ë¶„ ê°€ëŠ¥)
    if not _container_client:
        print("ERROR: Blob Container client is None for API usage log. Skipping log.")
        return

    prompt_tokens = getattr(usage_stats_obj, 'prompt_tokens', 0)
    completion_tokens = getattr(usage_stats_obj, 'completion_tokens', 0)
    total_tokens = getattr(usage_stats_obj, 'total_tokens', 0)

    new_log_entry = {
        "user_id": user_id_str, "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "model_used": model_name_str, 
        "request_type": request_type, # ìš”ì²­ ì¢…ë¥˜ (ì˜ˆ: "chat_completion", "embedding", "image_description")
        "prompt_tokens": prompt_tokens,
        "completion_tokens": completion_tokens, "total_tokens": total_tokens
    }

    current_usage_logs = load_data_from_blob(USAGE_LOG_BLOB_NAME, _container_client, "API ì‚¬ìš©ëŸ‰ ë¡œê·¸", default_value=[])
    if not isinstance(current_usage_logs, list): current_usage_logs = []
    current_usage_logs.append(new_log_entry)

    if not save_data_to_blob(current_usage_logs, USAGE_LOG_BLOB_NAME, _container_client, "API ì‚¬ìš©ëŸ‰ ë¡œê·¸"):
        print(f"WARNING: Failed to save API usage log to Blob for user '{user_id_str}'.")

# --- ë©”ì¸ UI êµ¬ì„± ---
# (ì´ì „ê³¼ ë™ì¼)
tab_labels_list = ["ğŸ’¬ ì—…ë¬´ ì§ˆë¬¸"]
if current_user_info.get("role") == "admin":
    tab_labels_list.append("âš™ï¸ ê´€ë¦¬ì ì„¤ì •")

main_tabs_list = st.tabs(tab_labels_list)
chat_interface_tab = main_tabs_list[0]
admin_settings_tab = main_tabs_list[1] if len(main_tabs_list) > 1 else None


with chat_interface_tab:
    st.header("ì—…ë¬´ ì§ˆë¬¸")
    st.markdown("ğŸ’¡ ì˜ˆì‹œ: SOP ë°±ì—… ì£¼ê¸°, PIC/S Annex 11 ì°¨ì´, (íŒŒì¼ ì²¨ë¶€ í›„) ì´ ì‚¬ì§„ ì† ìƒí™©ì€ ì–´ë–¤ ê·œì •ì— í•´ë‹¹í•˜ë‚˜ìš”? ë“±")

    if "messages" not in st.session_state:
        st.session_state["messages"] = []
        print("Chat messages list re-initialized in chat_tab (should not happen if init is correct).")

    for msg_item in st.session_state["messages"]:
        role, content, time_str = msg_item.get("role"), msg_item.get("content", ""), msg_item.get("time", "")
        align_class = "user-align" if role == "user" else "assistant-align"
        bubble_class = "user-bubble" if role == "user" else "assistant-bubble"
        
        # ì´ë¯¸ì§€ URLì´ contentì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì´ë¯¸ì§€ë¡œ í‘œì‹œ (ì„ íƒì  ê¸°ëŠ¥)
        # if role == "user" and content.startswith("data:image"):
        # st.markdown(f"""<div class="chat-bubble-container {align_class}"><img src="{content}" style="max-width: 300px; border-radius: 10px;"/><div class="timestamp">{time_str}</div></div>""", unsafe_allow_html=True)
        # else:
        st.markdown(f"""<div class="chat-bubble-container {align_class}"><div class="bubble {bubble_class}">{content}</div><div class="timestamp">{time_str}</div></div>""", unsafe_allow_html=True)


    st.markdown("<div style='height:16px'></div>", unsafe_allow_html=True) # ê°„ê²© ì¶”ê°€
    if st.button("ğŸ“‚ íŒŒì¼ ì²¨ë¶€/ìˆ¨ê¸°ê¸°", key="toggle_chat_uploader_final_v5_button"): # í‚¤ ë³€ê²½
        st.session_state.show_uploader = not st.session_state.get("show_uploader", False)

    chat_file_uploader_key = "chat_file_uploader_final_v5_widget" # í‚¤ ë³€ê²½
    uploaded_chat_file_runtime = None # ìœ„ì ¯ ìƒíƒœ ìœ ì§€ë¥¼ ìœ„í•´ ë°–ì—ì„œ ì´ˆê¸°í™”
    if st.session_state.get("show_uploader", False):
        uploaded_chat_file_runtime = st.file_uploader("ì§ˆë¬¸ê³¼ í•¨ê»˜ ì°¸ê³ í•  íŒŒì¼ ì²¨ë¶€ (ì„ íƒ ì‚¬í•­)",
                                     type=["pdf","docx","xlsx","xlsm","csv","pptx", "txt", "png", "jpg", "jpeg"], # í—ˆìš© íƒ€ì… ì¶”ê°€
                                     key=chat_file_uploader_key)
        if uploaded_chat_file_runtime: 
            st.caption(f"ì²¨ë¶€ë¨: {uploaded_chat_file_runtime.name} ({uploaded_chat_file_runtime.type}, {uploaded_chat_file_runtime.size} bytes)")
            # ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš° ë¯¸ë¦¬ë³´ê¸° (ì„ íƒì )
            if uploaded_chat_file_runtime.type.startswith("image/"):
                st.image(uploaded_chat_file_runtime, width=200)


    with st.form("chat_input_form_final_v5", clear_on_submit=True): # í‚¤ ë³€ê²½
        query_input_col, send_button_col = st.columns([4,1])
        with query_input_col:
            user_query_input = st.text_input("ì§ˆë¬¸ ì…ë ¥:", placeholder="ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
                                             key="user_query_text_input_final_v5", label_visibility="collapsed") # í‚¤ ë³€ê²½
        with send_button_col:
            send_query_button = st.form_submit_button("ì „ì†¡")

    if send_query_button and user_query_input.strip():
        if not openai_client:
            st.error("OpenAI ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        elif not tokenizer: # Tiktoken ë¡œë” ì‹¤íŒ¨ ì‹œ
             st.error("Tiktoken ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì‹¤íŒ¨. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            timestamp_now_str = datetime.now().strftime("%Y-%m-%d %H:%M")
            
            # ì‚¬ìš©ì ì§ˆë¬¸ ë©”ì‹œì§€ ì¶”ê°€ (ì´ë¯¸ì§€ íŒŒì¼ëª…ë„ í•¨ê»˜ í‘œì‹œ ê°€ëŠ¥)
            user_message_content = user_query_input
            if uploaded_chat_file_runtime:
                user_message_content += f"\n(ì²¨ë¶€ íŒŒì¼: {uploaded_chat_file_runtime.name})"
            st.session_state["messages"].append({"role":"user", "content":user_message_content, "time":timestamp_now_str})


            user_id_for_log = current_user_info.get("name", "anonymous_chat_user_runtime")
            print(f"User '{user_id_for_log}' submitted query: '{user_query_input[:50]}...' with file: {uploaded_chat_file_runtime.name if uploaded_chat_file_runtime else 'None'}")
            
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                assistant_response_content = "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                try:
                    print("Step 1: Preparing context and calculating tokens...")
                    context_items_for_prompt = []
                    
                    # --- ì±„íŒ… ì¤‘ íŒŒì¼ ì²˜ë¦¬ ë¡œì§ ---
                    text_from_chat_file = None
                    is_chat_file_image_description = False
                    chat_file_source_name_for_prompt = None

                    if uploaded_chat_file_runtime:
                        file_ext_chat = os.path.splitext(uploaded_chat_file_runtime.name)[1].lower()
                        is_image_chat = file_ext_chat in [".png", ".jpg", ".jpeg"]
                        
                        if is_image_chat:
                            print(f"DEBUG Chat: Processing uploaded image '{uploaded_chat_file_runtime.name}' for description.")
                            with st.spinner(f"ì²¨ë¶€ ì´ë¯¸ì§€ '{uploaded_chat_file_runtime.name}' ë¶„ì„ ì¤‘..."):
                                image_bytes_chat = uploaded_chat_file_runtime.getvalue()
                                description_chat = get_image_description(image_bytes_chat, uploaded_chat_file_runtime.name, openai_client)
                            if description_chat:
                                text_from_chat_file = description_chat
                                chat_file_source_name_for_prompt = f"ì‚¬ìš©ì ì²¨ë¶€ ì´ë¯¸ì§€: {uploaded_chat_file_runtime.name}" # (ì„¤ëª…)ì€ ë‚˜ì¤‘ì— ë¶™ì„
                                is_chat_file_image_description = True
                                print(f"DEBUG Chat: Image description generated for '{uploaded_chat_file_runtime.name}'. Length: {len(description_chat)}")
                            else:
                                st.warning(f"ì±„íŒ… ì¤‘ ì²¨ë¶€ëœ ì´ë¯¸ì§€ '{uploaded_chat_file_runtime.name}'ì˜ ì„¤ëª…ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í•´ë‹¹ íŒŒì¼ì€ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
                        else: # .txt, .pdf ë“± í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì¼
                            print(f"DEBUG Chat: Extracting text from uploaded file '{uploaded_chat_file_runtime.name}'.")
                            text_from_chat_file = extract_text_from_file(uploaded_chat_file_runtime)
                            if text_from_chat_file:
                                chat_file_source_name_for_prompt = f"ì‚¬ìš©ì ì²¨ë¶€ íŒŒì¼: {uploaded_chat_file_runtime.name}"
                                print(f"DEBUG Chat: Text extracted from '{uploaded_chat_file_runtime.name}'. Length: {len(text_from_chat_file)}")
                            else:
                                st.info(f"ì±„íŒ… ì¤‘ ì²¨ë¶€ëœ '{uploaded_chat_file_runtime.name}' íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‚´ìš©ì…ë‹ˆë‹¤. ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
                        
                        if text_from_chat_file: # ë‚´ìš©ì´ ìˆëŠ” ê²½ìš° (í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ ì„¤ëª…)
                            context_items_for_prompt.append({
                                "source": chat_file_source_name_for_prompt,
                                "content": text_from_chat_file,
                                "is_image_description": is_chat_file_image_description 
                            })
                    # --- íŒŒì¼ ì²˜ë¦¬ ë¡œì§ ë ---

                    prompt_structure = f"{PROMPT_RULES_CONTENT}\n\nìœ„ì˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë° ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ë¬¸ì„œì˜ ë‚´ìš©ì…ë‹ˆë‹¤:\n<ë¬¸ì„œ ì‹œì‘>\n{{context}}\n<ë¬¸ì„œ ë>"
                    base_prompt_text = prompt_structure.replace('{context}', '')
                    try:
                        base_tokens = len(tokenizer.encode(base_prompt_text))
                        query_tokens = len(tokenizer.encode(user_query_input))
                    except Exception as e_tokenize_base:
                        st.error(f"ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë˜ëŠ” ì§ˆë¬¸ í† í°í™” ì¤‘ ì˜¤ë¥˜: {e_tokenize_base}")
                        raise # ë” ì´ìƒ ì§„í–‰ ë¶ˆê°€

                    print(f"DEBUG: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ êµ¬ì¡° í† í°: {base_tokens}")
                    print(f"DEBUG: ì‚¬ìš©ì ì§ˆë¬¸ í† í°: {query_tokens}")

                    max_context_tokens = TARGET_INPUT_TOKENS_FOR_PROMPT - base_tokens - query_tokens
                    print(f"DEBUG: ëª©í‘œ í”„ë¡¬í”„íŠ¸ í† í°: {TARGET_INPUT_TOKENS_FOR_PROMPT}")
                    print(f"DEBUG: ì»¨í…ìŠ¤íŠ¸ì— í• ë‹¹ ê°€ëŠ¥í•œ ìµœëŒ€ í† í°: {max_context_tokens}")

                    context_string_for_llm = "í˜„ì¬ ì°¸ê³ í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤." # ê¸°ë³¸ê°’
                    if max_context_tokens <= 0:
                         st.warning("í”„ë¡¬í”„íŠ¸ ê·œì¹™ê³¼ ì§ˆë¬¸ë§Œìœ¼ë¡œë„ ì…ë ¥ í† í° ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸(DB ê²€ìƒ‰ ê²°ê³¼, ì²¨ë¶€ íŒŒì¼ ë‚´ìš©)ë¥¼ í¬í•¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                         print("WARNING: No tokens left for context after accounting for rules and query.")
                         context_string_for_llm = "ì°¸ê³ í•  ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (í† í° ì œí•œ)."
                    else:
                        # DB ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ (ì‚¬ìš©ì ì§ˆë¬¸ + ì´ë¯¸ì§€ ì„¤ëª…ì´ ìˆë‹¤ë©´ ê·¸ê²ƒë„ í¬í•¨í•˜ì—¬ ê²€ìƒ‰)
                        query_for_db_search = user_query_input
                        if is_chat_file_image_description and text_from_chat_file: # ì´ë¯¸ì§€ ì„¤ëª…ì´ ìˆë‹¤ë©´ ê²€ìƒ‰ ì¿¼ë¦¬ì— ì¶”ê°€
                            query_for_db_search = f"{user_query_input}\n\nì´ë¯¸ì§€ ë‚´ìš©: {text_from_chat_file}"
                        
                        print(f"DEBUG: Retrieving context from Vector DB based on query: '{query_for_db_search[:50]}...'")
                        retrieved_items_from_db = search_similar_chunks(query_for_db_search, k_results=3) # ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ ì¡°ì ˆ ê°€ëŠ¥
                        if retrieved_items_from_db:
                            context_items_for_prompt.extend(retrieved_items_from_db) # DB ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
                            print(f"DEBUG: Retrieved {len(retrieved_items_from_db)} items from Vector DB with source info.")
                        else:
                            print(f"DEBUG: No relevant items found in Vector DB for query.")
                        
                        # ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ… ë° í† í° ì œí•œ ì ìš©
                        if not context_items_for_prompt:
                            print("DEBUG: No context items found (no file attached, no DB results).")
                            # context_string_for_llmëŠ” ê¸°ë³¸ê°’ "í˜„ì¬ ì°¸ê³ í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤." ìœ ì§€
                        else:
                            seen_contents_for_final_context = set()
                            formatted_context_chunks = []
                            for item_idx, item in enumerate(context_items_for_prompt):
                                if isinstance(item, dict):
                                    content_value = item.get("content", "")
                                    source_info = item.get('source', f'ì¶œì²˜ ì •ë³´ ì—†ìŒ {item_idx+1}')
                                    is_desc_item = item.get("is_image_description", False)
                                    
                                    content_strip = content_value.strip()
                                    if content_strip and content_strip not in seen_contents_for_final_context:
                                        final_source_display_name = source_info
                                        # ì±„íŒ… ì¤‘ ì²¨ë¶€ íŒŒì¼ ì†ŒìŠ¤ ì´ë¦„ ì •ë¦¬
                                        if source_info.startswith("ì‚¬ìš©ì ì²¨ë¶€ ì´ë¯¸ì§€: "):
                                            final_source_display_name = source_info.replace("ì‚¬ìš©ì ì²¨ë¶€ ì´ë¯¸ì§€: ", "")
                                        elif source_info.startswith("ì‚¬ìš©ì ì²¨ë¶€ íŒŒì¼: "):
                                            final_source_display_name = source_info.replace("ì‚¬ìš©ì ì²¨ë¶€ íŒŒì¼: ", "")

                                        if is_desc_item:
                                            formatted_context_chunks.append(f"[Image Description for: {final_source_display_name}]\n{content_value}")
                                        else:
                                            formatted_context_chunks.append(f"[ì¶œì²˜: {final_source_display_name}]\n{content_value}")
                                        seen_contents_for_final_context.add(content_strip)
                                
                            if not formatted_context_chunks:
                                print("DEBUG: No unique context items after filtering. Using 'í˜„ì¬ ì°¸ê³ í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.'")
                                # context_string_for_llmëŠ” ê¸°ë³¸ê°’ "í˜„ì¬ ì°¸ê³ í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤." ìœ ì§€
                            else:
                                full_context_string = "\n\n---\n\n".join(formatted_context_chunks)
                                try:
                                    full_context_tokens = tokenizer.encode(full_context_string)
                                except Exception as e_tokenize_full_ctx:
                                    st.error(f"ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ í† í°í™” ì¤‘ ì˜¤ë¥˜: {e_tokenize_full_ctx}")
                                    raise 

                                print(f"DEBUG: ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ í† í° ìˆ˜ (ì¶œì²˜ í¬í•¨ í¬ë§·): {len(full_context_tokens)}")

                                if len(full_context_tokens) > max_context_tokens:
                                    truncated_tokens = full_context_tokens[:max_context_tokens]
                                    try:
                                        context_string_for_llm = tokenizer.decode(truncated_tokens)
                                        if len(full_context_tokens) > len(truncated_tokens) : # ì˜ë ¸ìŒì„ ëª…ì‹œ
                                            context_string_for_llm += "\n(...ë‚´ìš© ë” ìˆìŒ, ì¼ë¶€ ë‚´ìš©ì´ ì˜ë ¸ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)"
                                    except Exception as e_decode_truncated:
                                        st.error(f"ì˜ë¦° í† í° ë””ì½”ë”© ì¤‘ ì˜¤ë¥˜: {e_decode_truncated}")
                                        context_string_for_llm = "[ì˜¤ë¥˜: ì»¨í…ìŠ¤íŠ¸ ë””ì½”ë”© ì‹¤íŒ¨]"
                                    print(f"WARNING: ì»¨í…ìŠ¤íŠ¸ í† í° ìˆ˜ê°€ ë„ˆë¬´ ë§ì•„ {max_context_tokens} í† í°ìœ¼ë¡œ ì˜ëìŠµë‹ˆë‹¤.")
                                    print(f"DEBUG: ì˜ë¦° ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ (ì• 100ì): {context_string_for_llm[:100]}")
                                else:
                                    context_string_for_llm = full_context_string
                                    print(f"DEBUG: ì „ì²´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì• 100ì): {context_string_for_llm[:100]}")
                    
                    # ìµœì¢… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                    system_prompt_content = prompt_structure.replace('{context}', context_string_for_llm)
                    try:
                        final_system_tokens = len(tokenizer.encode(system_prompt_content))
                        final_prompt_tokens = final_system_tokens + query_tokens # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ì‚¬ìš©ì ì§ˆë¬¸
                    except Exception as e_tokenize_final_sys:
                         st.error(f"ìµœì¢… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í† í°í™” ì¤‘ ì˜¤ë¥˜: {e_tokenize_final_sys}")
                         raise

                    print(f"DEBUG: ìµœì¢… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í† í°: {final_system_tokens}")
                    print(f"DEBUG: ìµœì¢… API ì…ë ¥ í† í° (ì‹œìŠ¤í…œ+ì§ˆë¬¸): {final_prompt_tokens}")
                    if final_prompt_tokens > MODEL_MAX_INPUT_TOKENS:
                         print(f"CRITICAL WARNING: ìµœì¢… ì…ë ¥ í† í°({final_prompt_tokens})ì´ ëª¨ë¸ ìµœëŒ€ì¹˜({MODEL_MAX_INPUT_TOKENS})ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤! API ì˜¤ë¥˜ ê°€ëŠ¥ì„± ë†’ìŒ.")
                         # st.warning(f"ì…ë ¥ ìš”ì²­ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (í˜„ì¬ {final_prompt_tokens} í† í°, ìµœëŒ€ {MODEL_MAX_INPUT_TOKENS} í† í°). ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                    chat_messages_for_api = [{"role":"system", "content": system_prompt_content}, {"role":"user", "content": user_query_input}]

                    print("Step 2: Sending request to Azure OpenAI for chat completion...")
                    chat_completion_response = openai_client.chat.completions.create(
                        model=st.secrets["AZURE_OPENAI_DEPLOYMENT"], # ì±„íŒ…ìš© ëª¨ë¸
                        messages=chat_messages_for_api,
                        max_tokens=MODEL_MAX_OUTPUT_TOKENS, # ë‹µë³€ ìµœëŒ€ í† í°
                        temperature=0.1, # ë‹µë³€ ì¼ê´€ì„±
                        timeout=AZURE_OPENAI_TIMEOUT
                    )
                    assistant_response_content = chat_completion_response.choices[0].message.content.strip()
                    print("Azure OpenAI response received.")

                    if chat_completion_response.usage and container_client:
                        print("Logging OpenAI API usage for chat completion...")
                        log_openai_api_usage_to_blob(user_id_for_log, st.secrets["AZURE_OPENAI_DEPLOYMENT"], chat_completion_response.usage, container_client, request_type="chat_completion_with_rag")
                
                # ... (ì´í•˜ ì˜ˆì™¸ ì²˜ë¦¬ ë¡œì§ì€ ì´ì „ê³¼ ê±°ì˜ ë™ì¼)
                except APITimeoutError:
                    assistant_response_content = "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ ìƒì„± ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë” ê°„ë‹¨í•˜ê²Œ í•´ì£¼ì‹œê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                    st.error(assistant_response_content)
                    print(f"TIMEOUT ERROR: Chat completion request timed out for user '{user_id_for_log}'.")
                except APIConnectionError as ace:
                    assistant_response_content = f"API ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {ace}. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                    st.error(assistant_response_content)
                    print(f"API CONNECTION ERROR during chat completion: {ace}")
                except RateLimitError as rle:
                    assistant_response_content = f"API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤: {rle}. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                    st.error(assistant_response_content)
                    print(f"RATE LIMIT ERROR during chat completion: {rle}")
                except APIStatusError as ase: # OpenAI APIê°€ ì—ëŸ¬ ìƒíƒœ ì½”ë“œë¥¼ ë°˜í™˜í•  ë•Œ
                    assistant_response_content = f"APIì—ì„œ ì˜¤ë¥˜ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤ (ìƒíƒœ ì½”ë“œ {ase.status_code}): {ase.message}. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
                    st.error(assistant_response_content)
                    print(f"API STATUS ERROR during chat completion (Status {ase.status_code}): {ase.message}")
                    if ase.response and ase.response.content:
                        try:
                            error_details_chat = json.loads(ase.response.content.decode('utf-8'))
                            print(f"DEBUG ChatCompletion: Azure API error details: {json.dumps(error_details_chat, indent=2, ensure_ascii=False)}")
                        except Exception as json_e_chat:
                            print(f"DEBUG ChatCompletion: Could not parse Azure API error content as JSON: {json_e_chat}")
                            print(f"DEBUG ChatCompletion: Raw Azure API error content: {ase.response.content}")
                except Exception as gen_err: # ê¸°íƒ€ ì˜ˆì™¸ (í† í°í™” ì‹¤íŒ¨ ë“± í¬í•¨)
                    assistant_response_content = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {gen_err}. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
                    st.error(assistant_response_content)
                    print(f"UNEXPECTED ERROR during response generation: {gen_err}\n{traceback.format_exc()}")

                st.session_state["messages"].append({"role":"assistant", "content":assistant_response_content, "time":timestamp_now_str})
                print("Response processing complete.")
            
            # ìœ„ì ¯ ìƒíƒœ ì´ˆê¸°í™”ë¥¼ ìœ„í•´ uploaded_chat_file_runtimeì„ Noneìœ¼ë¡œ ì„¤ì • (ì„ íƒì )
            # st.session_state[chat_file_uploader_key] = None # ì´ë ‡ê²Œ í•˜ë©´ ì—…ë¡œë”ê°€ ì´ˆê¸°í™”ë¨
            # ë˜ëŠ” ê·¸ëƒ¥ st.rerun()ë§Œ í˜¸ì¶œ
            st.rerun()


if admin_settings_tab:
    with admin_settings_tab:
        st.header("âš™ï¸ ê´€ë¦¬ì ì„¤ì •")
        st.subheader("ğŸ‘¥ ê°€ì… ìŠ¹ì¸ ëŒ€ê¸°ì")
        # (ì´ì „ê³¼ ë™ì¼ - ë³€ê²½ ì—†ìŒ)
        if not USERS or not isinstance(USERS, dict):
            st.warning("ì‚¬ìš©ì ì •ë³´ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ê±°ë‚˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print(f"WARNING: USERS data is problematic or empty in admin tab. Type: {type(USERS)}")
        else:
            pending_approval_users = {uid:udata for uid,udata in USERS.items() if isinstance(udata, dict) and not udata.get("approved")}
            if pending_approval_users:
                for pending_uid, pending_user_data in pending_approval_users.items():
                    with st.expander(f"{pending_user_data.get('name','N/A')} ({pending_uid}) - {pending_user_data.get('department','N/A')}"):
                        approve_col, reject_col = st.columns(2)
                        if approve_col.button("ìŠ¹ì¸", key=f"admin_approve_user_final_v5_{pending_uid}"): # í‚¤ ë³€ê²½
                            USERS[pending_uid]["approved"] = True
                            if save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´"):
                                st.success(f"'{pending_uid}' ì‚¬ìš©ìë¥¼ ìŠ¹ì¸í•˜ê³  Blobì— ì €ì¥í–ˆìŠµë‹ˆë‹¤."); st.rerun()
                            else: st.error("ì‚¬ìš©ì ìŠ¹ì¸ ì •ë³´ Blob ì €ì¥ ì‹¤íŒ¨.")
                        if reject_col.button("ê±°ì ˆ", key=f"admin_reject_user_final_v5_{pending_uid}"): # í‚¤ ë³€ê²½
                            USERS.pop(pending_uid, None)
                            if save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´"):
                                st.info(f"'{pending_uid}' ì‚¬ìš©ìì˜ ê°€ì… ì‹ ì²­ì„ ê±°ì ˆí•˜ê³  Blobì— ì €ì¥í–ˆìŠµë‹ˆë‹¤."); st.rerun()
                            else: st.error("ì‚¬ìš©ì ê±°ì ˆ ì •ë³´ Blob ì €ì¥ ì‹¤íŒ¨.")
            else: st.info("ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")

        st.subheader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ë° í•™ìŠµ (Azure Blob Storage)")
        if 'processed_admin_file_info' not in st.session_state:
            st.session_state.processed_admin_file_info = None

        def clear_processed_file_info_on_admin_upload_change():
            print(f"DEBUG admin_file_uploader on_change: Clearing processed_admin_file_info (was: {st.session_state.processed_admin_file_info})")
            st.session_state.processed_admin_file_info = None

        admin_file_uploader_key = "admin_file_uploader_v_final_img_txt" # í‚¤ ë³€ê²½
        admin_uploaded_file = st.file_uploader(
            "í•™ìŠµí•  íŒŒì¼ ì—…ë¡œë“œ (PDF, DOCX, XLSX, CSV, PPTX, TXT, PNG, JPG, JPEG)",
            type=["pdf","docx","xlsx","xlsm","csv","pptx", "txt", "png", "jpg", "jpeg"], # í—ˆìš© íƒ€ì… ì¶”ê°€
            key=admin_file_uploader_key,
            on_change=clear_processed_file_info_on_admin_upload_change,
            accept_multiple_files=False # í•œ ë²ˆì— í•˜ë‚˜ì˜ íŒŒì¼ë§Œ ì²˜ë¦¬
        )

        if admin_uploaded_file and container_client:
            current_file_info = (admin_uploaded_file.name, admin_uploaded_file.size, admin_uploaded_file.type)
            if st.session_state.processed_admin_file_info != current_file_info:
                print(f"DEBUG Admin Upload: New file detected. File Info: {current_file_info}")
                
                file_ext_admin = os.path.splitext(admin_uploaded_file.name)[1].lower()
                is_image_admin_upload = file_ext_admin in [".png", ".jpg", ".jpeg"]
                content_for_learning = None
                is_img_desc_for_learning = False

                if is_image_admin_upload:
                    with st.spinner(f"'{admin_uploaded_file.name}' ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì„¤ëª… ìƒì„± ì¤‘..."):
                        img_bytes_admin = admin_uploaded_file.getvalue()
                        description_admin = get_image_description(img_bytes_admin, admin_uploaded_file.name, openai_client)
                    if description_admin:
                        content_for_learning = description_admin
                        is_img_desc_for_learning = True
                        st.info(f"ì´ë¯¸ì§€ '{admin_uploaded_file.name}'ì— ëŒ€í•œ ì„¤ëª…ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤ (ê¸¸ì´: {len(description_admin)}). ì´ ì„¤ëª…ì„ í•™ìŠµí•©ë‹ˆë‹¤.")
                        st.text_area("ìƒì„±ëœ ì´ë¯¸ì§€ ì„¤ëª… (í•™ìŠµ ëŒ€ìƒ)", description_admin, height=150, disabled=True)
                    else:
                        st.error(f"'{admin_uploaded_file.name}' ì´ë¯¸ì§€ ì„¤ëª…ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í•™ìŠµì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
                else: # í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì¼ (pdf, docx, txt ë“±)
                    with st.spinner(f"'{admin_uploaded_file.name}' íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì¤‘..."):
                        content_for_learning = extract_text_from_file(admin_uploaded_file)
                    if content_for_learning:
                        st.info(f"'{admin_uploaded_file.name}' íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤ (ê¸¸ì´: {len(content_for_learning)}).")
                    else:
                        st.warning(f"'{admin_uploaded_file.name}' íŒŒì¼ì—ì„œ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. í•™ìŠµì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
                
                if content_for_learning: # ë‚´ìš©ì´ ìˆê±°ë‚˜ (í…ìŠ¤íŠ¸) ì„¤ëª…ì´ ìƒì„±ëœ ê²½ìš°
                    with st.spinner(f"'{admin_uploaded_file.name}' ë‚´ìš© ì²˜ë¦¬ ë° í•™ìŠµ ì§„í–‰ ì¤‘..."):
                        content_chunks_for_learning = chunk_text_into_pieces(content_for_learning)
                        if content_chunks_for_learning:
                            # ì›ë³¸ íŒŒì¼ ì €ì¥ (í•­ìƒ)
                            original_file_blob_path = save_original_file_to_blob(admin_uploaded_file, container_client)
                            if original_file_blob_path: 
                                st.caption(f"ì›ë³¸ íŒŒì¼ '{admin_uploaded_file.name}'ì´ Blobì— '{original_file_blob_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            else: 
                                st.warning(f"ì›ë³¸ íŒŒì¼ '{admin_uploaded_file.name}'ì„ Blobì— ì €ì¥í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                            # ë²¡í„° DBì— ì¶”ê°€ ë° ë©”íƒ€ë°ì´í„° ì €ì¥
                            if add_document_to_vector_db_and_blob(
                                admin_uploaded_file, 
                                content_for_learning, # ì›ë³¸ í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ ì„¤ëª… ì „ì²´ (ì²­í‚¹ ì „)
                                content_chunks_for_learning, 
                                container_client, 
                                is_image_description=is_img_desc_for_learning
                            ):
                                st.success(f"'{admin_uploaded_file.name}' íŒŒì¼ í•™ìŠµ ë° Azure Blob Storageì— ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
                                st.session_state.processed_admin_file_info = current_file_info # ì„±ê³µ ì‹œ ì •ë³´ ê¸°ë¡
                                # ì„±ê³µ í›„ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒíƒœë¥¼ ëª…í™•íˆ í•˜ê±°ë‚˜, ì—…ë¡œë”ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ìˆìŒ
                                st.rerun() 
                            else:
                                st.error(f"'{admin_uploaded_file.name}' í•™ìŠµ ë˜ëŠ” Blob ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                                st.session_state.processed_admin_file_info = None # ì‹¤íŒ¨ ì‹œ ì •ë³´ ì´ˆê¸°í™”
                        else: 
                            st.warning(f"'{admin_uploaded_file.name}' íŒŒì¼ì—ì„œ ìœ ì˜ë¯¸í•œ í•™ìŠµ ì²­í¬ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                # (content_for_learningì´ ì—†ëŠ” ê²½ìš°ëŠ” ìœ„ì—ì„œ ì´ë¯¸ st.error ë˜ëŠ” st.warningìœ¼ë¡œ ì²˜ë¦¬ë¨)
            elif st.session_state.processed_admin_file_info == current_file_info:
                 st.caption(f"'{admin_uploaded_file.name}' íŒŒì¼ì€ ì´ì „ì— ì„±ê³µì ìœ¼ë¡œ í•™ìŠµ(ë˜ëŠ” ì²˜ë¦¬ ì‹œë„)ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜, í˜„ì¬ íŒŒì¼ì„ ì œê±°(X ë²„íŠ¼) í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•˜ì—¬ ì¬í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif admin_uploaded_file and not container_client:
            st.error("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  í•™ìŠµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")

        st.subheader("ğŸ“Š API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (Blob ë¡œê·¸ ê¸°ë°˜)")
        # (ì´ì „ê³¼ ë™ì¼ - ë³€ê²½ ì—†ìŒ)
        if container_client:
            usage_data_from_blob = load_data_from_blob(USAGE_LOG_BLOB_NAME, container_client, "API ì‚¬ìš©ëŸ‰ ë¡œê·¸", default_value=[])
            if usage_data_from_blob and isinstance(usage_data_from_blob, list) and len(usage_data_from_blob) > 0 :
                df_usage_stats=pd.DataFrame(usage_data_from_blob)
                
                # í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸ ë° ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ìš°ê¸°
                for col in ["total_tokens", "prompt_tokens", "completion_tokens"]:
                     if col not in df_usage_stats.columns:
                         df_usage_stats[col] = 0
                if "request_type" not in df_usage_stats.columns: # ìƒˆë¡œ ì¶”ê°€ëœ ì»¬ëŸ¼
                    df_usage_stats["request_type"] = "unknown"


                token_cols = ["total_tokens", "prompt_tokens", "completion_tokens"]
                for col in token_cols: # ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜, ë³€í™˜ ë¶ˆê°€ ì‹œ 0
                    df_usage_stats[col] = pd.to_numeric(df_usage_stats[col], errors='coerce').fillna(0)

                total_tokens_used = df_usage_stats["total_tokens"].sum()
                st.metric("ì´ API í˜¸ì¶œ ìˆ˜", len(df_usage_stats))
                st.metric("ì´ ì‚¬ìš© í† í° ìˆ˜", f"{int(total_tokens_used):,}")

                token_cost_per_unit = 0.0
                try: token_cost_per_unit=float(st.secrets.get("TOKEN_COST","0"))
                except (ValueError, TypeError): pass # ë³€í™˜ ì‹¤íŒ¨ ì‹œ 0.0 ìœ ì§€
                st.metric("ì˜ˆìƒ ë¹„ìš© (USD)", f"${total_tokens_used * token_cost_per_unit:.4f}") # ì†Œìˆ˜ì  4ìë¦¬ê¹Œì§€

                if "timestamp" in df_usage_stats.columns:
                    try: # timestamp ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ ì‹œë„
                         df_usage_stats['timestamp'] = pd.to_datetime(df_usage_stats['timestamp'])
                         st.dataframe(df_usage_stats.sort_values(by="timestamp",ascending=False), use_container_width=True)
                    except Exception as e_sort_ts:
                         print(f"Warning: Could not sort usage log by timestamp due to conversion error: {e_sort_ts}")
                         st.dataframe(df_usage_stats, use_container_width=True) # ì •ë ¬ ì‹¤íŒ¨ ì‹œ ì›ë³¸ í‘œì‹œ
                else: # timestamp ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš°
                    st.dataframe(df_usage_stats, use_container_width=True)
            else: st.info("ê¸°ë¡ëœ API ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ Blobì— ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        else: st.warning("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")

        st.subheader("ğŸ“‚ Azure Blob Storage íŒŒì¼ ëª©ë¡ (ìµœê·¼ 100ê°œ)")
        # (ì´ì „ê³¼ ë™ì¼ - ë³€ê²½ ì—†ìŒ)
        if container_client:
            try:
                blob_list_display = []
                count = 0
                max_blobs_to_show = 100 # í‘œì‹œí•  ìµœëŒ€ Blob ìˆ˜
                # last_modified ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìµœê·¼ íŒŒì¼ë¶€í„° ê°€ì ¸ì˜¤ê¸°
                blobs_sorted = sorted(container_client.list_blobs(), key=lambda b: b.last_modified, reverse=True)

                for blob_item in blobs_sorted:
                    if count >= max_blobs_to_show:
                        break
                    blob_list_display.append({
                        "íŒŒì¼ëª…": blob_item.name,
                        "í¬ê¸° (bytes)": blob_item.size,
                        "ìˆ˜ì •ì¼": blob_item.last_modified.strftime('%Y-%m-%d %H:%M:%S') if blob_item.last_modified else 'N/A'
                    })
                    count += 1
                
                if blob_list_display:
                    df_blobs_display = pd.DataFrame(blob_list_display)
                    st.dataframe(df_blobs_display, use_container_width=True)
                else: st.info("Azure Blob Storageì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            except AzureError as ae_list_blob: # Azure ê´€ë ¨ ì˜¤ë¥˜ ëª…ì‹œì  ì²˜ë¦¬
                 st.error(f"Azure Blob íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ Azure ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {ae_list_blob}")
                 print(f"AZURE ERROR listing blobs: {ae_list_blob}\n{traceback.format_exc()}")
            except Exception as e_list_blob:
                st.error(f"Azure Blob íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e_list_blob}")
                print(f"ERROR listing blobs: {e_list_blob}\n{traceback.format_exc()}")
        else:
            st.warning("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ íŒŒì¼ ëª©ë¡ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
