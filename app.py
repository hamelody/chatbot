import streamlit as st # ì²« ë²ˆì§¸ ë¼ì¸ ë˜ëŠ” ì£¼ì„/ë¹ˆ ì¤„ ì œì™¸ ì²« ë¼ì¸
import os
import io
import fitz  # PyMuPDF
import pandas as pd
import docx
from pptx import Presentation
import faiss
import openai
import numpy as np
import json
import time
from datetime import datetime
from openai import AzureOpenAI
from azure.storage.blob import BlobServiceClient
import tempfile
from werkzeug.security import check_password_hash, generate_password_hash
from streamlit_cookies_manager import EncryptedCookieManager
import traceback
import base64

# Streamlit ì•±ì˜ ê°€ì¥ ì²« ë²ˆì§¸ ëª…ë ¹ìœ¼ë¡œ st.set_page_config() í˜¸ì¶œ
st.set_page_config(
    page_title="ìœ ì•¤ìƒëª…ê³¼í•™ ì—…ë¬´ ê°€ì´ë“œ ë´‡",
    layout="centered", # ìš”ì²­ì— ë”°ë¼ centered ìœ ì§€
    initial_sidebar_state="auto"
)

# --- Base64 ì¸ì½”ë”© í•¨ìˆ˜ ì •ì˜ ---
def get_base64_of_bin_file(bin_file_path):
    try:
        with open(bin_file_path, 'rb') as f:
            data = f.read()
        return base64.b64encode(data).decode()
    except FileNotFoundError:
        print(f"ERROR: ë¡œê³  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {bin_file_path}")
        return None
    except Exception as e:
        print(f"ERROR: ë¡œê³  íŒŒì¼ '{bin_file_path}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# --- ì „ì—­ ë³€ìˆ˜ ë° ê²½ë¡œ ì„¤ì • ---
RULES_PATH_REPO = ".streamlit/prompt_rules.txt"
COMPANY_LOGO_PATH_REPO = "company_logo.png"
INDEX_BLOB_NAME = "vector_db/vector.index"
METADATA_BLOB_NAME = "vector_db/metadata.json"
USERS_BLOB_NAME = "app_data/users.json"
UPLOAD_LOG_BLOB_NAME = "app_logs/upload_log.json"
USAGE_LOG_BLOB_NAME = "app_logs/usage_log.json"

# --- CSS ìŠ¤íƒ€ì¼ ---
st.markdown("""
<style>
    /* CSS ìŠ¤íƒ€ì¼ ë‚´ìš©ì€ ì´ì „ê³¼ ë™ì¼ */
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button {
        background-color: #FFFFFF; color: #333F48; border: 1px solid #BCC0C4;
        border-radius: 8px; padding: 8px 12px; font-weight: 500;
        width: auto; min-width: 100px; white-space: nowrap; display: inline-block;
        transition: background-color 0.3s ease, border-color 0.3s ease;
    }
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button:hover {
        background-color: #F0F2F5; border-color: #A0A4A8;
    }
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button:active {
        background-color: #E0E2E5;
    }
    .chat-bubble-container { display: flex; flex-direction: column; margin-bottom: 15px; }
    .user-align { align-items: flex-end; }
    .assistant-align { align-items: flex-start; }
    .bubble { padding: 10px 15px; border-radius: 18px; max-width: 75%; word-wrap: break-word; display: inline-block; color: black; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.08); position: relative; }
    .user-bubble { background-color: #90EE90; color: black; border-bottom-right-radius: 5px; } /* ì‚¬ìš©ì ë§í’ì„  (ì—°ì´ˆë¡) */
    .assistant-bubble { background-color: #E9E9EB; border-bottom-left-radius: 5px; }
    .timestamp { font-size: 0.7rem; color: #8E8E93; padding: 2px 5px 0px 5px; }
    .main-title-container { text-align: center; margin-bottom: 24px; }
    .main-title { font-size: 2.1rem; font-weight: bold; display: block; }
    .sub-title { font-size: 0.9rem; color: gray; display: block; margin-top: 4px;}
    .logo-container { display: flex; align-items: center; }
    .logo-image { margin-right: 10px; }
    .version-text { font-size: 0.9rem; color: gray; }
</style>
""", unsafe_allow_html=True)

# --- Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
@st.cache_resource
def get_azure_openai_client_cached():
    print("Attempting to initialize Azure OpenAI client...")
    try:
        client = AzureOpenAI(
            api_key=st.secrets["AZURE_OPENAI_KEY"],
            azure_endpoint=st.secrets["AZURE_OPENAI_ENDPOINT"],
            api_version=st.secrets["AZURE_OPENAI_VERSION"]
        )
        print("Azure OpenAI client initialized successfully.")
        return client
    except KeyError as e:
        st.error(f"Azure OpenAI ì„¤ì • ì˜¤ë¥˜: secrets.toml íŒŒì¼ì— '{e.args[0]}' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì•±ì´ ì •ìƒ ë™ì‘í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print(f"ERROR: Missing Azure OpenAI secret: {e.args[0]}")
        return None
    except Exception as e:
        st.error(f"Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}. ì•±ì´ ì •ìƒ ë™ì‘í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print(f"ERROR: Azure OpenAI client initialization failed: {e}\n{traceback.format_exc()}")
        return None

@st.cache_resource
def get_azure_blob_clients_cached():
    print("Attempting to initialize Azure Blob Service client...")
    try:
        blob_service_client = BlobServiceClient.from_connection_string(st.secrets["AZURE_BLOB_CONN"])
        container_name = st.secrets["BLOB_CONTAINER"]
        container_client = blob_service_client.get_container_client(container_name)
        print(f"Azure Blob Service client and container client for '{container_name}' initialized successfully.")
        return blob_service_client, container_client
    except KeyError as e:
        st.error(f"Azure Blob Storage ì„¤ì • ì˜¤ë¥˜: secrets.toml íŒŒì¼ì— '{e.args[0]}' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ERROR: Missing Azure Blob Storage secret: {e.args[0]}")
        return None, None
    except Exception as e:
        st.error(f"Azure Blob í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}. ë°ì´í„° ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ERROR: Azure Blob client initialization failed: {e}\n{traceback.format_exc()}")
        return None, None

openai_client = get_azure_openai_client_cached()
blob_service, container_client = get_azure_blob_clients_cached()

EMBEDDING_MODEL = None
if openai_client:
    try:
        EMBEDDING_MODEL = st.secrets["AZURE_OPENAI_EMBEDDING_DEPLOYMENT"]
        print(f"Embedding model set to: {EMBEDDING_MODEL}")
    except KeyError:
        st.error("secrets.toml íŒŒì¼ì— 'AZURE_OPENAI_EMBEDDING_DEPLOYMENT' ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. ì„ë² ë”© ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ERROR: Missing AZURE_OPENAI_EMBEDDING_DEPLOYMENT secret.")
        openai_client = None # ì„ë² ë”© ëª¨ë¸ ì—†ì´ëŠ” ì£¼ìš” ê¸°ëŠ¥ ë¶ˆê°€
    except Exception as e:
        st.error(f"ì„ë² ë”© ëª¨ë¸ ì„¤ì • ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"ERROR: Loading AZURE_OPENAI_EMBEDDING_DEPLOYMENT secret: {e}")
        openai_client = None

# --- ë°ì´í„° ë¡œë“œ/ì €ì¥ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (Blob ì—°ë™) ---
def load_data_from_blob(blob_name, _container_client, data_description="ë°ì´í„°", default_value=None):
    if not _container_client:
        print(f"ERROR: Blob Container client is None for load_data_from_blob ('{data_description}'). Returning default.")
        return default_value if default_value is not None else {}
    
    print(f"Attempting to load '{data_description}' from Blob: '{blob_name}'")
    try:
        blob_client_instance = _container_client.get_blob_client(blob_name)
        if blob_client_instance.exists():
            with tempfile.TemporaryDirectory() as tmpdir:
                local_temp_path = os.path.join(tmpdir, os.path.basename(blob_name))
                with open(local_temp_path, "wb") as download_file:
                    download_file.write(blob_client_instance.download_blob().readall())
                if os.path.getsize(local_temp_path) > 0:
                    with open(local_temp_path, "r", encoding="utf-8") as f:
                        loaded_data = json.load(f)
                    print(f"'{data_description}' loaded successfully from Blob: '{blob_name}'")
                    return loaded_data
                else:
                    print(f"WARNING: '{data_description}' file '{blob_name}' exists in Blob but is empty. Returning default.")
                    return default_value if default_value is not None else {}
        else:
            print(f"WARNING: '{data_description}' file '{blob_name}' not found in Blob Storage. Returning default.")
            return default_value if default_value is not None else {}
    except json.JSONDecodeError:
        print(f"ERROR: Failed to decode JSON for '{data_description}' from Blob '{blob_name}'. Returning default.")
        st.warning(f"'{data_description}' íŒŒì¼({blob_name})ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        return default_value if default_value is not None else {}
    except Exception as e:
        print(f"ERROR loading '{data_description}' from Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        st.warning(f"'{data_description}' ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        return default_value if default_value is not None else {}

def save_data_to_blob(data_to_save, blob_name, _container_client, data_description="ë°ì´í„°"):
    if not _container_client:
        st.error(f"Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ '{data_description}'ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ERROR: Blob Container client is None, cannot save '{blob_name}'.")
        return False
    print(f"Attempting to save '{data_description}' to Blob Storage: '{blob_name}'")
    try:
        # ì—…ë¡œë“œ ì „ì— ë°ì´í„° íƒ€ì… í™•ì¸ (JSON ì§ë ¬í™” ê°€ëŠ¥í•œì§€)
        if not isinstance(data_to_save, (dict, list)):
            st.error(f"'{data_description}' ì €ì¥ ì‹¤íŒ¨: ë°ì´í„°ê°€ JSONìœ¼ë¡œ ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…(dict ë˜ëŠ” list)ì´ ì•„ë‹™ë‹ˆë‹¤.")
            print(f"ERROR: Data for '{blob_name}' is not JSON serializable (type: {type(data_to_save)}).")
            return False

        with tempfile.TemporaryDirectory() as tmpdir:
            local_temp_path = os.path.join(tmpdir, os.path.basename(blob_name))
            with open(local_temp_path, "w", encoding="utf-8") as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
            
            blob_client_instance = _container_client.get_blob_client(blob_name)
            with open(local_temp_path, "rb") as data_stream:
                blob_client_instance.upload_blob(data_stream, overwrite=True)
            print(f"Successfully saved '{data_description}' to Blob: '{blob_name}'")
        return True
    except Exception as e:
        st.error(f"Azure Blobì— '{data_description}' ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"ERROR saving '{data_description}' to Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        return False

def save_binary_data_to_blob(local_file_path, blob_name, _container_client, data_description="ë°”ì´ë„ˆë¦¬ ë°ì´í„°"):
    if not _container_client:
        st.error(f"Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ '{data_description}' ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ERROR: Blob Container client is None, cannot save binary '{blob_name}'.")
        return False
    if not os.path.exists(local_file_path):
        st.error(f"'{data_description}' ì €ì¥ì„ ìœ„í•œ ë¡œì»¬ íŒŒì¼ '{local_file_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ERROR: Local file for binary data not found: '{local_file_path}'")
        return False

    print(f"Attempting to save binary '{data_description}' from '{local_file_path}' to Blob: '{blob_name}'")
    try:
        blob_client_instance = _container_client.get_blob_client(blob_name)
        with open(local_file_path, "rb") as data_stream:
            blob_client_instance.upload_blob(data_stream, overwrite=True)
        print(f"Successfully saved binary '{data_description}' to Blob: '{blob_name}'")
        return True
    except Exception as e:
        st.error(f"Azure Blobì— ë°”ì´ë„ˆë¦¬ '{data_description}' ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"ERROR saving binary '{data_description}' to Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        return False

# --- ì‚¬ìš©ì ì •ë³´ ë¡œë“œ ---
USERS = {} 
if container_client:
    USERS = load_data_from_blob(USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´", default_value={})
    if not USERS or "admin" not in USERS : 
        print(f"'{USERS_BLOB_NAME}' from Blob is empty or admin is missing. Creating default admin.")
        USERS["admin"] = {
            "name": "ê´€ë¦¬ì", "department": "í’ˆì§ˆë³´ì¦íŒ€",
            "password_hash": generate_password_hash("diteam"), 
            "approved": True, "role": "admin"
        }
        if not save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´"):
             st.warning("ê¸°ë³¸ ê´€ë¦¬ì ì •ë³´ë¥¼ Blobì— ì €ì¥í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹¤í–‰ ì‹œ ë‹¤ì‹œ ì‹œë„ë©ë‹ˆë‹¤.")
else:
    st.error("Azure Blob Storage ì—°ê²° ì‹¤íŒ¨. ì‚¬ìš©ì ì •ë³´ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•±ì´ ì •ìƒ ë™ì‘í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("CRITICAL: Cannot initialize USERS due to Blob client failure.")
    USERS = {"admin": {"name": "ê´€ë¦¬ì(ì—°ê²°ì‹¤íŒ¨)", "department": "ì‹œìŠ¤í…œ", "password_hash": generate_password_hash("fallback"), "approved": True, "role": "admin"}}


# --- ì¿ í‚¤ ë§¤ë‹ˆì € ë° ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
cookies = None
cookie_manager_ready = False
print(f"Attempting to load COOKIE_SECRET from st.secrets: {st.secrets.get('COOKIE_SECRET')}")
try:
    cookie_secret_key = st.secrets.get("COOKIE_SECRET")
    if not cookie_secret_key:
        st.error("secrets.toml íŒŒì¼ì— 'COOKIE_SECRET'ì´(ê°€) ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì¿ í‚¤ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ERROR: COOKIE_SECRET is not set or empty in st.secrets.")
    else:
        cookies = EncryptedCookieManager(
            prefix="gmp_chatbot_final_auth_v4/", # Prefix ë³€ê²½í•˜ì—¬ ì´ì „ ì¿ í‚¤ì™€ ì¶©ëŒ ë°©ì§€
            password=cookie_secret_key
        )
        if cookies.ready():
            cookie_manager_ready = True
            print("CookieManager is ready.")
        else:
            print("CookieManager not ready on initial setup (may resolve on first interaction).")
except Exception as e:
    st.error(f"ì¿ í‚¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
    print(f"CRITICAL: CookieManager initialization error: {e}\n{traceback.format_exc()}")

SESSION_TIMEOUT = 1800 # ê¸°ë³¸ê°’ (30ë¶„)
try:
    session_timeout_secret = st.secrets.get("SESSION_TIMEOUT")
    if session_timeout_secret: SESSION_TIMEOUT = int(session_timeout_secret)
    print(f"Session timeout set to: {SESSION_TIMEOUT} seconds.")
except (ValueError, TypeError):
    print(f"WARNING: SESSION_TIMEOUT in secrets ('{session_timeout_secret}') is not a valid integer. Using default {SESSION_TIMEOUT}s.")
except Exception as e:
     print(f"WARNING: Error reading SESSION_TIMEOUT from secrets: {e}. Using default {SESSION_TIMEOUT}s.")


# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëŒ€í™” ë‚´ìš© í¬í•¨) ---
if "authenticated" not in st.session_state:
    print("Initializing st.session_state: 'authenticated', 'user', and 'messages'")
    st.session_state["authenticated"] = False
    st.session_state["user"] = {}
    st.session_state["messages"] = [] # *** ì¤‘ìš”: ì„¸ì…˜ ì‹œì‘ ì‹œ ë©”ì‹œì§€ ëª©ë¡ ì´ˆê¸°í™” ***
    
    if cookie_manager_ready: 
        auth_cookie_val = cookies.get("authenticated")
        print(f"Cookie 'authenticated' value on session init: {auth_cookie_val}")
        if auth_cookie_val == "true":
            login_time_str = cookies.get("login_time", "0")
            login_time = float(login_time_str if login_time_str and login_time_str.replace('.', '', 1).isdigit() else "0") # ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€
            if (time.time() - login_time) < SESSION_TIMEOUT:
                user_json_cookie = cookies.get("user", "{}")
                try:
                    user_data_from_cookie = json.loads(user_json_cookie if user_json_cookie else "{}")
                    if user_data_from_cookie and isinstance(user_data_from_cookie, dict): # íƒ€ì… í™•ì¸ ì¶”ê°€
                        st.session_state["user"] = user_data_from_cookie
                        st.session_state["authenticated"] = True
                        # ë¡œê·¸ì¸ ë³µì› ì‹œì—ëŠ” messagesë¥¼ ì—¬ê¸°ì„œ ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ.
                        print(f"User '{user_data_from_cookie.get('name')}' authenticated from cookie.")
                    else: 
                        print("User data in cookie is empty or invalid. Clearing auth state for cookie.")
                        st.session_state["authenticated"] = False 
                        if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
                except json.JSONDecodeError: 
                    print("ERROR: Failed to decode user JSON from cookie. Clearing auth state for cookie.")
                    st.session_state["authenticated"] = False 
                    if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
            else: 
                print("Session timeout detected from cookie. Clearing auth state for cookie.")
                st.session_state["authenticated"] = False 
                st.session_state["messages"] = [] # íƒ€ì„ì•„ì›ƒ ì‹œ ë©”ì‹œì§€ ì´ˆê¸°í™”
                if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
                # st.warning("ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.") # ë¡œê·¸ì¸ UI ì „ì— í‘œì‹œí•˜ë©´ ì¤‘ë³µ ê°€ëŠ¥
    else:
        print("CookieManager not ready, cannot restore session from cookie on session init.")

# ë¡œê·¸ì¸ UI ì „ì— st.session_state.messagesê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì´ˆê¸°í™” (ì¶”ê°€ ì•ˆì „ì¥ì¹˜)
if "messages" not in st.session_state:
    st.session_state["messages"] = []
    print("Redundant check: Initializing messages as it was not in session_state before login UI.")


# --- ë¡œê·¸ì¸ UI ë° ë¡œì§ ---
if not st.session_state.get("authenticated", False):
    st.title("ğŸ” ë¡œê·¸ì¸ ë˜ëŠ” íšŒì›ê°€ì…")
    if not cookie_manager_ready and st.secrets.get("COOKIE_SECRET"): # COOKIE_SECRETì€ ìˆëŠ”ë° ë§¤ë‹ˆì €ê°€ ì¤€ë¹„ ì•ˆëœ ê²½ìš°
        st.warning("ì¿ í‚¤ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    with st.form("auth_form_final_v3", clear_on_submit=False): # form key ë³€ê²½
        mode = st.radio("ì„ íƒ", ["ë¡œê·¸ì¸", "íšŒì›ê°€ì…"], key="auth_mode_final_v3")
        uid = st.text_input("ID", key="auth_uid_final_v3")
        pwd = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="auth_pwd_final_v3")
        name, dept = "", ""
        if mode == "íšŒì›ê°€ì…":
            name = st.text_input("ì´ë¦„", key="auth_name_final_v3")
            dept = st.text_input("ë¶€ì„œ", key="auth_dept_final_v3")
        submit_button = st.form_submit_button("í™•ì¸")

    if submit_button:
        if not uid or not pwd: st.error("IDì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif mode == "íšŒì›ê°€ì…" and (not name or not dept): st.error("ì´ë¦„ê³¼ ë¶€ì„œë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            if mode == "ë¡œê·¸ì¸":
                user_data_login = USERS.get(uid) # Blobì—ì„œ ë¡œë“œëœ USERS ì‚¬ìš©
                if not user_data_login: st.error("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” IDì…ë‹ˆë‹¤.")
                elif not user_data_login.get("approved", False): st.warning("ê°€ì… ìŠ¹ì¸ì´ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.")
                elif check_password_hash(user_data_login["password_hash"], pwd):
                    st.session_state["authenticated"] = True
                    st.session_state["user"] = user_data_login
                    st.session_state["messages"] = []  # *** ë¡œê·¸ì¸ ì„±ê³µ ì‹œ ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™” ***
                    print(f"Login successful for user '{uid}'. Chat messages cleared.")
                    if cookie_manager_ready:
                        try:
                            cookies["authenticated"] = "true"; cookies["user"] = json.dumps(user_data_login)
                            cookies["login_time"] = str(time.time()); cookies.save()
                            print(f"Cookies saved for user '{uid}'.")
                        except Exception as e_cookie_save:
                            st.warning(f"ë¡œê·¸ì¸ ì¿ í‚¤ ì €ì¥ ì¤‘ ë¬¸ì œ ë°œìƒ: {e_cookie_save}")
                            print(f"ERROR: Failed to save login cookies: {e_cookie_save}")
                    else:
                        st.warning("ì¿ í‚¤ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë¡œê·¸ì¸ ìƒíƒœë¥¼ ë¸Œë¼ìš°ì €ì— ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        print("WARNING: CookieManager not ready during login, cannot save cookies.")
                    st.success(f"{user_data_login.get('name', uid)}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤!"); st.rerun()
                else: st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            elif mode == "íšŒì›ê°€ì…":
                if uid in USERS: st.error("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” IDì…ë‹ˆë‹¤.")
                else:
                    USERS[uid] = {"name": name, "department": dept,
                                  "password_hash": generate_password_hash(pwd),
                                  "approved": False, "role": "user"}
                    if not save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´"):
                        st.error("ì‚¬ìš©ì ì •ë³´ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
                        # ì‹¤íŒ¨ ì‹œ USERS ë”•ì…”ë„ˆë¦¬ ë¡¤ë°± ê³ ë ¤
                        USERS.pop(uid, None) # ì¶”ê°€ ì‹œë„í–ˆë˜ ì‚¬ìš©ì ì œê±°
                    else:
                        st.success("ê°€ì… ì‹ ì²­ ì™„ë£Œ! ê´€ë¦¬ì ìŠ¹ì¸ í›„ ë¡œê·¸ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.stop()

# --- ì¸ì¦ í›„ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ ---
current_user_info = st.session_state.get("user", {})

# --- í—¤ë” (ë¡œê³ , ë²„ì „, ë¡œê·¸ì•„ì›ƒ ë²„íŠ¼) ---
top_cols_main = st.columns([0.7, 0.3])
with top_cols_main[0]:
    if os.path.exists(COMPANY_LOGO_PATH_REPO):
        logo_b64 = get_base64_of_bin_file(COMPANY_LOGO_PATH_REPO)
        if logo_b64:
            st.markdown(f"""
            <div class="logo-container">
                <img src="data:image/png;base64,{logo_b64}" class="logo-image" width="150">
                <span class="version-text">ver 2.0 (Chat Session Fix)</span>
            </div>""", unsafe_allow_html=True)
        else: # ë¡œê³  íŒŒì¼ì€ ìˆìœ¼ë‚˜ ì¸ì½”ë”© ì‹¤íŒ¨
            st.markdown(f"""<div class="logo-container"><span class="version-text" style="font-weight:bold;">ìœ ì•¤ìƒëª…ê³¼í•™</span> <span class="version-text" style="margin-left:10px;">ver 2.0 (Chat Session Fix)</span></div>""", unsafe_allow_html=True)
    else: # ë¡œê³  íŒŒì¼ ìì²´ê°€ ì—†ìŒ
        print(f"WARNING: Company logo file not found at {COMPANY_LOGO_PATH_REPO}")
        st.markdown(f"""<div class="logo-container"><span class="version-text" style="font-weight:bold;">ìœ ì•¤ìƒëª…ê³¼í•™</span> <span class="version-text" style="margin-left:10px;">ver 2.0 (Chat Session Fix)</span></div>""", unsafe_allow_html=True)

with top_cols_main[1]:
    st.markdown('<div style="text-align: right;">', unsafe_allow_html=True)
    if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_button_final_v3"): # ë²„íŠ¼ í‚¤ ë³€ê²½
        st.session_state["authenticated"] = False
        st.session_state["user"] = {}
        st.session_state["messages"] = []  # *** ë¡œê·¸ì•„ì›ƒ ì‹œ ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™” ***
        print("Logout successful. Chat messages cleared.")
        if cookie_manager_ready:
            try:
                cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
                print("Cookies cleared on logout.")
            except Exception as e_logout_cookie:
                print(f"ERROR: Failed to clear cookies on logout: {e_logout_cookie}")
        else:
             print("WARNING: CookieManager not ready during logout.")
        st.rerun()
    st.markdown('</div>', unsafe_allow_html=True)


# --- ë²¡í„° DB ë¡œë“œ (Azure Blob Storage ê¸°ë°˜) ---
@st.cache_resource
def load_vector_db_from_blob_cached(_container_client):
    if not _container_client:
        print("ERROR: Blob Container client is None for load_vector_db_from_blob_cached.")
        return faiss.IndexFlatL2(1536), [] 
    idx, meta = faiss.IndexFlatL2(1536), [] # ê¸°ë³¸ ë¹ˆ ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„°
    print(f"Attempting to load vector DB from Blob: '{INDEX_BLOB_NAME}', '{METADATA_BLOB_NAME}'")
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            local_index_path = os.path.join(tmpdir, os.path.basename(INDEX_BLOB_NAME))
            local_metadata_path = os.path.join(tmpdir, os.path.basename(METADATA_BLOB_NAME))

            index_blob_client = _container_client.get_blob_client(INDEX_BLOB_NAME)
            if index_blob_client.exists():
                with open(local_index_path, "wb") as download_file:
                    download_file.write(index_blob_client.download_blob().readall())
                if os.path.getsize(local_index_path) > 0: # íŒŒì¼ í¬ê¸° ì²´í¬
                    idx = faiss.read_index(local_index_path)
                    print(f"'{INDEX_BLOB_NAME}' loaded successfully from Blob Storage.")
                else:
                    print(f"WARNING: '{INDEX_BLOB_NAME}' is empty in Blob. Using new index.")
            else:
                # st.warning(f"Blob Storageì— '{INDEX_BLOB_NAME}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ì¸ë±ìŠ¤ê°€ ìƒì„±ë©ë‹ˆë‹¤.") # UIì— ë„ˆë¬´ ë§ì€ ê²½ê³  ë°©ì§€
                print(f"WARNING: '{INDEX_BLOB_NAME}' not found in Blob Storage. New index will be used/created.")

            metadata_blob_client = _container_client.get_blob_client(METADATA_BLOB_NAME)
            if metadata_blob_client.exists():
                with open(local_metadata_path, "wb") as download_file:
                    download_file.write(metadata_blob_client.download_blob().readall())
                if os.path.getsize(local_metadata_path) > 0 :
                    with open(local_metadata_path, "r", encoding="utf-8") as f: meta = json.load(f)
                else: 
                    meta = [] 
                    print(f"WARNING: '{METADATA_BLOB_NAME}' is empty in Blob.")
            else:
                # st.warning(f"Blob Storageì— '{METADATA_BLOB_NAME}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ë©”íƒ€ë°ì´í„°ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
                print(f"WARNING: '{METADATA_BLOB_NAME}' not found in Blob Storage. Starting with empty metadata.")
                meta = []
    except Exception as e:
        st.error(f"Azure Blob Storageì—ì„œ ë²¡í„°DB ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ERROR loading vector DB from Blob: {e}\n{traceback.format_exc()}")
    return idx, meta

index, metadata = faiss.IndexFlatL2(1536), [] 
if container_client:
    index, metadata = load_vector_db_from_blob_cached(container_client)
else:
    st.error("Azure Blob Storage ì—°ê²° ì‹¤íŒ¨ë¡œ ë²¡í„° DBë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í•™ìŠµ ë° ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("CRITICAL: Cannot load vector DB due to Blob client initialization failure (main section).")


# --- ê·œì¹™ íŒŒì¼ ë¡œë“œ ---
@st.cache_data
def load_prompt_rules_cached():
    if os.path.exists(RULES_PATH_REPO):
        try:
            with open(RULES_PATH_REPO, "r", encoding="utf-8") as f: rules_content = f.read()
            print(f"Prompt rules loaded successfully from '{RULES_PATH_REPO}'.")
            return rules_content
        except Exception as e:
            st.warning(f"'{RULES_PATH_REPO}' íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}. ê¸°ë³¸ ê·œì¹™ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            print(f"WARNING: Error loading prompt rules from '{RULES_PATH_REPO}': {e}")
    else:
        print(f"WARNING: Prompt rules file not found at '{RULES_PATH_REPO}'. Using default rules.")
    return "ë‹¹ì‹ ì€ ì œì•½íšŒì‚¬ DI/GMP ì „ë¬¸ê°€ ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ í•™ìŠµëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤. (ê¸°ë³¸ ê·œì¹™)"

PROMPT_RULES_CONTENT = load_prompt_rules_cached()

# --- í…ìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ---
def extract_text_from_file(uploaded_file_obj):
    ext = os.path.splitext(uploaded_file_obj.name)[1].lower(); text_content = ""
    try:
        uploaded_file_obj.seek(0); file_bytes = uploaded_file_obj.read()
        if ext == ".pdf":
            with fitz.open(stream=file_bytes, filetype="pdf") as doc: text_content = "\n".join(page.get_text() for page in doc)
        elif ext == ".docx": 
            with io.BytesIO(file_bytes) as doc_io: doc = docx.Document(doc_io); text_content = "\n".join(para.text for para in doc.paragraphs)
        elif ext in (".xlsx", ".xlsm"): 
            with io.BytesIO(file_bytes) as excel_io: df = pd.read_excel(excel_io); text_content = df.to_string(index=False)
        elif ext == ".csv": 
            with io.BytesIO(file_bytes) as csv_io:
                try: df = pd.read_csv(csv_io)
                except UnicodeDecodeError: df = pd.read_csv(csv_io, encoding='cp949')
                text_content = df.to_string(index=False)
        elif ext == ".pptx": 
            with io.BytesIO(file_bytes) as ppt_io: prs = Presentation(ppt_io); text_content = "\n".join(shape.text for slide in prs.slides for shape in slide.shapes if hasattr(shape, "text"))
        else: st.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {ext}"); return ""
    except Exception as e:
        st.error(f"'{uploaded_file_obj.name}' íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"Error extracting text from '{uploaded_file_obj.name}': {e}\n{traceback.format_exc()}")
        return ""
    return text_content.strip()

def chunk_text_into_pieces(text_to_chunk, chunk_size=500):
    if not text_to_chunk or not text_to_chunk.strip(): return [];
    chunks_list, current_buffer = [], ""
    for line in text_to_chunk.split("\n"):
        stripped_line = line.strip()
        if not stripped_line and not current_buffer.strip(): continue
        if len(current_buffer) + len(stripped_line) + 1 < chunk_size: 
            current_buffer += stripped_line + "\n"
        else:
            if current_buffer.strip(): chunks_list.append(current_buffer.strip())
            current_buffer = stripped_line + "\n"
    if current_buffer.strip(): chunks_list.append(current_buffer.strip())
    return [c for c in chunks_list if c] 

def get_text_embedding(text_to_embed):
    if not openai_client or not EMBEDDING_MODEL:
        # st.error("OpenAI í´ë¼ì´ì–¸íŠ¸ ë˜ëŠ” ì„ë² ë”© ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„ë² ë”©ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.") # UIì— ë„ˆë¬´ ë§ì€ ì—ëŸ¬ ë°©ì§€
        print("ERROR: OpenAI client or embedding model not ready for get_text_embedding.")
        return None
    if not text_to_embed or not text_to_embed.strip(): return None
    try:
        response = openai_client.embeddings.create(input=[text_to_embed], model=EMBEDDING_MODEL)
        return response.data[0].embedding
    except Exception as e:
        st.error(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"ERROR: Failed to get text embedding for '{text_to_embed[:50]}...': {e}\n{traceback.format_exc()}")
        return None

# --- ìœ ì‚¬ë„ ê²€ìƒ‰ ë° ë¬¸ì„œ ì¶”ê°€ (Blob ì—°ë™) ---
def search_similar_chunks(query_text, k_results=5):
    if index is None or index.ntotal == 0 or not metadata:
        print("Search not possible: Index is empty or metadata is missing.")
        return []
    query_vector = get_text_embedding(query_text)
    if query_vector is None: return []
    try:
        actual_k = min(k_results, index.ntotal)
        if actual_k == 0 : return [] 

        distances, indices_found = index.search(np.array([query_vector]).astype("float32"), actual_k)
        valid_indices = [i for i in indices_found[0] if 0 <= i < len(metadata)]
        return [metadata[i]["content"] for i in valid_indices]
    except Exception as e:
        st.error(f"ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"ERROR: Similarity search failed: {e}\n{traceback.format_exc()}")
        return []

def add_document_to_vector_db_and_blob(uploaded_file_obj, text_content, text_chunks, _container_client):
    global index, metadata
    if not text_chunks: st.warning(f"'{uploaded_file_obj.name}' íŒŒì¼ì—ì„œ ì²˜ë¦¬í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."); return False
    if not _container_client: st.error("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ í•™ìŠµ ê²°ê³¼ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return False

    vectors_to_add, new_metadata_entries_for_current_file = [], []
    for chunk_idx, chunk in enumerate(text_chunks):
        print(f"Processing chunk {chunk_idx+1}/{len(text_chunks)} for embedding from '{uploaded_file_obj.name}'...")
        embedding = get_text_embedding(chunk)
        if embedding is not None:
            vectors_to_add.append(embedding)
            new_metadata_entries_for_current_file.append({"file_name": uploaded_file_obj.name, "content": chunk})
        else:
            print(f"Warning: Failed to get embedding for a chunk in '{uploaded_file_obj.name}'. Skipping chunk.")

    if not vectors_to_add: st.warning(f"'{uploaded_file_obj.name}' íŒŒì¼ì—ì„œ ìœ íš¨í•œ ì„ë² ë”©ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); return False

    try:
        if vectors_to_add: index.add(np.array(vectors_to_add).astype("float32"))
        metadata.extend(new_metadata_entries_for_current_file) # ì „ì—­ metadata ì—…ë°ì´íŠ¸
        print(f"Added {len(vectors_to_add)} new chunks to in-memory DB from '{uploaded_file_obj.name}'. Index total: {index.ntotal}")

        with tempfile.TemporaryDirectory() as tmpdir:
            temp_index_path = os.path.join(tmpdir, "temp.index")
            if index.ntotal > 0 : 
                 faiss.write_index(index, temp_index_path) # í˜„ì¬ ì „ì²´ indexë¥¼ ì„ì‹œ íŒŒì¼ì— ì”€
                 if not save_binary_data_to_blob(temp_index_path, INDEX_BLOB_NAME, _container_client, "ë²¡í„° ì¸ë±ìŠ¤"):
                    st.error("ë²¡í„° ì¸ë±ìŠ¤ Blob ì €ì¥ ì‹¤íŒ¨"); return False
            else: # ì¸ë±ìŠ¤ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°, Blobì— ë¹ˆ íŒŒì¼ì„ ì˜¬ë¦¬ê±°ë‚˜ ì•„ë¬´ê²ƒë„ ì•ˆí•¨
                print(f"Skipping saving empty index to Blob: {INDEX_BLOB_NAME}")
                # í•„ìš”í•˜ë‹¤ë©´ Blobì—ì„œ ê¸°ì¡´ ì¸ë±ìŠ¤ íŒŒì¼ ì‚­ì œ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
                # index_blob_client = _container_client.get_blob_client(INDEX_BLOB_NAME)
                # if index_blob_client.exists(): index_blob_client.delete_blob()

        if not save_data_to_blob(metadata, METADATA_BLOB_NAME, _container_client, "ë©”íƒ€ë°ì´í„°"): # í˜„ì¬ ì „ì²´ metadata ì €ì¥
            st.error("ë©”íƒ€ë°ì´í„° Blob ì €ì¥ ì‹¤íŒ¨"); return False

        user_info = st.session_state.get("user", {}); uploader_name = user_info.get("name", "N/A")
        new_log_entry = {"file": uploaded_file_obj.name, "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                         "chunks_added": len(vectors_to_add), "uploader": uploader_name}
        
        current_upload_logs = load_data_from_blob(UPLOAD_LOG_BLOB_NAME, _container_client, "ì—…ë¡œë“œ ë¡œê·¸", default_value=[])
        if not isinstance(current_upload_logs, list): current_upload_logs = []
        current_upload_logs.append(new_log_entry)
        if not save_data_to_blob(current_upload_logs, UPLOAD_LOG_BLOB_NAME, _container_client, "ì—…ë¡œë“œ ë¡œê·¸"):
            st.warning("ì—…ë¡œë“œ ë¡œê·¸ë¥¼ Blobì— ì €ì¥í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return True
    except Exception as e:
        st.error(f"ë¬¸ì„œ í•™ìŠµ ë˜ëŠ” Azure Blob ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"ERROR: Failed to add document or upload to Blob: {e}\n{traceback.format_exc()}")
        return False

def save_original_file_to_blob(uploaded_file_obj, _container_client):
    if not _container_client: st.error("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ì›ë³¸ íŒŒì¼ì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return None
    try:
        uploaded_file_obj.seek(0)
        # íŒŒì¼ëª… ì¤‘ë³µì„ í”¼í•˜ê¸° ìœ„í•´ íƒ€ì„ìŠ¤íƒ¬í”„ë‚˜ UUID ì¶”ê°€ ê³ ë ¤
        original_blob_name = f"uploaded_originals/{datetime.now().strftime('%Y%m%d%H%M%S')}_{uploaded_file_obj.name}"
        blob_client_for_original = _container_client.get_blob_client(blob=original_blob_name)
        blob_client_for_original.upload_blob(uploaded_file_obj.getvalue(), overwrite=False) # overwrite=Falseë¡œ ì„¤ì •í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
        print(f"Original file '{uploaded_file_obj.name}' saved to Blob as '{original_blob_name}'.")
        return original_blob_name # ì €ì¥ëœ Blob ê²½ë¡œ/ì´ë¦„ ë°˜í™˜
    except Exception as e: # êµ¬ì²´ì ì¸ ì˜ˆì™¸ ì²˜ë¦¬ (ì˜ˆ: AzureError) ê°€ëŠ¥
        st.error(f"'{uploaded_file_obj.name}' ì›ë³¸ íŒŒì¼ Blob ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"ERROR: Failed to save original file to Blob: {e}\n{traceback.format_exc()}")
        return None

# --- ì‚¬ìš©ëŸ‰ ë¡œê¹… í•¨ìˆ˜ (Blob ì—°ë™) ---
def log_openai_api_usage_to_blob(user_id_str, model_name_str, usage_stats_obj, _container_client):
    if not _container_client:
        print("ERROR: Blob Container client is None for API usage log. Skipping log.")
        return

    new_log_entry = {
        "user_id": user_id_str, "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "model_used": model_name_str, "prompt_tokens": usage_stats_obj.prompt_tokens,
        "completion_tokens": usage_stats_obj.completion_tokens, "total_tokens": usage_stats_obj.total_tokens
    }
    
    current_usage_logs = load_data_from_blob(USAGE_LOG_BLOB_NAME, _container_client, "API ì‚¬ìš©ëŸ‰ ë¡œê·¸", default_value=[])
    if not isinstance(current_usage_logs, list): current_usage_logs = [] 
    current_usage_logs.append(new_log_entry)
    
    if not save_data_to_blob(current_usage_logs, USAGE_LOG_BLOB_NAME, _container_client, "API ì‚¬ìš©ëŸ‰ ë¡œê·¸"):
        # st.warning("API ì‚¬ìš©ëŸ‰ ë¡œê·¸ë¥¼ Blobì— ì €ì¥í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") # UIì— ë„ˆë¬´ ë§ì€ ê²½ê³  ë°©ì§€
        print(f"WARNING: Failed to save API usage log to Blob for user '{user_id_str}'.")


# --- ë©”ì¸ UI êµ¬ì„± ---
st.markdown("""
<div class="main-title-container">
  <span class="main-title">ìœ ì•¤ìƒëª…ê³¼í•™ GMP/SOP ì—…ë¬´ ê°€ì´ë“œ ë´‡</span>
  <span class="sub-title">Made by DI.PART</span>
</div>
""", unsafe_allow_html=True)

tab_labels_list = ["ğŸ’¬ ì—…ë¬´ ì§ˆë¬¸"]
if current_user_info.get("role") == "admin": 
    tab_labels_list.append("âš™ï¸ ê´€ë¦¬ì ì„¤ì •")

main_tabs_list = st.tabs(tab_labels_list)
chat_interface_tab = main_tabs_list[0]
admin_settings_tab = main_tabs_list[1] if len(main_tabs_list) > 1 else None

with chat_interface_tab:
    st.header("ì—…ë¬´ ì§ˆë¬¸")
    st.markdown("ğŸ’¡ ì˜ˆì‹œ: SOP ë°±ì—… ì£¼ê¸°, PIC/S Annex 11 ì°¨ì´ ë“±")

    # ì„¸ì…˜ ì‹œì‘ ì‹œ messagesê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™” (ìœ„ì—ì„œ ì´ë¯¸ ìˆ˜í–‰í–ˆì§€ë§Œ, ì•ˆì „ì¥ì¹˜)
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
        print("Chat messages list re-initialized in chat_tab (should not happen if init Ğ¸ÑĞ¿Ğ°Ğ½ÑĞºĞ¸Ğ¹).")

    for msg_item in st.session_state["messages"]: # í˜„ì¬ ì„¸ì…˜ì˜ ë©”ì‹œì§€ë§Œ í‘œì‹œ
        role, content, time_str = msg_item.get("role"), msg_item.get("content", ""), msg_item.get("time", "")
        align_class = "user-align" if role == "user" else "assistant-align"
        bubble_class = "user-bubble" if role == "user" else "assistant-bubble"
        # HTML injection ë°©ì§€ë¥¼ ìœ„í•´ content ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬ ê³ ë ¤ (st.markdownì€ ê¸°ë³¸ì ìœ¼ë¡œ ì–´ëŠì •ë„ ì²˜ë¦¬í•¨)
        st.markdown(f"""<div class="chat-bubble-container {align_class}"><div class="bubble {bubble_class}">{content}</div><div class="timestamp">{time_str}</div></div>""", unsafe_allow_html=True)

    st.markdown("<div style='height:16px'></div>", unsafe_allow_html=True) # ì—¬ë°±
    if st.button("ğŸ“‚ íŒŒì¼ ì²¨ë¶€/ìˆ¨ê¸°ê¸°", key="toggle_chat_uploader_final_v3_button"): # í‚¤ ë³€ê²½
        st.session_state.show_uploader = not st.session_state.get("show_uploader", False)

    chat_file_uploader_key = "chat_file_uploader_final_v3_widget" # í‚¤ ë³€ê²½
    uploaded_chat_file_runtime = None
    if st.session_state.get("show_uploader", False):
        uploaded_chat_file_runtime = st.file_uploader("ì§ˆë¬¸ê³¼ í•¨ê»˜ ì°¸ê³ í•  íŒŒì¼ ì²¨ë¶€ (ì„ íƒ ì‚¬í•­)",
                                     type=["pdf","docx","xlsx","xlsm","csv","pptx"],
                                     key=chat_file_uploader_key)
        if uploaded_chat_file_runtime: st.caption(f"ì²¨ë¶€ë¨: {uploaded_chat_file_runtime.name}")

    with st.form("chat_input_form_final_v3", clear_on_submit=True): # form key ë³€ê²½
        query_input_col, send_button_col = st.columns([4,1])
        with query_input_col:
            user_query_input = st.text_input("ì§ˆë¬¸ ì…ë ¥:", placeholder="ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
                                             key="user_query_text_input_final_v3", label_visibility="collapsed") # í‚¤ ë³€ê²½
        with send_button_col:
            send_query_button = st.form_submit_button("ì „ì†¡")

    if send_query_button and user_query_input.strip():
        if not openai_client: # OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            st.error("OpenAI ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        else:
            timestamp_now_str = datetime.now().strftime("%Y-%m-%d %H:%M")
            # í˜„ì¬ ì„¸ì…˜ì˜ messages ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            st.session_state["messages"].append({"role":"user", "content":user_query_input, "time":timestamp_now_str})
            
            user_id_for_log = current_user_info.get("name", "anonymous_chat_user_runtime") 
            
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                try:
                    context_chunks_for_prompt = []
                    if uploaded_chat_file_runtime: # í˜„ì¬ ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš©
                        temp_file_text = extract_text_from_file(uploaded_chat_file_runtime)
                        if temp_file_text:
                            temp_file_chunks = chunk_text_into_pieces(temp_file_text)
                            if temp_file_chunks:
                                for chunk_piece in temp_file_chunks:
                                    context_chunks_for_prompt.extend(search_similar_chunks(chunk_piece, k_results=2))
                                if not context_chunks_for_prompt: # ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ ì—†ìœ¼ë©´ ì›ë³¸ ì¼ë¶€ ì‚¬ìš©
                                     context_chunks_for_prompt.append(temp_file_text[:2000]) # ì˜ˆ: ì²« 2000ì
                            else: st.info(f"'{uploaded_chat_file_runtime.name}' íŒŒì¼ì—ì„œ ìœ ì˜ë¯¸í•œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else: st.info(f"'{uploaded_chat_file_runtime.name}' íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‚´ìš©ì…ë‹ˆë‹¤.")

                    if not context_chunks_for_prompt or len(context_chunks_for_prompt) < 3:
                        needed_k = max(1, 3 - len(context_chunks_for_prompt))
                        context_chunks_for_prompt.extend(search_similar_chunks(user_query_input, k_results=needed_k))

                    final_unique_context = list(set(c for c in context_chunks_for_prompt if c and c.strip())) # ì¤‘ë³µ ì œê±°
                    if not final_unique_context: st.info("ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì°¸ê³  ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ë‹µë³€ì„ ì‹œë„í•©ë‹ˆë‹¤.")

                    context_string_for_llm = "\n\n---\n\n".join(final_unique_context) if final_unique_context else "í˜„ì¬ ì°¸ê³ í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
                    system_prompt_content = f"{PROMPT_RULES_CONTENT}\n\nìœ„ì˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë° ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ë¬¸ì„œì˜ ë‚´ìš©ì…ë‹ˆë‹¤:\n<ë¬¸ì„œ ì‹œì‘>\n{context_string_for_llm}\n<ë¬¸ì„œ ë>"
                    
                    chat_messages = [{"role":"system", "content": system_prompt_content}, {"role":"user", "content": user_query_input}]
                    chat_completion_response = openai_client.chat.completions.create(
                        model=st.secrets["AZURE_OPENAI_DEPLOYMENT"], messages=chat_messages, max_tokens=4000, temperature=0.1)
                    assistant_response_content = chat_completion_response.choices[0].message.content.strip()
                    st.session_state["messages"].append({"role":"assistant", "content":assistant_response_content, "time":timestamp_now_str})
                    
                    if chat_completion_response.usage and container_client: # container_client ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
                        log_openai_api_usage_to_blob(user_id_for_log, st.secrets["AZURE_OPENAI_DEPLOYMENT"], chat_completion_response.usage, container_client)

                except Exception as gen_err:
                    st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {gen_err}")
                    st.session_state["messages"].append({"role":"assistant", "content":"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.", "time":timestamp_now_str})
                    print(f"ERROR: General error during response generation: {gen_err}\n{traceback.format_exc()}")
            st.rerun() # UI ì—…ë°ì´íŠ¸


if admin_settings_tab: 
    with admin_settings_tab:
        st.header("âš™ï¸ ê´€ë¦¬ì ì„¤ì •")
        st.subheader("ğŸ‘¥ ê°€ì… ìŠ¹ì¸ ëŒ€ê¸°ì")
        if not USERS or not isinstance(USERS, dict): # USERSê°€ ìœ íš¨í•œ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
            st.warning("ì‚¬ìš©ì ì •ë³´ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ê±°ë‚˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print(f"WARNING: USERS data is problematic or empty in admin tab. Type: {type(USERS)}")
        else:
            pending_approval_users = {uid:udata for uid,udata in USERS.items() if isinstance(udata, dict) and not udata.get("approved")}
            if pending_approval_users:
                for pending_uid, pending_user_data in pending_approval_users.items():
                    with st.expander(f"{pending_user_data.get('name','N/A')} ({pending_uid}) - {pending_user_data.get('department','N/A')}"):
                        approve_col, reject_col = st.columns(2)
                        if approve_col.button("ìŠ¹ì¸", key=f"admin_approve_user_final_v3_{pending_uid}"): # í‚¤ ë³€ê²½
                            USERS[pending_uid]["approved"] = True
                            if save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´"):
                                st.success(f"'{pending_uid}' ì‚¬ìš©ìë¥¼ ìŠ¹ì¸í•˜ê³  Blobì— ì €ì¥í–ˆìŠµë‹ˆë‹¤."); st.rerun()
                            else: st.error("ì‚¬ìš©ì ìŠ¹ì¸ ì •ë³´ Blob ì €ì¥ ì‹¤íŒ¨.")
                        if reject_col.button("ê±°ì ˆ", key=f"admin_reject_user_final_v3_{pending_uid}"): # í‚¤ ë³€ê²½
                            USERS.pop(pending_uid, None) 
                            if save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "ì‚¬ìš©ì ì •ë³´"):
                                st.info(f"'{pending_uid}' ì‚¬ìš©ìì˜ ê°€ì… ì‹ ì²­ì„ ê±°ì ˆí•˜ê³  Blobì— ì €ì¥í–ˆìŠµë‹ˆë‹¤."); st.rerun()
                            else: st.error("ì‚¬ìš©ì ê±°ì ˆ ì •ë³´ Blob ì €ì¥ ì‹¤íŒ¨.")
            else: st.info("ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")

        st.subheader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ë° í•™ìŠµ (Azure Blob Storage)")
        admin_file_uploader_key = "admin_file_uploader_final_v3_widget" # í‚¤ ë³€ê²½
        admin_uploaded_file = st.file_uploader("í•™ìŠµí•  íŒŒì¼ ì—…ë¡œë“œ", type=["pdf","docx","xlsx","xlsm","csv","pptx"], key=admin_file_uploader_key)

        if admin_uploaded_file and container_client: # container_client ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            with st.spinner(f"'{admin_uploaded_file.name}' íŒŒì¼ ì²˜ë¦¬ ë° í•™ìŠµ ì¤‘..."):
                extracted_content = extract_text_from_file(admin_uploaded_file)
                if extracted_content:
                    content_chunks = chunk_text_into_pieces(extracted_content)
                    if content_chunks:
                        original_file_blob_path = save_original_file_to_blob(admin_uploaded_file, container_client)
                        if original_file_blob_path: st.caption(f"ì›ë³¸ íŒŒì¼ì´ Blobì— '{original_file_blob_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        else: st.warning("ì›ë³¸ íŒŒì¼ì„ Blobì— ì €ì¥í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                        if add_document_to_vector_db_and_blob(admin_uploaded_file, extracted_content, content_chunks, container_client):
                            st.success(f"'{admin_uploaded_file.name}' íŒŒì¼ í•™ìŠµ ë° Azure Blob Storageì— ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
                        else: st.error(f"'{admin_uploaded_file.name}' í•™ìŠµ ë˜ëŠ” Blob ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    else: st.warning(f"'{admin_uploaded_file.name}' íŒŒì¼ì—ì„œ ìœ ì˜ë¯¸í•œ ì²­í¬ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else: st.warning(f"'{admin_uploaded_file.name}' íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‚´ìš©ì…ë‹ˆë‹¤.")
            st.rerun() # ì²˜ë¦¬ í›„ UI ìƒˆë¡œê³ ì¹¨
        elif admin_uploaded_file and not container_client:
            st.error("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  í•™ìŠµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")

        st.subheader("ğŸ“Š API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (Blob ë¡œê·¸ ê¸°ë°˜)")
        if container_client: # container_client ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            usage_data_from_blob = load_data_from_blob(USAGE_LOG_BLOB_NAME, container_client, "API ì‚¬ìš©ëŸ‰ ë¡œê·¸", default_value=[])
            if usage_data_from_blob and isinstance(usage_data_from_blob, list) and len(usage_data_from_blob) > 0 :
                df_usage_stats=pd.DataFrame(usage_data_from_blob)
                if "total_tokens" not in df_usage_stats.columns:
                    df_usage_stats["total_tokens"] = 0 # ì—†ëŠ” ê²½ìš° 0ìœ¼ë¡œ ì±„ì›€
                    # st.warning("'total_tokens' ì»¬ëŸ¼ì´ ì¼ë¶€ ë¡œê·¸ì— ì—†ì–´ 0ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.") # ë„ˆë¬´ ë§ì€ ê²½ê³  ë°©ì§€
                
                total_tokens_used = df_usage_stats["total_tokens"].sum()
                st.metric("ì´ API í˜¸ì¶œ ìˆ˜", len(df_usage_stats))
                st.metric("ì´ ì‚¬ìš© í† í° ìˆ˜", f"{int(total_tokens_used):,}")
                
                token_cost_per_unit = 0.0
                try: token_cost_per_unit=float(st.secrets.get("TOKEN_COST","0"))
                except (ValueError, TypeError) : pass # ì˜¤ë¥˜ ì‹œ 0.0 ìœ ì§€
                st.metric("ì˜ˆìƒ ë¹„ìš© (USD)", f"${int(total_tokens_used) * token_cost_per_unit:.4f}")

                if "timestamp" in df_usage_stats.columns:
                    st.dataframe(df_usage_stats.sort_values(by="timestamp",ascending=False), use_container_width=True)
                else: 
                    st.dataframe(df_usage_stats, use_container_width=True)
            else: st.info("ê¸°ë¡ëœ API ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ Blobì— ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        else: st.warning("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")

        st.subheader("ğŸ“‚ Azure Blob Storage íŒŒì¼ ëª©ë¡ (ìµœê·¼ 100ê°œ)")
        if container_client: # container_client ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            try:
                blob_list_display = []
                for blob_item in container_client.list_blobs(results_per_page=100): 
                    blob_list_display.append({
                        "íŒŒì¼ëª…": blob_item.name, 
                        "í¬ê¸° (bytes)": blob_item.size, 
                        "ìˆ˜ì •ì¼": blob_item.last_modified.strftime('%Y-%m-%d %H:%M:%S') if blob_item.last_modified else 'N/A'
                    })
                if blob_list_display:
                    df_blobs_display = pd.DataFrame(blob_list_display)
                    st.dataframe(df_blobs_display.sort_values(by="ìˆ˜ì •ì¼", ascending=False), use_container_width=True)
                else: st.info("Azure Blob Storageì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"Azure Blob íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
                print(f"ERROR listing blobs: {e}\n{traceback.format_exc()}")
        else:
            st.warning("Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ íŒŒì¼ ëª©ë¡ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
