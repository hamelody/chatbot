import streamlit as st
# st.set_page_configëŠ” ë°˜ë“œì‹œ Streamlit ëª…ë ¹ì–´ ì¤‘ ê°€ì¥ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
st.set_page_config(
    page_title="ìœ ì•¤ìƒëª…ê³¼í•™ ì—…ë¬´ ê°€ì´ë“œ ë´‡",
    layout="centered", # ë˜ëŠ” "wide"
    initial_sidebar_state="auto" # ë˜ëŠ” "expanded", "collapsed"
)

import os
import io
import fitz # PyMuPDF
import pandas as pd
import docx
from pptx import Presentation
import faiss
import openai
import numpy as np
import json
import time
from datetime import datetime
import uuid # ê³ ìœ  ID ìƒì„±ì„ ìœ„í•´ ì¶”ê°€
from openai import AzureOpenAI, APIConnectionError, APITimeoutError, RateLimitError, APIStatusError
from azure.core.exceptions import AzureError
from azure.storage.blob import BlobServiceClient
import tempfile
from werkzeug.security import check_password_hash, generate_password_hash
import traceback
import base64
import tiktoken
import re # ì£¼ì„ ì œê±° ë˜ëŠ” ë‹¤ë¥¸ ì •ê·œì‹ ì‚¬ìš©ì„ ìœ„í•´

from streamlit_cookies_manager import EncryptedCookieManager
print("Imported streamlit_cookies_manager (EncryptedCookieManager only).")


try:
    tokenizer = tiktoken.get_encoding("o200k_base") # ìµœì‹  ëª¨ë¸ìš© ì¸ì½”ë”
    print("Tiktoken 'o200k_base' encoder loaded successfully.")
except Exception as e:
    st.error(f"Tiktoken encoder 'o200k_base' load failed: {e}. Token-based length limit may not work.")
    print(f"ERROR: Failed to load tiktoken 'o200k_base' encoder: {e}")
    try:
        tokenizer = tiktoken.get_encoding("cl100k_base") # ëŒ€ì²´ ì¸ì½”ë”
        print("Tiktoken 'cl100k_base' encoder loaded successfully as a fallback.")
    except Exception as e2:
        st.error(f"Tiktoken encoder 'cl100k_base' (fallback) load failed: {e2}. Token-based length limit may not work.")
        print(f"ERROR: Failed to load tiktoken 'cl100k_base' (fallback) encoder: {e2}")
        tokenizer = None


APP_VERSION = "1.0.7 (Chat History Deletion)" 

# --- íŒŒì¼ ê²½ë¡œ ë° ìƒìˆ˜ ì •ì˜ ---
RULES_PATH_REPO = ".streamlit/prompt_rules.txt"
COMPANY_LOGO_PATH_REPO = "company_logo.png" # ì•± ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— ë¡œê³  íŒŒì¼ ìœ„ì¹˜ ê°€ì •
INDEX_BLOB_NAME = "vector_db/vector.index"
METADATA_BLOB_NAME = "vector_db/metadata.json"
USERS_BLOB_NAME = "app_data/users.json"
UPLOAD_LOG_BLOB_NAME = "app_logs/upload_log.json"
USAGE_LOG_BLOB_NAME = "app_logs/usage_log.json"
CHAT_HISTORY_BASE_PATH = "chat_histories/" # ì‚¬ìš©ìë³„ ëŒ€í™” ë‚´ì—­ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ

# --- API ë° ëª¨ë¸ ì„¤ì • ---
AZURE_OPENAI_TIMEOUT = 60.0 # Azure OpenAI API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
MODEL_MAX_INPUT_TOKENS = 128000 # ì‚¬ìš©í•˜ëŠ” LLMì˜ ìµœëŒ€ ì…ë ¥ í† í° ìˆ˜ (ì˜ˆ: gpt-4-turbo)
MODEL_MAX_OUTPUT_TOKENS = 4096 # LLMì˜ ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜ (ì¡°ì • ê°€ëŠ¥)
BUFFER_TOKENS = 500 # í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì‹œ ì—¬ìœ  í† í°
TARGET_INPUT_TOKENS_FOR_PROMPT = MODEL_MAX_INPUT_TOKENS - MODEL_MAX_OUTPUT_TOKENS - BUFFER_TOKENS
IMAGE_DESCRIPTION_MAX_TOKENS = 500 # ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì‹œ ìµœëŒ€ í† í°
EMBEDDING_BATCH_SIZE = 16 # ì„ë² ë”© ë°°ì¹˜ í¬ê¸°

# --- ëŒ€í™” ë‚´ì—­ ê´€ë ¨ í•¨ìˆ˜ ---
def get_current_user_login_id():
    user_info = st.session_state.get("user", {})
    return user_info.get("uid")

def get_user_chat_history_blob_name(user_login_id):
    if not user_login_id:
        return None
    return f"{CHAT_HISTORY_BASE_PATH}{user_login_id}_history.json"

def load_user_conversations_from_blob():
    user_login_id = get_current_user_login_id()
    if not user_login_id or not container_client:
        print(f"Cannot load chat history: User ID ('{user_login_id}') or container_client is missing.")
        return []
    blob_name = get_user_chat_history_blob_name(user_login_id)
    # load_data_from_blob í•¨ìˆ˜ëŠ” default_valueë¡œ {"conversations": []}ì™€ ìœ ì‚¬í•œ êµ¬ì¡°ë¥¼ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì • í•„ìš”
    history_data_container = load_data_from_blob(blob_name, container_client, f"chat history for {user_login_id}", default_value={"conversations": []})
    
    # history_data_containerê°€ Noneì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„ (load_data_from_blobì´ Noneì„ ë°˜í™˜í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
    if history_data_container is None:
        loaded_conversations = []
    elif isinstance(history_data_container, dict):
        loaded_conversations = history_data_container.get("conversations", [])
    elif isinstance(history_data_container, list): # ì´ì „ ë²„ì „ í˜¸í™˜ (list ìì²´ë¥¼ ì €ì¥í•œ ê²½ìš°)
        loaded_conversations = history_data_container
        print(f"Warning: Loaded chat history for user '{user_login_id}' as a direct list. à¸„à¸§à¸£à¸ˆà¸°à¹€à¸›à¹‡à¸™ dict {{'conversations': [...]}}.")
    else:
        loaded_conversations = []
        print(f"Warning: Unexpected data type for chat history for user '{user_login_id}': {type(history_data_container)}")

    print(f"Loaded {len(loaded_conversations)} conversations for user '{user_login_id}'.")
    try:
        # last_updatedê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ getì˜ ë‘ ë²ˆì§¸ ì¸ìë¡œ ê¸°ë³¸ê°’ ì œê³µ
        loaded_conversations.sort(key=lambda x: x.get("last_updated", x.get("timestamp", "1970-01-01T00:00:00")), reverse=True)
    except Exception as e_sort:
        print(f"Error sorting conversations for user '{user_login_id}': {e_sort}")
    return loaded_conversations


def save_user_conversations_to_blob():
    user_login_id = get_current_user_login_id()
    if not user_login_id or not container_client or "all_user_conversations" not in st.session_state:
        print(f"Cannot save chat history: User ID ('{user_login_id}'), container_client, or all_user_conversations missing.")
        return False
    
    # ì €ì¥ ì „ ìµœì‹ ìˆœìœ¼ë¡œ ë‹¤ì‹œ ì •ë ¬ (last_updated ê¸°ì¤€)
    try:
        st.session_state.all_user_conversations.sort(key=lambda x: x.get("last_updated", x.get("timestamp", "1970-01-01T00:00:00")), reverse=True)
    except Exception as e_sort_save:
        print(f"Error sorting conversations before saving for user '{user_login_id}': {e_sort_save}")

    blob_name = get_user_chat_history_blob_name(user_login_id)
    print(f"Saving {len(st.session_state.all_user_conversations)} conversations for user '{user_login_id}' to {blob_name}.")
    return save_data_to_blob({"conversations": st.session_state.all_user_conversations}, blob_name, container_client, f"chat history for {user_login_id}")

def generate_conversation_title(messages_list):
    if not messages_list:
        return "ë¹ˆ ëŒ€í™”"
    for msg in messages_list:
        if msg.get("role") == "user" and msg.get("content","").strip():
            # "(ì²¨ë¶€ íŒŒì¼: ...)" ë¶€ë¶„ ì œì™¸
            title_candidate = msg["content"].split("\n(ì²¨ë¶€ íŒŒì¼:")[0].strip()
            # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            return title_candidate[:30] + "..." if len(title_candidate) > 30 else title_candidate
    return "ëŒ€í™” ì‹œì‘" # ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ì—†ëŠ” ê²½ìš°

def archive_current_chat_session_if_needed():
    user_login_id = get_current_user_login_id()
    # í˜„ì¬ ë©”ì‹œì§€ê°€ ì—†ê±°ë‚˜, ì‚¬ìš©ìê°€ ì—†ìœ¼ë©´ ì•„ì¹´ì´ë¸Œí•  í•„ìš” ì—†ìŒ
    if not user_login_id or not st.session_state.get("current_chat_messages"):
        print("Archive check: No user ID or no current messages. Skipping archive.")
        return False # ë³€ê²½ ì—†ìŒ

    active_id = st.session_state.get("active_conversation_id")
    current_messages_copy = list(st.session_state.current_chat_messages) # í•­ìƒ ë³µì‚¬ë³¸ ì‚¬ìš©
    
    archived_or_updated = False

    if active_id: # í˜„ì¬ ë¶ˆëŸ¬ì˜¨ ëŒ€í™”ê°€ ìˆëŠ” ê²½ìš° (ì—…ë°ì´íŠ¸ ì‹œë„)
        found_and_updated = False
        for i, conv in enumerate(st.session_state.all_user_conversations):
            if conv["id"] == active_id:
                # ë©”ì‹œì§€ ë‚´ìš©ì´ ì‹¤ì œë¡œ ë³€ê²½ë˜ì—ˆëŠ”ì§€ ê°„ë‹¨íˆ í™•ì¸ (ë” ì •êµí•œ ë¹„êµë„ ê°€ëŠ¥)
                if conv["messages"] != current_messages_copy: # ë©”ì‹œì§€ ëª©ë¡ ìì²´ê°€ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    conv["messages"] = current_messages_copy
                    conv["last_updated"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    # ì œëª©ì€ ì²« ë©”ì‹œì§€ ê¸°ì¤€ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìœ¼ë¯€ë¡œ, ì¼ë°˜ì ìœ¼ë¡œëŠ” ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŒ.
                    # í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œ conv["title"] = generate_conversation_title(current_messages_copy) ì¶”ê°€ ê°€ëŠ¥
                    st.session_state.all_user_conversations[i] = conv # ë¦¬ìŠ¤íŠ¸ ë‚´ ê°ì²´ ì§ì ‘ ìˆ˜ì •ì´ ë°˜ì˜ë˜ë„ë¡
                    print(f"Archived (updated) conversation ID: {active_id}, Title: '{conv.get('title', 'N/A')}'")
                    archived_or_updated = True
                else:
                    print(f"Conversation ID: {active_id} has no changes to messages. No update to archive needed.")
                found_and_updated = True
                break
        if not found_and_updated: # active_idê°€ ìˆì—ˆì§€ë§Œ ëª©ë¡ì— ì—†ëŠ” ì´ìƒí•œ ê²½ìš° (ìƒˆ ëŒ€í™”ë¡œ ì²˜ë¦¬)
             print(f"Warning: active_conversation_id '{active_id}' not found in conversation log. Treating as new chat for archiving.")
             active_id = None # ìƒˆ ëŒ€í™”ë¡œ ì·¨ê¸‰í•˜ë„ë¡ active_id ì´ˆê¸°í™”
    
    # active_idê°€ Noneì´ê±°ë‚˜, ìœ„ì—ì„œ Noneìœ¼ë¡œ ë°”ë€ ê²½ìš° (ì¦‰, ìƒˆ ëŒ€í™”ë¡œ ì·¨ê¸‰)
    if not active_id : 
        # current_chat_messagesê°€ ì‹¤ì œë¡œ ë‚´ìš©ì´ ìˆì–´ì•¼ ìƒˆ ëŒ€í™”ë¡œ ì €ì¥
        if current_messages_copy: 
            new_conv_id = str(uuid.uuid4()) # ê³ ìœ  ID ìƒì„±
            title = generate_conversation_title(current_messages_copy)
            # ì²« ë©”ì‹œì§€ ì‹œê°„ ë˜ëŠ” í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ëŒ€í‘œ ì‹œê°„ ì„¤ì •
            timestamp_str = current_messages_copy[0].get("time") if current_messages_copy and current_messages_copy[0].get("time") else datetime.now().strftime("%Y-%m-%d %H:%M")

            new_conversation = {
                "id": new_conv_id,
                "title": title,
                "timestamp": timestamp_str, # ëŒ€í™” ì‹œì‘ ì‹œì  (ì²« ë©”ì‹œì§€ ì‹œê°„ ë˜ëŠ” ìƒì„± ì‹œê°„)
                "messages": current_messages_copy,
                "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            st.session_state.all_user_conversations.insert(0, new_conversation) # ìµœì‹  ëŒ€í™”ë¥¼ ë§¨ ì•ì— ì¶”ê°€
            # ìƒˆ ëŒ€í™”ê°€ ì €ì¥ë˜ì—ˆìœ¼ë¯€ë¡œ, ì´ì œ ì´ ëŒ€í™”ê°€ "í™œì„±" ëŒ€í™”ê°€ ë¨ (IDë¥¼ ë¶€ì—¬ë°›ì•˜ìŒ)
            # í•˜ì§€ë§Œ ì´ í•¨ìˆ˜ëŠ” ë³´í†µ ì»¨í…ìŠ¤íŠ¸ ì „í™˜ ì§ì „ì— í˜¸ì¶œë˜ë¯€ë¡œ, ì´ í•¨ìˆ˜ ë‚´ì—ì„œ active_idë¥¼ ë°”ê¾¸ëŠ” ê²ƒì€
            # í˜¸ì¶œí•œ ìª½ì˜ ë¡œì§ê³¼ ê¼¬ì¼ ìˆ˜ ìˆìŒ. í˜¸ì¶œí•œ ìª½ì—ì„œ active_idë¥¼ ê´€ë¦¬í•˜ë„ë¡ ë‘ .
            print(f"Archived (new) conversation ID: {new_conv_id}, Title: '{title}'")
            archived_or_updated = True
        else: # current_messages_copyê°€ ë¹„ì–´ìˆìœ¼ë©´ ìƒˆ ëŒ€í™”ë¡œ ì €ì¥í•  ë‚´ìš© ì—†ìŒ
             print("Archive check: Current messages empty and no active_id. Skipping archive of new chat.")


    if archived_or_updated: # ì‹¤ì œ ë³€ê²½/ì¶”ê°€ê°€ ìˆì—ˆë˜ ê²½ìš°ì—ë§Œ ì €ì¥
        save_user_conversations_to_blob()
    
    return archived_or_updated # ë³€ê²½ì´ ìˆì—ˆëŠ”ì§€ ì—¬ë¶€ ë°˜í™˜
# --- END ëŒ€í™” ë‚´ì—­ ê´€ë ¨ í•¨ìˆ˜ ---

def get_base64_of_bin_file(bin_file_path):
    try:
        with open(bin_file_path, 'rb') as f:
            data = f.read()
        return base64.b64encode(data).decode()
    except FileNotFoundError:
        print(f"ERROR: Logo file not found: {bin_file_path}")
        return None
    except Exception as e:
        print(f"ERROR: Processing logo file '{bin_file_path}': {e}")
        return None

def get_logo_and_version_html(app_version_str):
    logo_html_part = ""
    company_name_default = '<span class="version-text" style="font-weight:bold; font-size: 1.5em;">ìœ ì•¤ìƒëª…ê³¼í•™</span>'
    
    if os.path.exists(COMPANY_LOGO_PATH_REPO):
        logo_b64 = get_base64_of_bin_file(COMPANY_LOGO_PATH_REPO)
        if logo_b64:
            logo_html_part = f'<img src="data:image/png;base64,{logo_b64}" class="logo-image" width="150" style="vertical-align: middle;">'
        else:
            logo_html_part = company_name_default
    else:
        print(f"WARNING: Company logo file not found at {COMPANY_LOGO_PATH_REPO}")
        logo_html_part = company_name_default
        
    return f"""
        {logo_html_part}
        <span class="version-text" style="vertical-align: middle; margin-left: 10px;">{app_version_str}</span>
    """

st.markdown("""
<style>
    /* ê¸°ë³¸ CSS ìŠ¤íƒ€ì¼ */
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button {
        background-color: #FFFFFF; color: #333F48; border: 1px solid #BCC0C4;
        border-radius: 8px; padding: 8px 12px; font-weight: 500;
        width: auto; min-width: 100px; white-space: nowrap; display: inline-block;
        transition: background-color 0.3s ease, border-color 0.3s ease;
    }
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button:hover {
        background-color: #F0F2F5; border-color: #A0A4A8;
    }
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button:active {
        background-color: #E0E2E5;
    }
    .chat-bubble-container { display: flex; flex-direction: column; margin-bottom: 15px; }
    .user-align { align-items: flex-end; }
    .assistant-align { align-items: flex-start; }
    .bubble { padding: 10px 15px; border-radius: 18px; max-width: 75%; word-wrap: break-word; display: inline-block; color: black; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.08); position: relative; }
    .user-bubble { background-color: #90EE90; color: black; border-bottom-right-radius: 5px; }
    .assistant-bubble { background-color: #E9E9EB; border-bottom-left-radius: 5px; }
    .timestamp { font-size: 0.7rem; color: #8E8E93; padding: 2px 5px 0px 5px; }
    
    /* ë©”ì¸ ì•± ì œëª© ë° ë¶€ì œëª© (ë¡œê·¸ì¸ í›„) */
    .main-app-title-container { text-align: center; margin-bottom: 24px; }
    .main-app-title { font-size: 2.1rem; font-weight: bold; display: block; }
    .main-app-subtitle { font-size: 0.9rem; color: gray; display: block; margin-top: 4px;}
    
    /* ë¡œê³  ë° ë²„ì „ */
    .logo-container { display: flex; align-items: center; }
    .logo-image { margin-right: 10px; }
    .version-text { font-size: 0.9rem; color: gray; }

    /* ë¡œê·¸ì¸ í™”ë©´ ì „ìš© ì œëª© ìŠ¤íƒ€ì¼ */
    .login-page-header-container { text-align: center; margin-top: 10px; margin-bottom: 10px;}
    .login-page-main-title { font-size: 1.8rem; font-weight: bold; display: block; color: #333F48; } 
    .login-page-sub-title { font-size: 0.85rem; color: gray; display: block; margin-top: 2px; margin-bottom: 20px;}
    .login-form-title { 
        font-size: 1.6rem; 
        font-weight: bold;
        text-align: center;
        margin-top: 10px; 
        margin-bottom: 25px; 
    }

    /* ëª¨ë°”ì¼ í™”ë©´ ëŒ€ì‘ */
    @media (max-width: 768px) {
        .main-app-title { font-size: 1.8rem; }
        .main-app-subtitle { font-size: 0.8rem; }
        .login-page-main-title { font-size: 1.5rem; }
        .login-page-sub-title { font-size: 0.8rem; }
        .login-form-title { font-size: 1.3rem; margin-bottom: 20px; }
        .stButton>button { font-size: 0.9rem !important; } /* ì‚¬ì´ë“œë°” ë²„íŠ¼ ë“± ëª¨ë°”ì¼ í¬ê¸° ì¡°ì • */
    }
    /* ì‚¬ì´ë“œë°” ë²„íŠ¼ ìŠ¤íƒ€ì¼ ë¯¸ì„¸ ì¡°ì • */
    .stButton>button { 
        text-align: left !important; 
        display: block !important; 
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def get_azure_openai_client_cached():
    print("Attempting to initialize Azure OpenAI client...")
    try:
        api_version_to_use = st.secrets.get("AZURE_OPENAI_VERSION", "2024-02-15-preview")
        print(f"DEBUG: Initializing AzureOpenAI client with API version: {api_version_to_use}")
        client = AzureOpenAI(
            api_key=st.secrets["AZURE_OPENAI_KEY"],
            azure_endpoint=st.secrets["AZURE_OPENAI_ENDPOINT"],
            api_version=api_version_to_use,
            timeout=AZURE_OPENAI_TIMEOUT
        )
        print("Azure OpenAI client initialized successfully.")
        return client
    except KeyError as e:
        st.error(f"Azure OpenAI config error: Missing key '{e.args[0]}' in secrets.")
        print(f"ERROR: Missing Azure OpenAI secret: {e.args[0]}")
        return None
    except Exception as e:
        st.error(f"Error initializing Azure OpenAI client: {e}.")
        print(f"ERROR: Azure OpenAI client initialization failed: {e}\n{traceback.format_exc()}")
        return None

@st.cache_resource
def get_azure_blob_clients_cached():
    print("Attempting to initialize Azure Blob Service client...")
    try:
        conn_str = st.secrets["AZURE_BLOB_CONN"]
        blob_service_client = BlobServiceClient.from_connection_string(conn_str, connection_timeout=60, read_timeout=120)
        container_name = st.secrets["BLOB_CONTAINER"]
        container_client = blob_service_client.get_container_client(container_name)
        print(f"Azure Blob Service client and container client for '{container_name}' initialized successfully.")
        return blob_service_client, container_client
    except KeyError as e:
        st.error(f"Azure Blob Storage config error: Missing key '{e.args[0]}' in secrets.")
        print(f"ERROR: Missing Azure Blob Storage secret: {e.args[0]}")
        return None, None
    except Exception as e:
        st.error(f"Error initializing Azure Blob client: {e}.")
        print(f"ERROR: Azure Blob client initialization failed: {e}\n{traceback.format_exc()}")
        return None, None

openai_client = get_azure_openai_client_cached()
blob_service, container_client = get_azure_blob_clients_cached()

EMBEDDING_MODEL = None
if openai_client:
    try:
        EMBEDDING_MODEL = st.secrets["AZURE_OPENAI_EMBEDDING_DEPLOYMENT"]
        print(f"Embedding model set to: {EMBEDDING_MODEL}")
    except KeyError:
        st.error("Missing 'AZURE_OPENAI_EMBEDDING_DEPLOYMENT' in secrets.")
        print("ERROR: Missing AZURE_OPENAI_EMBEDDING_DEPLOYMENT secret.")
        openai_client = None # í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© ë¶ˆê°€ ì²˜ë¦¬
    except Exception as e:
        st.error(f"Error loading embedding model config: {e}")
        print(f"ERROR: Loading AZURE_OPENAI_EMBEDDING_DEPLOYMENT secret: {e}")
        openai_client = None # í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© ë¶ˆê°€ ì²˜ë¦¬


def load_data_from_blob(blob_name, _container_client, data_description="data", default_value=None):
    if not _container_client:
        print(f"ERROR: Blob Container client is None for load_data_from_blob ('{data_description}'). Returning default.")
        return default_value if default_value is not None else ({} if not isinstance(default_value, list) else [])
    
    print(f"Attempting to load '{data_description}' from Blob: '{blob_name}'")
    try:
        blob_client_instance = _container_client.get_blob_client(blob_name)
        if blob_client_instance.exists():
            with tempfile.TemporaryDirectory() as tmpdir:
                local_temp_path = os.path.join(tmpdir, os.path.basename(blob_name))
                with open(local_temp_path, "wb") as download_file:
                    download_stream = blob_client_instance.download_blob(timeout=60)
                    download_file.write(download_stream.readall())
                
                if os.path.getsize(local_temp_path) > 0:
                    with open(local_temp_path, "r", encoding="utf-8") as f:
                        loaded_data = json.load(f)
                    print(f"Successfully loaded '{data_description}' from Blob: '{blob_name}'")
                    return loaded_data
                else: # íŒŒì¼ì€ ì¡´ì¬í•˜ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°
                    print(f"WARNING: '{data_description}' file '{blob_name}' exists in Blob but is empty. Returning default.")
                    return default_value if default_value is not None else ({} if not isinstance(default_value, list) else [])
        else: # íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
            print(f"WARNING: '{data_description}' file '{blob_name}' not found in Blob Storage. Returning default.")
            return default_value if default_value is not None else ({} if not isinstance(default_value, list) else [])
    except json.JSONDecodeError: # JSON íŒŒì‹± ì˜¤ë¥˜
        print(f"ERROR: Failed to decode JSON for '{data_description}' from Blob '{blob_name}'. Returning default.")
        st.warning(f"File '{data_description}' ({blob_name}) is corrupted or not valid JSON. Using default.")
        return default_value if default_value is not None else ({} if not isinstance(default_value, list) else [])
    except AzureError as ae: # Azure ê´€ë ¨ ì˜¤ë¥˜
        print(f"AZURE ERROR loading '{data_description}' from Blob '{blob_name}': {ae}\n{traceback.format_exc()}")
        st.warning(f"Azure service error loading '{data_description}': {ae}. Using default.")
        return default_value if default_value is not None else ({} if not isinstance(default_value, list) else [])
    except Exception as e: # ê¸°íƒ€ ëª¨ë“  ì˜¤ë¥˜
        print(f"GENERAL ERROR loading '{data_description}' from Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        st.warning(f"Unknown error loading '{data_description}': {e}. Using default.")
        return default_value if default_value is not None else ({} if not isinstance(default_value, list) else [])

def save_data_to_blob(data_to_save, blob_name, _container_client, data_description="data"):
    if not _container_client:
        # st.error(f"Cannot save '{data_description}': Azure Blob client not ready.") # UI ì˜¤ë¥˜ ìµœì†Œí™”
        print(f"ERROR: Blob Container client is None, cannot save '{data_description}' to '{blob_name}'.")
        return False
    try:
        # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ì¸ì§€ í™•ì¸ (dict ë˜ëŠ” list)
        if not isinstance(data_to_save, (dict, list)):
            # st.error(f"Save failed for '{data_description}': Data is not JSON serializable (type: {type(data_to_save)}).")
            print(f"ERROR: Data for '{blob_name}' is not JSON serializable (type: {type(data_to_save)}).")
            return False
            
        with tempfile.TemporaryDirectory() as tmpdir:
            local_temp_path = os.path.join(tmpdir, os.path.basename(blob_name))
            with open(local_temp_path, "w", encoding="utf-8") as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
            
            blob_client_instance = _container_client.get_blob_client(blob_name)
            with open(local_temp_path, "rb") as data_stream:
                blob_client_instance.upload_blob(data_stream, overwrite=True, timeout=60)
            print(f"Successfully saved '{data_description}' to Blob: '{blob_name}'")
        return True
    except AzureError as ae:
        # st.error(f"Azure service error saving '{data_description}' to Blob: {ae}")
        print(f"AZURE ERROR saving '{data_description}' to Blob '{blob_name}': {ae}\n{traceback.format_exc()}")
        return False
    except Exception as e:
        # st.error(f"Unknown error saving '{data_description}' to Blob: {e}")
        print(f"GENERAL ERROR saving '{data_description}' to Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        return False

def save_binary_data_to_blob(local_file_path, blob_name, _container_client, data_description="binary data"):
    if not _container_client:
        # st.error(f"Cannot save binary '{data_description}': Azure Blob client not ready.")
        print(f"ERROR: Blob Container client is None, cannot save binary '{blob_name}'.")
        return False
    if not os.path.exists(local_file_path):
        # st.error(f"Local file for binary '{data_description}' not found: '{local_file_path}'")
        print(f"ERROR: Local file for binary data not found: '{local_file_path}'")
        return False
    try:
        blob_client_instance = _container_client.get_blob_client(blob_name)
        with open(local_file_path, "rb") as data_stream:
            blob_client_instance.upload_blob(data_stream, overwrite=True, timeout=120) # ë°”ì´ë„ˆë¦¬ íŒŒì¼ì€ íƒ€ì„ì•„ì›ƒ ê¸¸ê²Œ
        print(f"Successfully saved binary '{data_description}' to Blob: '{blob_name}'")
        return True
    except AzureError as ae:
        # st.error(f"Azure service error saving binary '{data_description}' to Blob: {ae}")
        print(f"AZURE ERROR saving binary '{data_description}' to Blob '{blob_name}': {ae}\n{traceback.format_exc()}")
        return False
    except Exception as e:
        # st.error(f"Unknown error saving binary '{data_description}' to Blob: {e}")
        print(f"GENERAL ERROR saving binary '{data_description}' to Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        return False

USERS = {}
if container_client:
    USERS = load_data_from_blob(USERS_BLOB_NAME, container_client, "user info", default_value={})
    if not isinstance(USERS, dict) : # ë¡œë“œëœ ë°ì´í„°ê°€ dictê°€ ì•„ë‹ˆë©´ ì´ˆê¸°í™”
        print(f"ERROR: USERS loaded from blob is not a dict ({type(USERS)}). Re-initializing.")
        USERS = {}
    if "admin" not in USERS: # admin ê³„ì •ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±
        print(f"'{USERS_BLOB_NAME}' from Blob is empty or admin is missing. Creating default admin.")
        admin_password = st.secrets.get("ADMIN_PASSWORD", "diteam_fallback_secret") # ADMIN_PASSWORD secretsì—ì„œ ê°€ì ¸ì˜¤ê¸°
        USERS["admin"] = {
            "name": "ê´€ë¦¬ì", "department": "í’ˆì§ˆë³´ì¦íŒ€", "uid": "admin", # uid í•„ë“œ ì¶”ê°€
            "password_hash": generate_password_hash(admin_password),
            "approved": True, "role": "admin"
        }
        if not save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "initial user info with default admin"):
             st.warning("Failed to save default admin info to Blob. Will retry on next user data save.") # UI ê²½ê³ 
else: # Blob í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨ ì‹œ
    st.error("Azure Blob Storage connection failed. Cannot initialize user info. App may not function correctly.")
    print("CRITICAL: Cannot initialize USERS due to Blob client failure.")
    USERS = {"admin": {"name": "ê´€ë¦¬ì(ì—°ê²°ì‹¤íŒ¨)", "department": "ì‹œìŠ¤í…œ", "uid":"admin", "password_hash": generate_password_hash("fallback"), "approved": True, "role": "admin"}}


cookies = None
cookie_manager_ready = False # ì „ì—­ ë³€ìˆ˜ì²˜ëŸ¼ ì‚¬ìš©ë  ì¿ í‚¤ ë§¤ë‹ˆì € ì¤€ë¹„ ìƒíƒœ
print(f"Attempting to load COOKIE_SECRET from st.secrets...")
try:
    cookie_secret_key = st.secrets.get("COOKIE_SECRET")
    if not cookie_secret_key:
        # st.error("'COOKIE_SECRET' is not set or empty in st.secrets.") # ë¡œê·¸ì¸ ì „ UI ì˜¤ë¥˜ ìµœì†Œí™”
        print("ERROR: COOKIE_SECRET is not set or empty in st.secrets.")
    else:
        cookies = EncryptedCookieManager(
            prefix="gmp_chatbot_v1.0.7_cookie/", # ì¿ í‚¤ prefix ë³€ê²½ (ë²„ì „ì—… ë° ê¸°ëŠ¥ëª…ì‹œ)
            password=cookie_secret_key
        )
        print("CookieManager object created. Readiness will be checked before use.")
except Exception as e:
    # st.error(f"Unknown error creating cookie manager object: {e}") # ë¡œê·¸ì¸ ì „ UI ì˜¤ë¥˜ ìµœì†Œí™”
    print(f"CRITICAL: CookieManager object creation error: {e}\n{traceback.format_exc()}")
    cookies = None # ì¿ í‚¤ ê°ì²´ ìƒì„± ì‹¤íŒ¨ ì‹œ Noneìœ¼ë¡œ ì„¤ì •

SESSION_TIMEOUT = 1800 # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ê¸°ë³¸ê°’ (30ë¶„)
try:
    session_timeout_secret = st.secrets.get("SESSION_TIMEOUT")
    if session_timeout_secret: SESSION_TIMEOUT = int(session_timeout_secret)
    print(f"Session timeout set to: {SESSION_TIMEOUT} seconds.")
except (ValueError, TypeError):
    print(f"WARNING: SESSION_TIMEOUT in secrets ('{session_timeout_secret}') is not a valid integer. Using default {SESSION_TIMEOUT}s.")
except Exception as e:
     print(f"WARNING: Error reading SESSION_TIMEOUT from secrets: {e}. Using default {SESSION_TIMEOUT}s.")

# --- Session State ì´ˆê¸°í™” ---
session_keys_defaults = {
    "authenticated": False, "user": {},
    "current_chat_messages": [], "all_user_conversations": [],
    "active_conversation_id": None, "show_uploader": False,
    "pending_delete_conv_id": None # ëŒ€í™” ì‚­ì œ í™•ì¸ìš© ID ì €ì¥
}
for key, default_value in session_keys_defaults.items():
    if key not in st.session_state:
        st.session_state[key] = default_value
        print(f"Initializing st.session_state['{key}'] to default.")

# --- ì¿ í‚¤ë¥¼ ì‚¬ìš©í•œ ì„¸ì…˜ ë³µì› ì‹œë„ (ì•± ì‹¤í–‰ ì´ˆê¸°) ---
if not st.session_state.get("authenticated", False) and cookies is not None:
    print("Attempting initial session restore from cookies as user is not authenticated in session_state.")
    try:
        if cookies.ready(): # ì´ ì‹œì ì— ready()ê°€ Trueì—¬ì•¼ í•¨
            cookie_manager_ready = True # Trueë¡œ ì„¤ì •!
            print("CookieManager.ready() is True for initial session restore.")
            auth_cookie_val = cookies.get("authenticated")
            print(f"Cookie 'authenticated' value for initial restore: {auth_cookie_val}")

            if auth_cookie_val == "true":
                login_time_str = cookies.get("login_time", "0")
                try: login_time = float(login_time_str if login_time_str and login_time_str.replace('.', '', 1).isdigit() else "0")
                except ValueError: login_time = 0.0
                
                if (time.time() - login_time) < SESSION_TIMEOUT:
                    user_json_cookie = cookies.get("user", "{}")
                    try:
                        user_data_from_cookie = json.loads(user_json_cookie if user_json_cookie else "{}")
                        # uidê°€ ìˆëŠ”ì§€ í™•ì¸ (ì¤‘ìš”)
                        if user_data_from_cookie and isinstance(user_data_from_cookie, dict) and "uid" in user_data_from_cookie:
                            st.session_state["user"] = user_data_from_cookie
                            st.session_state["authenticated"] = True
                            # ë¡œê·¸ì¸ ì„±ê³µ ì‹œ ëŒ€í™” ë‚´ì—­ ë¡œë“œ
                            st.session_state.all_user_conversations = load_user_conversations_from_blob() # user_idëŠ” ë‚´ë¶€ì ìœ¼ë¡œ get_current_user_login_id() ì‚¬ìš©
                            st.session_state.current_chat_messages = [] # ìƒˆ ëŒ€í™”ë¡œ ì‹œì‘
                            st.session_state.active_conversation_id = None
                            print(f"User '{user_data_from_cookie.get('name')}' session restored from cookie. Chat history loaded.")
                            # ì—¬ê¸°ì„œ st.rerun()ì„ í˜¸ì¶œí•˜ë©´ ì¿ í‚¤ ê´€ë ¨ ì»´í¬ë„ŒíŠ¸ê°€ ì•„ì§ ì™„ì „íˆ ë§ˆìš´íŠ¸ë˜ì§€ ì•Šì•„ ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥ì„± ìˆìŒ
                        else:
                            print("User data in cookie is empty, invalid, or missing uid. Clearing auth state from cookie.")
                            if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
                            st.session_state["authenticated"] = False
                    except json.JSONDecodeError:
                        print("ERROR: Failed to decode user JSON from cookie. Clearing auth state from cookie.")
                        if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
                        st.session_state["authenticated"] = False
                else: # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ
                    print("Session timeout detected from cookie. Clearing auth state and cookies.")
                    if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
                    st.session_state["authenticated"] = False
            # else: auth_cookie_valì´ "true"ê°€ ì•„ë‹ˆë©´ st.session_state["authenticated"]ëŠ” Falseë¡œ ìœ ì§€ë¨
        else: # cookies.ready() is False
            print("CookieManager.ready() is False for initial session restore. Cannot load cookies at this exact moment.")
            # cookie_manager_readyëŠ” Falseë¡œ ìœ ì§€ë¨
    except Exception as e_cookie_op_initial:
        print(f"Exception during initial cookie operations (session restore): {e_cookie_op_initial}\n{traceback.format_exc()}")
        st.session_state["authenticated"] = False # ì•ˆì „í•˜ê²Œ Falseë¡œ
        # cookie_manager_readyëŠ” Falseë¡œ ìœ ì§€ë  ìˆ˜ ìˆìŒ

# ë¡œê·¸ì¸ UI í‘œì‹œ ì „ ì¿ í‚¤ ë§¤ë‹ˆì € ì¤€ë¹„ ìƒíƒœ ìµœì¢… í™•ì¸ (ìœ„ì—ì„œ readyê°€ ì•„ë‹ˆì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
if cookies is not None and not cookie_manager_ready: # cookie_manager_readyê°€ ì—¬ì „íˆ Falseì´ë©´
    print("Checking CookieManager readiness again before login UI (if it was not ready initially)...")
    try:
        if cookies.ready():
            cookie_manager_ready = True # Trueë¡œ ì—…ë°ì´íŠ¸
            print("CookieManager became ready just before login UI (second check).")
            # ë§Œì•½ ì—¬ê¸°ì„œ readyê°€ ë˜ì—ˆê³ , ì•„ì§ ì¸ì¦ ì•ˆëœ ìƒíƒœë¼ë©´, ìœ„ ì„¸ì…˜ ë³µì› ë¡œì§ì„ í•œë²ˆ ë” ì‹œë„í•´ë³¼ ìˆ˜ ìˆìŒ.
            # í•˜ì§€ë§Œ ë³µì¡ì„±ì„ ì¤„ì´ê¸° ìœ„í•´, í˜„ì¬ëŠ” ì´ í”Œë˜ê·¸ë§Œ ì—…ë°ì´íŠ¸í•˜ê³ , ë‹¤ìŒë²ˆ rerun ì‹œ ìœ„ ë¡œì§ì´ ë‹¤ì‹œ ì‹œë„ë˜ë„ë¡ í•¨.
            # ë˜ëŠ”, ì—¬ê¸°ì„œ ëª…ì‹œì ìœ¼ë¡œ ì„¸ì…˜ ë³µì›ì„ ë‹¤ì‹œ ì‹œë„í•˜ê³  ì„±ê³µ ì‹œ st.rerun().
            # (1.0.5 ë²„ì „ì˜ "ë‘ ë²ˆì§¸ ê¸°íšŒ" ë¡œì§ì´ ì´ì™€ ìœ ì‚¬í–ˆìŒ. ì—¬ê¸°ì„œëŠ” ìš°ì„  í”Œë˜ê·¸ ì—…ë°ì´íŠ¸ì— ì§‘ì¤‘)
        else:
            print("CookieManager still not ready before login UI (second check).")
    except Exception as e_ready_login_ui:
        print(f"WARNING: cookies.ready() call just before login UI failed: {e_ready_login_ui}")


if not st.session_state.get("authenticated", False):
    # ë¡œê·¸ì¸ í™”ë©´ UI
    st.markdown("""
    <div class="login-page-header-container" style="margin-top: 80px;"> 
      <span class="login-page-main-title">ìœ ì•¤ìƒëª…ê³¼í•™ GMP/SOP ì—…ë¬´ ê°€ì´ë“œ ë´‡</span>
      <span class="login-page-sub-title">Made by DI.PART</span>
    </div>
    """, unsafe_allow_html=True)
    st.markdown('<p class="login-form-title">ğŸ” ë¡œê·¸ì¸ ë˜ëŠ” íšŒì›ê°€ì…</p>', unsafe_allow_html=True)

    if cookies is None or not cookie_manager_ready: # ìµœì¢…ì ìœ¼ë¡œ ì¿ í‚¤ ë§¤ë‹ˆì € ìƒíƒœ í™•ì¸ í›„ ê²½ê³ 
        st.warning("ì¿ í‚¤ ì‹œìŠ¤í…œì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¡œê·¸ì¸ì´ ìœ ì§€ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ìƒˆë¡œê³ ì¹¨ í•´ë³´ì„¸ìš”.")

    with st.form("auth_form_v1.0.7_delete", clear_on_submit=False):
        mode = st.radio("ì„ íƒ", ["ë¡œê·¸ì¸", "íšŒì›ê°€ì…"], key="auth_mode_v1.0.7_delete")
        # form ë‚´ë¶€ì—ì„œëŠ” ì…ë ¥ê°’ì„ ë³€ìˆ˜ì— í• ë‹¹í•´ë„ submit ì „ê¹Œì§€ëŠ” ì™¸ë¶€ì—ì„œ ì‚¬ìš© ë¶ˆê°€
        uid_input_form = st.text_input("ID", key="auth_uid_v1.0.7_delete")
        pwd_form = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="auth_pwd_v1.0.7_delete")
        name_form, dept_form = "", ""
        if mode == "íšŒì›ê°€ì…":
            name_form = st.text_input("ì´ë¦„", key="auth_name_v1.0.7_delete")
            dept_form = st.text_input("ë¶€ì„œ", key="auth_dept_v1.0.7_delete")
        submit_button_form = st.form_submit_button("í™•ì¸")

    if submit_button_form: # í¼ ì œì¶œ ì‹œì—ë§Œ ì•„ë˜ ë¡œì§ ì‹¤í–‰
        if not uid_input_form or not pwd_form: st.error("IDì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif mode == "íšŒì›ê°€ì…" and (not name_form or not dept_form): st.error("íšŒì›ê°€ì… ì‹œ ì´ë¦„ê³¼ ë¶€ì„œë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            if mode == "ë¡œê·¸ì¸":
                user_data_from_db = USERS.get(uid_input_form) # DB(USERS ë”•ì…”ë„ˆë¦¬)ì—ì„œ ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                if not user_data_from_db: st.error("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” IDì…ë‹ˆë‹¤.")
                elif not user_data_from_db.get("approved", False): st.warning("ê´€ë¦¬ì ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ ê³„ì •ì…ë‹ˆë‹¤.")
                elif check_password_hash(user_data_from_db["password_hash"], pwd_form):
                    
                    # ì„¸ì…˜ì— ì €ì¥í•  ì‚¬ìš©ì ì •ë³´ êµ¬ì„± (uid í¬í•¨)
                    session_user_data_on_login = user_data_from_db.copy()
                    session_user_data_on_login["uid"] = uid_input_form # USERS ë”•ì…”ë„ˆë¦¬ì˜ í‚¤(ë¡œê·¸ì¸ ID)ë¥¼ uidë¡œ ì €ì¥

                    st.session_state["authenticated"] = True
                    st.session_state["user"] = session_user_data_on_login
                    
                    # ë¡œê·¸ì¸ ì„±ê³µ ì‹œ ëŒ€í™” ë‚´ì—­ ë¡œë“œ ë° ìƒˆ ëŒ€í™” ì¤€ë¹„
                    st.session_state.all_user_conversations = load_user_conversations_from_blob() # user_idëŠ” ë‚´ë¶€ì ìœ¼ë¡œ get_current_user_login_id() ì‚¬ìš©
                    st.session_state.current_chat_messages = [] # ìƒˆ ëŒ€í™”ë¡œ ì‹œì‘
                    st.session_state.active_conversation_id = None
                    st.session_state.pending_delete_conv_id = None # í˜¹ì‹œ ë‚¨ì•„ìˆì„ ìˆ˜ ìˆëŠ” í”Œë˜ê·¸ ì´ˆê¸°í™”
                    print(f"Login successful for user '{uid_input_form}'. Chat history loaded. Starting new chat session.")

                    if cookies is not None and cookie_manager_ready: # ì¿ í‚¤ ë§¤ë‹ˆì € ì¤€ë¹„ë˜ì—ˆì„ ë•Œë§Œ ì¿ í‚¤ ì €ì¥
                        try:
                            cookies["authenticated"] = "true"
                            cookies["user"] = json.dumps(session_user_data_on_login) # uid í¬í•¨ëœ ì •ë³´ ì €ì¥
                            cookies["login_time"] = str(time.time())
                            cookies.save()
                            print(f"Cookies saved for user '{uid_input_form}'.")
                        except Exception as e_cookie_save_login:
                            st.warning(f"ë¡œê·¸ì¸ ì¿ í‚¤ ì €ì¥ ì¤‘ ë¬¸ì œ ë°œìƒ: {e_cookie_save_login}")
                            print(f"ERROR: Failed to save login cookies: {e_cookie_save_login}")
                    elif cookies is None:
                         st.warning("ì¿ í‚¤ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë¡œê·¸ì¸ ìƒíƒœë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë¡œê·¸ì¸ ì‹œì )")
                    elif not cookie_manager_ready:
                         st.warning("ì¿ í‚¤ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë¡œê·¸ì¸ ìƒíƒœë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë¡œê·¸ì¸ ì‹œì , not ready)")
                    
                    st.success(f"{session_user_data_on_login.get('name', uid_input_form)}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤!"); st.rerun()
                else: st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            elif mode == "íšŒì›ê°€ì…":
                if uid_input_form in USERS: st.error("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” IDì…ë‹ˆë‹¤.")
                else:
                    USERS[uid_input_form] = {"name": name_form, "department": dept_form, "uid": uid_input_form, 
                                  "password_hash": generate_password_hash(pwd_form),
                                  "approved": False, "role": "user"}
                    if not save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "user info (signup)"):
                        st.error("íšŒì› ì •ë³´ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
                        USERS.pop(uid_input_form, None) # ì €ì¥ ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
                    else:
                        st.success("íšŒì›ê°€ì… ìš”ì²­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ì ìŠ¹ì¸ í›„ ë¡œê·¸ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.stop() # ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ìëŠ” ì—¬ê¸°ì„œ ì‹¤í–‰ ì¤‘ì§€

# --- ì´í•˜ ì½”ë“œëŠ” ì¸ì¦ëœ ì‚¬ìš©ìì—ê²Œë§Œ ë³´ì„ ---
current_user_info = st.session_state.get("user", {}) # uid í¬í•¨

# --- ì‚¬ì´ë“œë°”: ì‚¬ìš©ì ì •ë³´, ìƒˆ ëŒ€í™” ë²„íŠ¼ ë° ëŒ€í™” ë‚´ì—­ ---
with st.sidebar:
    st.markdown(f"**{current_user_info.get('name', 'ì‚¬ìš©ì')}** (`{current_user_info.get('uid', 'IDì—†ìŒ')}`)")
    st.markdown(f"*{current_user_info.get('department', 'ë¶€ì„œì •ë³´ì—†ìŒ')}*")
    st.markdown("---")

    if st.button("â• ìƒˆ ëŒ€í™” ì‹œì‘", use_container_width=True, key="new_chat_button_sidebar_v7"):
        # í˜„ì¬ ëŒ€í™”ê°€ ìˆë‹¤ë©´ ì•„ì¹´ì´ë¸Œ (IDê°€ ì—†ì–´ë„ ìƒˆ ëŒ€í™”ë¡œ ì•„ì¹´ì´ë¸Œë¨)
        archive_current_chat_session_if_needed() 
        
        st.session_state.current_chat_messages = [] # í˜„ì¬ ì±„íŒ… ë©”ì‹œì§€ ë¹„ìš°ê¸°
        st.session_state.active_conversation_id = None # í™œì„± ëŒ€í™” ID ì—†ìŒ (ìƒˆ ëŒ€í™” ìƒíƒœ)
        st.session_state.pending_delete_conv_id = None # ì‚­ì œ ë³´ë¥˜ ID ì´ˆê¸°í™”
        print("New chat started by user via sidebar button.")
        st.rerun()

    st.markdown("##### ì´ì „ ëŒ€í™”")
    
    # ì‚­ì œ í™•ì¸ UI (pending_delete_conv_idê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ)
    if st.session_state.get("pending_delete_conv_id"):
        conv_id_to_delete = st.session_state.pending_delete_conv_id
        # ì‚­ì œí•  ëŒ€í™”ì˜ ì œëª© ì°¾ê¸° (ì—†ìœ¼ë©´ IDë¡œ ëŒ€ì²´)
        conv_title_to_delete = conv_id_to_delete 
        for c_del in st.session_state.all_user_conversations:
            if c_del['id'] == conv_id_to_delete:
                conv_title_to_delete = c_del.get('title', conv_id_to_delete)
                break
        
        st.sidebar.warning(f"'{conv_title_to_delete}' ëŒ€í™”ë¥¼ ì •ë§ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
        del_confirm_cols = st.sidebar.columns(2)
        if del_confirm_cols[0].button("âœ… ì˜ˆ, ì‚­ì œ", key=f"confirm_del_yes_{conv_id_to_delete}", use_container_width=True):
            # all_user_conversations ë¦¬ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ IDì˜ ëŒ€í™” ì œê±°
            st.session_state.all_user_conversations = [
                c for c in st.session_state.all_user_conversations if c['id'] != conv_id_to_delete
            ]
            save_user_conversations_to_blob() # ë³€ê²½ëœ ì „ì²´ ëª©ë¡ ì €ì¥
            
            # ë§Œì•½ í˜„ì¬ í™œì„± ëŒ€í™”ê°€ ì‚­ì œëœ ëŒ€í™”ì˜€ë‹¤ë©´, í˜„ì¬ ì±„íŒ…ì°½ ë¹„ìš°ê¸°
            if st.session_state.active_conversation_id == conv_id_to_delete:
                st.session_state.current_chat_messages = []
                st.session_state.active_conversation_id = None
            
            st.session_state.pending_delete_conv_id = None # ì‚­ì œ ë³´ë¥˜ í”Œë˜ê·¸ í•´ì œ
            st.toast(f"'{conv_title_to_delete}' ëŒ€í™”ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.", icon="ğŸ—‘ï¸")
            st.rerun()

        if del_confirm_cols[1].button("âŒ ì•„ë‹ˆìš”", key=f"confirm_del_no_{conv_id_to_delete}", use_container_width=True):
            st.session_state.pending_delete_conv_id = None # ì‚­ì œ ë³´ë¥˜ í”Œë˜ê·¸ í•´ì œ
            st.rerun()

    # ëŒ€í™” ëª©ë¡ í‘œì‹œ
    if not st.session_state.all_user_conversations:
        st.sidebar.caption("ì´ì „ ëŒ€í™” ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # all_user_conversationsëŠ” load/save ì‹œ ì´ë¯¸ last_updated ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ë¨
    # í™”ë©´ì—ëŠ” ìµœê·¼ 20ê°œ ë˜ëŠ” ì„¤ì •í•œ ê°œìˆ˜ë§Œí¼ í‘œì‹œ
    for conv_idx, conv_data in enumerate(st.session_state.all_user_conversations[:20]): 
        # ê° ëŒ€í™” ì•„ì´í…œì„ ê°€ë¡œë¡œ ë°°ì¹˜ (ì œëª©/ì‹œê°„ ë²„íŠ¼, ì‚­ì œ ì•„ì´ì½˜ ë²„íŠ¼)
        item_cols = st.sidebar.columns([0.85, 0.15]) # ë²„íŠ¼ê³¼ ì•„ì´ì½˜ ë¹„ìœ¨
        
        title_display = conv_data.get('title', f"ëŒ€í™”_{conv_data['id'][:8]}")
        # timestampëŠ” ì²« ë©”ì‹œì§€ ì‹œê°„, last_updatedëŠ” ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„. ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´
        timestamp_display = conv_data.get('last_updated', conv_data.get('timestamp','')) 
        
        button_label = f"{title_display} ({timestamp_display})"
        is_active_conversation = (st.session_state.active_conversation_id == conv_data["id"])

        # ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸° ë²„íŠ¼
        if item_cols[0].button(
            button_label, 
            key=f"load_conv_btn_{conv_data['id']}", 
            use_container_width=True, 
            type="primary" if is_active_conversation else "secondary",
            help=f"{title_display} ëŒ€í™” ë³´ê¸°"
        ):
            if not is_active_conversation: # í˜„ì¬ í™œì„± ëŒ€í™”ê°€ ì•„ë‹ ë•Œë§Œ ìƒˆë¡œ ë¡œë“œ
                # í˜„ì¬ ì§„í–‰ì¤‘ì´ë˜ ëŒ€í™”(current_chat_messages)ê°€ ìƒˆ ë‚´ìš©ì´ë©´ ì €ì¥
                archive_current_chat_session_if_needed() 
                
                st.session_state.current_chat_messages = list(conv_data["messages"]) # ëŒ€í™” ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸° (ë³µì‚¬ë³¸)
                st.session_state.active_conversation_id = conv_data["id"]
                st.session_state.pending_delete_conv_id = None # ë‹¤ë¥¸ ëŒ€í™” ì„ íƒ ì‹œ ì‚­ì œ ë³´ë¥˜ í•´ì œ
                print(f"Loaded conversation ID: {conv_data['id']}, Title: '{title_display}'")
                st.rerun()
        
        # ì‚­ì œ ì•„ì´ì½˜ ë²„íŠ¼
        if item_cols[1].button("ğŸ—‘ï¸", key=f"delete_icon_btn_{conv_data['id']}", help="ì´ ëŒ€í™” ì‚­ì œ"):
            st.session_state.pending_delete_conv_id = conv_data['id'] # ì‚­ì œ ë³´ë¥˜ ìƒíƒœë¡œ ì„¤ì •
            st.rerun() # ì‚­ì œ í™•ì¸ UIë¥¼ í‘œì‹œí•˜ê¸° ìœ„í•´ rerun

    if len(st.session_state.all_user_conversations) > 20:
        st.sidebar.caption("ë” ë§ì€ ë‚´ì—­ì€ ì „ì²´ ë³´ê¸° ê¸°ëŠ¥(ì¶”í›„ êµ¬í˜„)ì„ ì´ìš©í•´ì£¼ì„¸ìš”.")


# --- ë©”ì¸ í™”ë©´ ìƒë‹¨ ë¡œê³  ë° ë¡œê·¸ì•„ì›ƒ ë²„íŠ¼ ---
top_cols_main = st.columns([0.7, 0.3])
with top_cols_main[0]:
    main_logo_html = get_logo_and_version_html(APP_VERSION)
    st.markdown(f"""<div class="logo-container">{main_logo_html}</div>""", unsafe_allow_html=True)

with top_cols_main[1]:
    st.markdown('<div style="text-align: right;">', unsafe_allow_html=True)
    if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_button_v1.0.7_delete"):
        archive_current_chat_session_if_needed() # ë¡œê·¸ì•„ì›ƒ ì „ í˜„ì¬ ëŒ€í™” ì €ì¥
        
        # ëª¨ë“  ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëŒ€í™” ë‚´ì—­ ê´€ë ¨ í¬í•¨)
        for key_to_reset in session_keys_defaults.keys():
            if key_to_reset == "authenticated": # authenticatedëŠ” Falseë¡œ
                st.session_state[key_to_reset] = False
            elif key_to_reset == "user": # userëŠ” ë¹ˆ dictë¡œ
                st.session_state[key_to_reset] = {}
            elif isinstance(session_keys_defaults[key_to_reset], list): # ë¦¬ìŠ¤íŠ¸ íƒ€ì…ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ
                st.session_state[key_to_reset] = []
            else: # ë‚˜ë¨¸ì§€ëŠ” None ë˜ëŠ” ê¸°ë³¸ê°’ (pending_delete_conv_id ë“±)
                st.session_state[key_to_reset] = session_keys_defaults[key_to_reset]
        
        print("Logout successful. All relevant session states cleared.")
        
        if cookies is not None and cookie_manager_ready: # ì¿ í‚¤ ë§¤ë‹ˆì € ì¤€ë¹„ëœ ê²½ìš°ì—ë§Œ
            try:
                cookies["authenticated"] = "false"
                cookies["user"] = ""
                cookies["login_time"] = ""
                cookies.save()
                print("Cookies cleared on logout.")
            except Exception as e_logout_cookie:
                 print(f"ERROR: Failed to clear cookies on logout: {e_logout_cookie}")
        st.rerun()
    st.markdown('</div>', unsafe_allow_html=True)

# --- ë©”ì¸ í™”ë©´ ì•± ì œëª© ---
st.markdown("""
<div class="main-app-title-container">
  <span class="main-app-title">ìœ ì•¤ìƒëª…ê³¼í•™ GMP/SOP ì—…ë¬´ ê°€ì´ë“œ ë´‡</span>
  <span class="main-app-subtitle">Made by DI.PART</span>
</div>
""", unsafe_allow_html=True)


# --- @st.cache_resource ë° @st.cache_data í•¨ìˆ˜ë“¤ ---
@st.cache_resource
def load_vector_db_from_blob_cached(_container_client):
    if not _container_client:
        print("ERROR: Blob Container client is None for load_vector_db_from_blob_cached.")
        return faiss.IndexFlatL2(1536), []
    current_embedding_dimension = 1536
    idx, meta = faiss.IndexFlatL2(current_embedding_dimension), []
    print(f"Attempting to load vector DB from Blob: '{INDEX_BLOB_NAME}', '{METADATA_BLOB_NAME}' with dimension {current_embedding_dimension}")
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            local_index_path = os.path.join(tmpdir, os.path.basename(INDEX_BLOB_NAME))
            local_metadata_path = os.path.join(tmpdir, os.path.basename(METADATA_BLOB_NAME))

            index_blob_client = _container_client.get_blob_client(INDEX_BLOB_NAME)
            if index_blob_client.exists():
                print(f"Downloading '{INDEX_BLOB_NAME}'...")
                with open(local_index_path, "wb") as download_file:
                    download_stream = index_blob_client.download_blob(timeout=60)
                    download_file.write(download_stream.readall())
                if os.path.getsize(local_index_path) > 0:
                    try:
                        idx = faiss.read_index(local_index_path)
                        if idx.d != current_embedding_dimension:
                            print(f"WARNING: Loaded FAISS index dimension ({idx.d}) does not match expected dimension ({current_embedding_dimension}). Re-initializing.")
                            idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []
                        else:
                            print(f"'{INDEX_BLOB_NAME}' loaded successfully from Blob Storage. Dimension: {idx.d}")
                    except Exception as e_faiss_read:
                        print(f"ERROR reading FAISS index: {e_faiss_read}. Re-initializing index.")
                        idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []
                else:
                    print(f"WARNING: '{INDEX_BLOB_NAME}' is empty in Blob. Using new index."); idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []
            else:
                print(f"WARNING: '{INDEX_BLOB_NAME}' not found in Blob Storage. New index will be used/created."); idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []

            if idx is not None: # idxê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”/ë¡œë“œ ëœ ê²½ìš°
                metadata_blob_client = _container_client.get_blob_client(METADATA_BLOB_NAME)
                # ë©”íƒ€ë°ì´í„°ëŠ” ì¸ë±ìŠ¤ íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ê³  ë‚´ìš©ì´ ìˆê±°ë‚˜, DBì— ì•„ì´í…œì´ ìˆì„ ë•Œë§Œ ë¡œë“œ ì‹œë„
                if metadata_blob_client.exists() and (idx.ntotal > 0 or (index_blob_client.exists() and os.path.exists(local_index_path) and os.path.getsize(local_index_path) > 0) ):
                    print(f"Downloading '{METADATA_BLOB_NAME}'...")
                    with open(local_metadata_path, "wb") as download_file_meta:
                        download_stream_meta = metadata_blob_client.download_blob(timeout=60)
                        download_file_meta.write(download_stream_meta.readall())
                    if os.path.getsize(local_metadata_path) > 0 :
                        with open(local_metadata_path, "r", encoding="utf-8") as f_meta: meta = json.load(f_meta)
                    else: meta = []; print(f"WARNING: '{METADATA_BLOB_NAME}' is empty in Blob.")
                # ì¸ë±ìŠ¤ê°€ ìƒˆë¡­ê³  ë¹„ì–´ìˆìœ¼ë©°, ì¸ë±ìŠ¤ íŒŒì¼ë„ ì—†ëŠ” ê²½ìš° (ì™„ì „ ì´ˆê¸° ìƒíƒœ)
                elif idx.ntotal == 0 and not (index_blob_client.exists() and os.path.exists(local_index_path) and os.path.getsize(local_index_path) > 0):
                     print(f"INFO: Index is new and empty, and no existing index file in blob. Starting with empty metadata."); meta = []
                else: # ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ê±°ë‚˜, ì¸ë±ìŠ¤ëŠ” ìˆì§€ë§Œ í•´ë‹¹ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ëŠ” ë“±ì˜ ê·¸ ì™¸ ìƒí™©
                    print(f"INFO: Metadata file '{METADATA_BLOB_NAME}' not found, or index is empty/inconsistent with file. Starting with empty metadata."); meta = []

            # ë°ì´í„° ì¼ê´€ì„± ìµœì¢… ì²´í¬
            if idx is not None and idx.ntotal == 0 and len(meta) > 0: # ì¸ë±ìŠ¤ëŠ” ë¹„ì—ˆëŠ”ë° ë©”íƒ€ë°ì´í„°ë§Œ ìˆëŠ” ê²½ìš°
                print(f"INFO: FAISS index is empty (ntotal=0) but metadata is not. Clearing metadata for consistency."); meta = []
            elif idx is not None and idx.ntotal > 0 and not meta and (index_blob_client.exists() and os.path.exists(local_index_path) and os.path.getsize(local_index_path) > 0) : # ì¸ë±ìŠ¤ëŠ” ìˆëŠ”ë° ë©”íƒ€ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° (íŒŒì¼ì€ ì¡´ì¬)
                print(f"CRITICAL WARNING: FAISS index has data (ntotal={idx.ntotal}) but metadata is empty, despite index file existing. This may lead to errors.")
    except AzureError as ae:
        st.error(f"Azure service error loading vector DB from Blob: {ae}"); print(f"AZURE ERROR loading vector DB: {ae}\n{traceback.format_exc()}"); idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []
    except Exception as e:
        st.error(f"Unknown error loading vector DB from Blob: {e}"); print(f"GENERAL ERROR loading vector DB: {e}\n{traceback.format_exc()}"); idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []
    return idx, meta

index, metadata = (faiss.IndexFlatL2(1536), []) # ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
if container_client: # Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ëœ ê²½ìš°ì—ë§Œ ë¡œë“œ ì‹œë„
    index, metadata = load_vector_db_from_blob_cached(container_client)
    print(f"DEBUG: FAISS index loaded after cache. ntotal: {index.ntotal if index else 'Index is None'}, dimension: {index.d if index else 'N/A'}")
    print(f"DEBUG: Metadata loaded after cache. Length: {len(metadata) if metadata is not None else 'Metadata is None'}")
else:
    st.error("Azure Blob Storage connection failed. Cannot load vector DB. File learning/search will be limited.")
    print("CRITICAL: Cannot load vector DB due to Blob client initialization failure (main section).")

@st.cache_data
def load_prompt_rules_cached():
    default_rules = """1. ì œê³µëœ 'ë¬¸ì„œ ë‚´ìš©'ì„ ìµœìš°ì„ ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.
2. ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ê°€ ë¬¸ì„œ ë‚´ìš©ì— ëª…í™•íˆ ì—†ëŠ” ê²½ìš°, "ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•©ë‹ˆë‹¤. ì¶”ì¸¡ì„± ë‹µë³€ì€ í”¼í•©ë‹ˆë‹¤.
3. ë‹µë³€ì€ êµ¬ì²´ì ì´ê³  ëª…í™•í•´ì•¼ í•˜ë©°, ê°€ëŠ¥í•˜ë‹¤ë©´ ê´€ë ¨ ê·œì • ë²ˆí˜¸ë‚˜ ì ˆì°¨ ë‹¨ê³„ë¥¼ ì–¸ê¸‰í•©ë‹ˆë‹¤.
4. ë‹µë³€ì€ í•­ìƒ í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê²Œ ì œê³µí•©ë‹ˆë‹¤.
5. ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš°, ì •í™•í•œ ê³„ì‚° ê³¼ì •ì„ í¬í•¨í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.
6. ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼(ì´ë¯¸ì§€ í¬í•¨)ì˜ ë‚´ìš©ê³¼ ì§ˆë¬¸ì„ ì—°ê´€ì§€ì–´ ë‹µë³€í•´ì•¼ í•  ê²½ìš°, í•´ë‹¹ íŒŒì¼ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë‹µë³€ì— í™œìš©í•©ë‹ˆë‹¤. íŒŒì¼ëª…ë„ í•¨ê»˜ ì–¸ê¸‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
7. ë‹µë³€ì€ í•­ìƒ ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ì— ë¶€í•©í•˜ë„ë¡ ë…¸ë ¥í•©ë‹ˆë‹¤.
8. ë¬¸ì„œ ë‚´ìš©ì— ì—¬ëŸ¬ ê´€ë ¨ ì •ë³´ê°€ ìˆì„ ê²½ìš°, ê°€ì¥ ì¤‘ìš”í•˜ê±°ë‚˜ ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.
9. ì•ˆì „, í’ˆì§ˆ, ê·œì • ì¤€ìˆ˜ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì—ëŠ” íŠ¹íˆ ì‹ ì¤‘í•˜ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
10. ë‹µë³€ì€ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤. ë³µì¡í•œ ë‚´ìš©ì€ í•„ìš”ì‹œ ëª©ë¡ í˜•íƒœë¡œ ì œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""
    if os.path.exists(RULES_PATH_REPO):
        try:
            with open(RULES_PATH_REPO, "r", encoding="utf-8") as f: rules_content = f.read()
            print(f"Prompt rules loaded successfully from '{RULES_PATH_REPO}'.")
            return rules_content
        except Exception as e:
            # st.warning(f"Error loading '{RULES_PATH_REPO}': {e}. Using default rules defined above.") # UI ê²½ê³  ìµœì†Œí™”
            print(f"WARNING: Error loading prompt rules from '{RULES_PATH_REPO}': {e}. Using default rules defined in code.")
            return default_rules
    else:
        print(f"WARNING: Prompt rules file not found at '{RULES_PATH_REPO}'. Using default rules defined in code.")
        return default_rules
PROMPT_RULES_CONTENT = load_prompt_rules_cached()

def extract_text_from_file(uploaded_file_obj):
    ext = os.path.splitext(uploaded_file_obj.name)[1].lower()
    text_content = ""
    if ext in [".png", ".jpg", ".jpeg"]: # ì´ë¯¸ì§€ëŠ” ì—¬ê¸°ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì•ˆ í•¨
        print(f"DEBUG extract_text_from_file: Skipped image file '{uploaded_file_obj.name}' for text extraction.")
        return "" 
    try:
        uploaded_file_obj.seek(0)
        file_bytes = uploaded_file_obj.read()
        if ext == ".pdf":
            with fitz.open(stream=file_bytes, filetype="pdf") as doc: text_content = "\n".join(page.get_text() for page in doc)
        elif ext == ".docx": # í…Œì´ë¸” ì¶”ì¶œ ê°œì„  ë²„ì „
            with io.BytesIO(file_bytes) as doc_io:
                doc = docx.Document(doc_io); full_text = []
                for para in doc.paragraphs: full_text.append(para.text)
                for table_idx, table in enumerate(doc.tables):
                    table_data_text = [f"--- Table {table_idx+1} Start ---"] # í…Œì´ë¸” êµ¬ë¶„ì ì¶”ê°€
                    for row_idx, row in enumerate(table.rows):
                        row_cells_text = [cell.text.strip() for cell_idx, cell in enumerate(row.cells)]
                        table_data_text.append(" | ".join(row_cells_text)) # ì…€ êµ¬ë¶„
                    table_data_text.append(f"--- Table {table_idx+1} End ---")
                    full_text.append("\n".join(table_data_text)) # ê° í…Œì´ë¸” ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ
                text_content = "\n\n".join(full_text) # ë‹¨ë½ê³¼ í…Œì´ë¸” ë‚´ìš©ì„ í•©ì¹¨
        elif ext in (".xlsx", ".xlsm"):
            with io.BytesIO(file_bytes) as excel_io: df_dict = pd.read_excel(excel_io, sheet_name=None)
            text_content = "\n\n".join(f"--- Sheet: {name} ---\n{df.to_string(index=False)}" for name, df in df_dict.items())
        elif ext == ".csv":
            with io.BytesIO(file_bytes) as csv_io: # BytesIO ì‚¬ìš©
                try: df = pd.read_csv(csv_io)
                except UnicodeDecodeError: # UTF-8 ì‹¤íŒ¨ ì‹œ CP949 ì‹œë„
                    # BytesIOëŠ” ë‚´ë¶€ í¬ì¸í„°ë¥¼ ê°€ì§€ë¯€ë¡œ, ë‹¤ì‹œ ì½ìœ¼ë ¤ë©´ ìƒˆë¡œìš´ BytesIO ê°ì²´ë¥¼ ë§Œë“¤ê±°ë‚˜ seek(0) í•„ìš”
                    df = pd.read_csv(io.BytesIO(file_bytes), encoding='cp949') 
                text_content = df.to_string(index=False)
        elif ext == ".pptx":
            with io.BytesIO(file_bytes) as ppt_io: prs = Presentation(ppt_io); text_content = "\n".join(shape.text for slide in prs.slides for shape in slide.shapes if hasattr(shape, "text"))
        elif ext == ".txt":
            try: text_content = file_bytes.decode('utf-8')
            except UnicodeDecodeError: 
                try: text_content = file_bytes.decode('cp949')
                except Exception: text_content = file_bytes.decode('latin-1', errors='replace') # ìµœí›„ì˜ ìˆ˜ë‹¨
            except Exception as e_txt: print(f"Txt decode error: {e_txt}"); text_content = ""
        else: st.warning(f"Unsupported text file type: {ext} (File: {uploaded_file_obj.name})"); return ""
    except Exception as e: st.error(f"Error extracting text from '{uploaded_file_obj.name}': {e}"); print(f"ERROR extracting text: {e}\n{traceback.format_exc()}"); return ""
    return text_content.strip()

def save_original_file_to_blob(uploaded_file_obj, _container_client, base_path="original_files"):
    if not _container_client or not uploaded_file_obj: return None
    try:
        safe_file_name = re.sub(r'[\\/*?:"<>|]', "_", uploaded_file_obj.name)
        blob_name = f"{base_path}/{datetime.now().strftime('%Y%m%d%H%M%S')}_{safe_file_name}"
        blob_client_instance = _container_client.get_blob_client(blob_name)
        uploaded_file_obj.seek(0)
        file_bytes_for_original = uploaded_file_obj.read() # ì—¬ê¸°ì„œ íŒŒì¼ ë‚´ìš©ì„ ë‹¤ì‹œ ì½ìŒ
        with io.BytesIO(file_bytes_for_original) as data_stream:
            blob_client_instance.upload_blob(data_stream, overwrite=True, timeout=120)
        print(f"Successfully saved original file '{safe_file_name}' to Blob as '{blob_name}'"); return blob_name
    except Exception as e: print(f"ERROR saving original file to Blob ('{uploaded_file_obj.name}'): {e}"); return None

def log_openai_api_usage_to_blob(user_id, model_name, usage_object, _container_client, request_type="general_api_call"):
    if not _container_client: print(f"ERROR: Blob client None, cannot log API usage."); return False
    log_entry = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "user_id": user_id, 
        "model_name": model_name, "request_type": request_type, 
        "prompt_tokens": getattr(usage_object, 'prompt_tokens', 0), 
        "completion_tokens": getattr(usage_object, 'completion_tokens', 0), 
        "total_tokens": getattr(usage_object, 'total_tokens', 0)
    }
    try:
        current_logs = load_data_from_blob(USAGE_LOG_BLOB_NAME, _container_client, "API usage log", default_value=[])
        if not isinstance(current_logs, list): current_logs = [] # ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ì´ˆê¸°í™”
        current_logs.append(log_entry)
        if save_data_to_blob(current_logs, USAGE_LOG_BLOB_NAME, _container_client, "API usage log"):
            print(f"Successfully logged API usage for user '{user_id}'."); return True
        else:
            print(f"ERROR: Failed to save API usage log to Blob after appending new entry."); return False
    except Exception as e: print(f"GENERAL ERROR logging API usage: {e}\n{traceback.format_exc()}"); return False

def chunk_text_into_pieces(text_to_chunk, chunk_size=500): # ì²­í¬ í¬ê¸°ëŠ” í† í°ì´ ì•„ë‹Œ ê¸€ì ìˆ˜ ê¸°ë°˜
    if not text_to_chunk or not text_to_chunk.strip(): return [];
    chunks_list, current_buffer = [], ""
    for line in text_to_chunk.split("\n"): 
        stripped_line = line.strip()
        if not stripped_line and not current_buffer.strip(): continue 
        if len(current_buffer) + len(stripped_line) + 1 < chunk_size: 
            current_buffer += stripped_line + "\n"
        else: 
            if current_buffer.strip(): chunks_list.append(current_buffer.strip())
            current_buffer = stripped_line + "\n" 
    if current_buffer.strip(): chunks_list.append(current_buffer.strip())
    return [c for c in chunks_list if c] # ë‚´ìš©ì´ ìˆëŠ” ì²­í¬ë§Œ ë°˜í™˜

def get_image_description(image_bytes, image_filename, client_instance):
    if not client_instance: print("ERROR: OpenAI client not ready for image description."); return None
    print(f"DEBUG: Requesting description for image '{image_filename}'")
    try:
        base64_image = base64.b64encode(image_bytes).decode('utf-8')
        ext = os.path.splitext(image_filename)[1].lower(); 
        mime_type = "image/jpeg" if ext in [".jpg", ".jpeg"] else "image/png" if ext == ".png" else "application/octet-stream" # ê¸°ë³¸ê°’ ë³€ê²½
        vision_model = st.secrets.get("AZURE_OPENAI_DEPLOYMENT", "gpt-4-vision-preview") # secretsì— ì—†ìœ¼ë©´ ê¸°ë³¸ ëª¨ë¸ëª… ì‚¬ìš©
        
        response = client_instance.chat.completions.create(
            model=vision_model, 
            messages=[{"role": "user", "content": [
                {"type": "text", "text": f"Describe this image (filename: '{image_filename}') from a work/professional perspective. This description will be used for text-based search. Mention key objects, states, possible contexts, and any elements relevant to GMP/SOP if applicable."}, 
                {"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{base64_image}" }}
            ]}], 
            max_tokens=IMAGE_DESCRIPTION_MAX_TOKENS, temperature=0.2, timeout=AZURE_OPENAI_TIMEOUT
        )
        description = response.choices[0].message.content.strip()
        print(f"DEBUG: Image description for '{image_filename}' generated (len: {len(description)}).")
        # ì—¬ê¸°ì„œ API ì‚¬ìš©ëŸ‰ ë¡œê¹… ì¶”ê°€ ê°€ëŠ¥
        return description
    except Exception as e: 
        print(f"ERROR during image description for '{image_filename}': {e}\n{traceback.format_exc()}")
        # st.error(f"ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì˜¤ë¥˜: {e}") # UI ì˜¤ë¥˜ ìµœì†Œí™”
        return None

def get_text_embedding(text_to_embed, client=openai_client, model=EMBEDDING_MODEL):
    if not client or not model or not text_to_embed or not text_to_embed.strip(): 
        # print("Skipping embedding for empty or invalid input.") # ë„ˆë¬´ ë¹ˆë²ˆí•œ ë¡œê·¸ ë°©ì§€
        return None
    try: 
        response = client.embeddings.create(input=[text_to_embed], model=model, timeout=AZURE_OPENAI_TIMEOUT / 2)
        return response.data[0].embedding
    except Exception as e: 
        print(f"ERROR during single text embedding for text starting with '{text_to_embed[:30]}...': {e}")
        return None

def get_batch_embeddings(texts_to_embed, client=openai_client, model=EMBEDDING_MODEL, batch_size=EMBEDDING_BATCH_SIZE):
    if not client or not model or not texts_to_embed: return []
    all_embeddings = []
    for i in range(0, len(texts_to_embed), batch_size):
        batch = texts_to_embed[i:i + batch_size]; 
        if not batch: continue # ë¹ˆ ë°°ì¹˜ë©´ ê±´ë„ˆë›°ê¸°
        print(f"DEBUG: Requesting embeddings for batch of {len(batch)} texts...")
        try:
            response = client.embeddings.create(input=batch, model=model, timeout=AZURE_OPENAI_TIMEOUT)
            # ì‘ë‹µ ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ index ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            batch_embeddings = [item.embedding for item in sorted(response.data, key=lambda emb_item: emb_item.index)]
            all_embeddings.extend(batch_embeddings)
            print(f"DEBUG: Embeddings received for batch {i//batch_size + 1}.")
        except Exception as e: 
            print(f"ERROR during batch embedding for batch starting with '{batch[0][:30]}...': {e}")
            all_embeddings.extend([None] * len(batch)) # ì‹¤íŒ¨ ì‹œ Noneìœ¼ë¡œ ì±„ì›€
    return all_embeddings

def search_similar_chunks(query_text, k_results=3):
    if index is None or index.ntotal == 0 or not metadata: 
        print("Vector DB empty or not loaded. Search aborted.")
        return []
    query_vector = get_text_embedding(query_text)
    if query_vector is None: 
        print("Query embedding failed. Search aborted.")
        return []
    try:
        actual_k = min(k_results, index.ntotal); 
        if actual_k == 0 : return []
        distances, indices_found = index.search(np.array([query_vector]).astype("float32"), actual_k)
        results = []
        for idx_val in indices_found[0]:
            if 0 <= idx_val < len(metadata) and isinstance(metadata[idx_val], dict):
                 results.append({
                    "source": metadata[idx_val].get("file_name", "Unknown Source"), 
                    "content": metadata[idx_val].get("content", ""), 
                    "is_image_description": metadata[idx_val].get("is_image_description", False), 
                    "original_file_extension": metadata[idx_val].get("original_file_extension", "")
                })
            else:
                print(f"Warning: Invalid index {idx_val} from FAISS search. Metadata length: {len(metadata)}")
        return results
    except Exception as e: 
        # st.error(f"Similarity search error: {e}") # UI ì˜¤ë¥˜ ìµœì†Œí™”
        print(f"ERROR: Similarity search failed: {e}\n{traceback.format_exc()}"); return []

def add_document_to_vector_db_and_blob(uploaded_file_obj, processed_content_unused, text_chunks, _container_client, is_image_description=False):
    global index, metadata # ì „ì—­ ë³€ìˆ˜ ìˆ˜ì • ëª…ì‹œ
    if not text_chunks: st.warning(f"No content chunks to process for '{uploaded_file_obj.name}'."); return False
    if not _container_client: st.error("Cannot save learning results: Azure Blob client not ready."); return False
    
    file_type_log_desc = "image description" if is_image_description else "text document"
    print(f"Adding '{file_type_log_desc}' from '{uploaded_file_obj.name}' to vector DB.")
    
    chunk_embeddings = get_batch_embeddings(text_chunks)
    vectors_to_add, new_metadata_entries = [], []
    successful_embedding_count = 0

    for i, chunk in enumerate(text_chunks):
        embedding = chunk_embeddings[i] if i < len(chunk_embeddings) else None
        if embedding:
            vectors_to_add.append(embedding)
            new_metadata_entries.append({
                "file_name": uploaded_file_obj.name, "content": chunk, 
                "is_image_description": is_image_description, 
                "original_file_extension": os.path.splitext(uploaded_file_obj.name)[1].lower()
            })
            successful_embedding_count +=1
        else:
            print(f"Warning: Failed to get embedding for chunk {i+1} of '{uploaded_file_obj.name}'. Skipping.")

    if successful_embedding_count == 0: 
        st.error(f"No valid embeddings generated for '{uploaded_file_obj.name}'. Document not learned."); return False
    if successful_embedding_count < len(text_chunks):
        st.warning(f"Some content from '{uploaded_file_obj.name}' failed embedding. Only successful parts learned.")

    try:
        current_dim = np.array(vectors_to_add[0]).shape[0]
        if index is None or index.d != current_dim: 
            print(f"Re-initializing FAISS index. Old dim: {index.d if index else 'None'}, New dim: {current_dim}")
            index = faiss.IndexFlatL2(current_dim); metadata = []
        
        if vectors_to_add: index.add(np.array(vectors_to_add).astype("float32"))
        metadata.extend(new_metadata_entries)
        print(f"Added {len(vectors_to_add)} new chunks from '{uploaded_file_obj.name}'. Index total: {index.ntotal}, Dim: {index.d}")

        # FAISS ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° Blobì— ì €ì¥
        with tempfile.TemporaryDirectory() as tmpdir:
            temp_index_path = os.path.join(tmpdir, "temp.index")
            if index.ntotal > 0: 
                 faiss.write_index(index, temp_index_path)
                 if not save_binary_data_to_blob(temp_index_path, INDEX_BLOB_NAME, _container_client, "vector index"):
                     st.error("Failed to save vector index to Blob."); return False # ì‹¬ê°í•œ ì˜¤ë¥˜ë¡œ ê°„ì£¼
            else: print(f"Skipping saving empty index to Blob: {INDEX_BLOB_NAME}")
        
        if not save_data_to_blob(metadata, METADATA_BLOB_NAME, _container_client, "metadata"):
            st.error("Failed to save metadata to Blob."); return False # ì‹¬ê°í•œ ì˜¤ë¥˜ë¡œ ê°„ì£¼

        # ì—…ë¡œë“œ ë¡œê·¸ ê¸°ë¡
        uploader_name = st.session_state.user.get("name", "N/A")
        log_entry = {"file": uploaded_file_obj.name, "type": file_type_log_desc, "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "chunks_added": len(vectors_to_add), "uploader": uploader_name}
        upload_logs = load_data_from_blob(UPLOAD_LOG_BLOB_NAME, _container_client, "upload log", default_value=[])
        if not isinstance(upload_logs, list): upload_logs = []
        upload_logs.append(log_entry)
        if not save_data_to_blob(upload_logs, UPLOAD_LOG_BLOB_NAME, _container_client, "upload log"):
            st.warning("Failed to save upload log to Blob.") # ê²½ê³ ë§Œ í‘œì‹œ
        return True
    except Exception as e: 
        st.error(f"Error during document learning or Azure Blob upload for '{uploaded_file_obj.name}': {e}")
        print(f"ERROR: Failed to add document or upload to Blob: {e}\n{traceback.format_exc()}"); return False


# --- íƒ­ ì •ì˜ ---
chat_interface_tab, admin_settings_tab = None, None
# current_user_infoëŠ” ë¡œê·¸ì¸ ì„±ê³µ í›„ ì •ì˜ë˜ë¯€ë¡œ, íƒ­ ì •ì˜ëŠ” ê·¸ ì´í›„ ë˜ëŠ” ì—¬ê¸°ì„œ ì¡°ê±´ë¶€ë¡œ ê°€ëŠ¥
if st.session_state.authenticated and current_user_info.get("role") == "admin":
    chat_interface_tab, admin_settings_tab = st.tabs(["ğŸ’¬ ì±—ë´‡ ì§ˆë¬¸", "âš™ï¸ ê´€ë¦¬ì ì„¤ì •"])
else: # ì¼ë°˜ ì‚¬ìš©ì ë˜ëŠ” ì•„ì§ current_user_infoê°€ ì—†ì„ ê²½ìš° (ë¡œê·¸ì¸ í™”ë©´)
    chat_interface_tab = st.container() 

# --- ì±—ë´‡ ì§ˆë¬¸ ì¸í„°í˜ì´ìŠ¤ ---
if chat_interface_tab: # ì´ íƒ­ì´ í™œì„±í™”ë˜ì—ˆê±°ë‚˜, ì¼ë°˜ ì‚¬ìš©ìì˜ ê²½ìš° í•­ìƒ ì´ ë¸”ë¡ ì‹¤í–‰
    with chat_interface_tab:
        st.header("ì—…ë¬´ ì§ˆë¬¸")
        st.markdown("ğŸ’¡ ì˜ˆì‹œ: SOP ë°±ì—… ì£¼ê¸°, PIC/S Annex 11 ì°¨ì´, (íŒŒì¼ ì²¨ë¶€ í›„) ì´ ì‚¬ì§„ ì† ìƒí™©ì€ ì–´ë–¤ ê·œì •ì— í•´ë‹¹í•˜ë‚˜ìš”? ë“±")

        # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ (current_chat_messages ì‚¬ìš©)
        for msg_item in st.session_state.current_chat_messages:
            role, content, time_str = msg_item.get("role"), msg_item.get("content", ""), msg_item.get("time", "")
            align_class = "user-align" if role == "user" else "assistant-align"
            bubble_class = "user-bubble" if role == "user" else "assistant-bubble"
            st.markdown(f"""<div class="chat-bubble-container {align_class}"><div class="bubble {bubble_class}">{content}</div><div class="timestamp">{time_str}</div></div>""", unsafe_allow_html=True)

        st.markdown("<div style='height:16px'></div>", unsafe_allow_html=True) 
        
        # íŒŒì¼ ì—…ë¡œë” í† ê¸€ ë²„íŠ¼
        if st.button("ğŸ“‚ íŒŒì¼ ì²¨ë¶€/ìˆ¨ê¸°ê¸°", key="toggle_chat_uploader_v7_del"): 
            st.session_state.show_uploader = not st.session_state.get("show_uploader", False)

        chat_file_uploader_key = "chat_file_uploader_v7_del_widget" 
        uploaded_chat_file_runtime = None # í˜„ì¬ ì‹¤í–‰ì—ì„œ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼
        
        if st.session_state.get("show_uploader", False): # ì—…ë¡œë” í‘œì‹œ ìƒíƒœì´ë©´
            uploaded_chat_file_runtime = st.file_uploader("ì§ˆë¬¸ê³¼ í•¨ê»˜ ì°¸ê³ í•  íŒŒì¼ ì²¨ë¶€ (ì„ íƒ ì‚¬í•­)",
                                     type=["pdf","docx","xlsx","xlsm","csv","pptx", "txt", "png", "jpg", "jpeg"], 
                                     key=chat_file_uploader_key)
            if uploaded_chat_file_runtime: 
                st.caption(f"ì²¨ë¶€ë¨: {uploaded_chat_file_runtime.name} ({uploaded_chat_file_runtime.type}, {uploaded_chat_file_runtime.size} bytes)")
                if uploaded_chat_file_runtime.type.startswith("image/"): st.image(uploaded_chat_file_runtime, width=200)

        # ì±„íŒ… ì…ë ¥ í¼
        with st.form("chat_input_form_v7_del", clear_on_submit=True): 
            query_input_col, send_button_col = st.columns([4,1])
            with query_input_col:
                user_query_input_form = st.text_input("ì§ˆë¬¸ ì…ë ¥:", placeholder="ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...", key="user_query_text_input_v7_del", label_visibility="collapsed") 
            with send_button_col: send_query_button_form = st.form_submit_button("ì „ì†¡")

        if send_query_button_form and user_query_input_form.strip(): # ì „ì†¡ ë²„íŠ¼ ëˆŒë¦¬ê³  ë‚´ìš© ìˆìœ¼ë©´
            if not openai_client or not tokenizer: # í•„ìˆ˜ í´ë¼ì´ì–¸íŠ¸/ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
                st.error("OpenAI ì„œë¹„ìŠ¤ ë˜ëŠ” í† í¬ë‚˜ì´ì €ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."); st.stop()
            
            timestamp_now_str = datetime.now().strftime("%Y-%m-%d %H:%M")
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„± (ì²¨ë¶€ íŒŒì¼ ì •ë³´ í¬í•¨)
            user_message_content_for_display = user_query_input_form
            if uploaded_chat_file_runtime: 
                user_message_content_for_display += f"\n(ì²¨ë¶€ íŒŒì¼: {uploaded_chat_file_runtime.name})"
            
            # í˜„ì¬ ì±„íŒ… ë©”ì‹œì§€ ëª©ë¡ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.current_chat_messages.append({"role":"user", "content":user_message_content_for_display, "time":timestamp_now_str})
            
            # ë§Œì•½ í˜„ì¬ ìƒˆ ëŒ€í™” ìƒíƒœì˜€ë‹¤ë©´(active_conversation_id is None), 
            # ì´ ì‹œì ì—ì„œ ëŒ€í™” IDë¥¼ ìƒì„±í•˜ê³  all_user_conversationsì— ì„ì‹œë¡œ ì¶”ê°€í•´ë‘˜ ìˆ˜ ìˆìŒ.
            # ë˜ëŠ” archive_current_chat_session_if_needed()ê°€ í˜¸ì¶œë  ë•Œ ì²˜ë¦¬ë˜ë„ë¡ í•¨.
            # ì—¬ê¸°ì„œëŠ” ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ë³´ë‚¸ í›„, AI ë‹µë³€ê¹Œì§€ ë°›ê³  ë‚˜ì„œ ì»¨í…ìŠ¤íŠ¸ ì „í™˜ ì‹œ ì €ì¥í•˜ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼.
            
            user_name_for_log = current_user_info.get("name", "anonymous_chat_user")
            print(f"User '{user_name_for_log}' submitted query: '{user_query_input_form[:50]}...' (File: {uploaded_chat_file_runtime.name if uploaded_chat_file_runtime else 'None'})")
            
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                assistant_response_content = "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”." # ê¸°ë³¸ ì˜¤ë¥˜ ë©”ì‹œì§€
                try: 
                    print("Step 1: Preparing context and calculating tokens...")
                    context_items_for_llm_prompt = [] # LLM í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë  ì»¨í…ìŠ¤íŠ¸ ì•„ì´í…œ
                    
                    # ì±„íŒ… ì‹œ ì²¨ë¶€ íŒŒì¼ ì²˜ë¦¬
                    text_content_from_chat_file, is_chat_file_image, chat_file_source_display_name = None, False, None
                    if uploaded_chat_file_runtime:
                        file_extension_chat = os.path.splitext(uploaded_chat_file_runtime.name)[1].lower()
                        is_chat_file_image = file_extension_chat in [".png", ".jpg", ".jpeg"]
                        
                        if is_chat_file_image:
                            print(f"DEBUG Chat: Processing uploaded image '{uploaded_chat_file_runtime.name}' for description.")
                            with st.spinner(f"ì²¨ë¶€ ì´ë¯¸ì§€ '{uploaded_chat_file_runtime.name}' ë¶„ì„ ì¤‘..."):
                                image_bytes = uploaded_chat_file_runtime.getvalue()
                                description = get_image_description(image_bytes, uploaded_chat_file_runtime.name, openai_client)
                            if description:
                                text_content_from_chat_file = description
                                chat_file_source_display_name = f"ì‚¬ìš©ì ì²¨ë¶€ ì´ë¯¸ì§€: {uploaded_chat_file_runtime.name}"
                                print(f"DEBUG Chat: Image description generated (len: {len(description)}).")
                            else: st.warning(f"ì´ë¯¸ì§€ '{uploaded_chat_file_runtime.name}' ì„¤ëª…ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else: 
                            print(f"DEBUG Chat: Extracting text from uploaded file '{uploaded_chat_file_runtime.name}'.")
                            text_content_from_chat_file = extract_text_from_file(uploaded_chat_file_runtime)
                            if text_content_from_chat_file: 
                                chat_file_source_display_name = f"ì‚¬ìš©ì ì²¨ë¶€ íŒŒì¼: {uploaded_chat_file_runtime.name}"
                                print(f"DEBUG Chat: Text extracted (len: {len(text_content_from_chat_file)}).")
                            elif text_content_from_chat_file == "": st.info(f"íŒŒì¼ '{uploaded_chat_file_runtime.name}'ì´ ë¹„ì—ˆê±°ë‚˜ ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
                        if text_content_from_chat_file: 
                            context_items_for_llm_prompt.append({
                                "source": chat_file_source_display_name, "content": text_content_from_chat_file, 
                                "is_image_description": is_chat_file_image
                            })
                    
                    # í”„ë¡¬í”„íŠ¸ êµ¬ì„± ë° í† í° ê³„ì‚°
                    prompt_template_for_llm = f"{PROMPT_RULES_CONTENT}\n\në‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤:\n<ë¬¸ì„œ ì‹œì‘>\n{{context}}\n<ë¬¸ì„œ ë>"
                    base_prompt_tokens = len(tokenizer.encode(prompt_template_for_llm.replace('{context}', '')))
                    user_query_tokens = len(tokenizer.encode(user_query_input_form))
                    max_context_tokens_allowed = TARGET_INPUT_TOKENS_FOR_PROMPT - base_prompt_tokens - user_query_tokens
                    
                    final_context_string_for_llm = "í˜„ì¬ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
                    if max_context_tokens_allowed > 0:
                        query_for_vector_db_search = user_query_input_form
                        if is_chat_file_image and text_content_from_chat_file: # ì´ë¯¸ì§€ ì„¤ëª…ì´ ìˆìœ¼ë©´ ê²€ìƒ‰ ì¿¼ë¦¬ì— ì¶”ê°€
                            query_for_vector_db_search = f"{user_query_input_form}\n\nì²¨ë¶€ ì´ë¯¸ì§€ ë‚´ìš©: {text_content_from_chat_file}"
                        
                        retrieved_db_chunks = search_similar_chunks(query_for_vector_db_search, k_results=3)
                        if retrieved_db_chunks: context_items_for_llm_prompt.extend(retrieved_db_chunks)
                        
                        if context_items_for_llm_prompt:
                            unique_contents_seen = set()
                            formatted_context_segments = []
                            for item in context_items_for_llm_prompt:
                                content_segment = item.get("content","").strip()
                                if content_segment and content_segment not in unique_contents_seen:
                                    source_name = item.get('source','ì•Œ ìˆ˜ ì—†ìŒ').replace("ì‚¬ìš©ì ì²¨ë¶€ ì´ë¯¸ì§€: ","").replace("ì‚¬ìš©ì ì²¨ë¶€ íŒŒì¼: ","")
                                    prefix = "[ì´ë¯¸ì§€ ì„¤ëª…: " if item.get("is_image_description") else "[ì¶œì²˜ ë¬¸ì„œ: "
                                    formatted_context_segments.append(f"{prefix}{source_name}]\n{content_segment}")
                                    unique_contents_seen.add(content_segment)
                            
                            if formatted_context_segments:
                                combined_context_str = "\n\n---\n\n".join(formatted_context_segments)
                                encoded_combined_context = tokenizer.encode(combined_context_str)
                                if len(encoded_combined_context) > max_context_tokens_allowed:
                                    truncated_tokens_for_context = encoded_combined_context[:max_context_tokens_allowed]
                                    final_context_string_for_llm = tokenizer.decode(truncated_tokens_for_context)
                                    if len(encoded_combined_context) > len(truncated_tokens_for_context):
                                        final_context_string_for_llm += "\n(...ë¬¸ì„œ ë‚´ìš©ì´ ê¸¸ì–´ ì¼ë¶€ ì˜ë ¸ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)"
                                else: final_context_string_for_llm = combined_context_str
                    
                    system_prompt_final = prompt_template_for_llm.replace('{context}', final_context_string_for_llm)
                    total_input_tokens = len(tokenizer.encode(system_prompt_final)) + user_query_tokens
                    if total_input_tokens > MODEL_MAX_INPUT_TOKENS: 
                        print(f"CRITICAL WARNING: Total input tokens ({total_input_tokens}) exceed model max ({MODEL_MAX_INPUT_TOKENS})!")
                    
                    api_messages_to_send = [{"role":"system", "content": system_prompt_final}, {"role":"user", "content": user_query_input_form}]
                    print("Step 2: Sending request to Azure OpenAI for chat completion...")
                    
                    chat_model_deployment_name = st.secrets.get("AZURE_OPENAI_DEPLOYMENT")
                    if not chat_model_deployment_name:
                        st.error("ì±„íŒ… ëª¨ë¸ ë°°í¬ ì´ë¦„('AZURE_OPENAI_DEPLOYMENT')ì´ secretsì— ì—†ìŠµë‹ˆë‹¤."); raise ValueError("Chat model name missing.")
                        
                    chat_completion_result = openai_client.chat.completions.create(
                        model=chat_model_deployment_name, messages=api_messages_to_send,
                        max_tokens=MODEL_MAX_OUTPUT_TOKENS, temperature=0.1, timeout=AZURE_OPENAI_TIMEOUT
                    )
                    assistant_response_content = chat_completion_result.choices[0].message.content.strip()
                    print("Azure OpenAI response received.")

                    if chat_completion_result.usage and container_client:
                        log_openai_api_usage_to_blob(user_name_for_log, chat_model_deployment_name, chat_completion_result.usage, container_client, request_type="chat_completion_with_rag")
                
                except Exception as gen_err: 
                    assistant_response_content = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {gen_err}."
                    st.error(assistant_response_content) # UIì— ì˜¤ë¥˜ í‘œì‹œ
                    print(f"UNEXPECTED ERROR during response generation: {gen_err}\n{traceback.format_exc()}")

            st.session_state.current_chat_messages.append({"role":"assistant", "content":assistant_response_content, "time":timestamp_now_str})
            # ë‹µë³€ í›„ í˜„ì¬ ëŒ€í™”ê°€ ìƒˆ ëŒ€í™”ì˜€ìœ¼ë©´ IDë¥¼ ë¶€ì—¬í•˜ê³  ì €ì¥í•  ì¤€ë¹„ (ì‹¤ì œ ì €ì¥ì€ ì»¨í…ìŠ¤íŠ¸ ì „í™˜ ì‹œ)
            if st.session_state.active_conversation_id is None and st.session_state.current_chat_messages:
                # archive_current_chat_session_if_needed() í•¨ìˆ˜ê°€ í˜¸ì¶œë  ë•Œ ìƒˆ IDê°€ í• ë‹¹ë˜ê³  ì €ì¥ë¨.
                # ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ê³„ì† ë³´ë‚´ëŠ” ë™ì•ˆì€ active_idëŠ” Noneìœ¼ë¡œ ìœ ì§€ë  ìˆ˜ ìˆìœ¼ë©°,
                # ìƒˆ ëŒ€í™” ì‹œì‘ / ë‹¤ë¥¸ ëŒ€í™” ë¡œë“œ / ë¡œê·¸ì•„ì›ƒ ì‹œ ì•„ì¹´ì´ë¸Œ í•¨ìˆ˜ê°€ í˜¸ì¶œë˜ë©´ì„œ IDê°€ ë¶€ì—¬ë˜ê³  ì €ì¥ë¨.
                # ë§Œì•½, ì²« ì‘ë‹µ ì§í›„ ë°”ë¡œ all_user_conversationsì— ë°˜ì˜í•˜ê³  ì‹¶ë‹¤ë©´ ì—¬ê¸°ì„œ archive í•¨ìˆ˜ í˜¸ì¶œ í•„ìš”.
                # ì§€ê¸ˆì€ archive í•¨ìˆ˜ê°€ ì»¨í…ìŠ¤íŠ¸ ì „í™˜ ì‹œì ì— í˜¸ì¶œë˜ë„ë¡ ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” íŠ¹ë³„í•œ ì²˜ë¦¬ ì•ˆí•¨.
                pass
            
            print("Response processing complete. Triggering rerun to display new messages."); st.rerun()

# --- ê´€ë¦¬ì ì„¤ì • íƒ­ ---
if admin_settings_tab: # admin_settings_tabì´ Noneì´ ì•„ë‹ˆê³ , í˜„ì¬ í™œì„±í™”ëœ íƒ­ì¼ ë•Œ (st.tabs ì‚¬ìš© ì‹œ ìë™ ì²˜ë¦¬)
    with admin_settings_tab:
        st.header("âš™ï¸ ê´€ë¦¬ì ì„¤ì •")
        # ê°€ì… ìŠ¹ì¸ ëŒ€ê¸°ì
        st.subheader("ğŸ‘¥ ê°€ì… ìŠ¹ì¸ ëŒ€ê¸°ì")
        if not USERS or not isinstance(USERS, dict): st.warning("ì‚¬ìš©ì ì •ë³´ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ê±°ë‚˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            pending_users = {uid:udata for uid,udata in USERS.items() if isinstance(udata, dict) and not udata.get("approved")}
            if pending_users:
                for pending_uid, pending_data in pending_users.items():
                    with st.expander(f"{pending_data.get('name','N/A')} ({pending_uid}) - {pending_data.get('department','N/A')}"):
                        approve_col, reject_col = st.columns(2)
                        if approve_col.button("ìŠ¹ì¸", key=f"admin_approve_user_v7_{pending_uid}"): 
                            USERS[pending_uid]["approved"] = True
                            if save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "user info (approval)"):
                                st.success(f"ì‚¬ìš©ì '{pending_uid}' ìŠ¹ì¸ ì™„ë£Œ."); st.rerun()
                            else: st.error("ì‚¬ìš©ì ìŠ¹ì¸ ì •ë³´ ì €ì¥ ì‹¤íŒ¨.")
                        if reject_col.button("ê±°ì ˆ", key=f"admin_reject_user_v7_{pending_uid}"): 
                            USERS.pop(pending_uid, None)
                            if save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "user info (rejection)"):
                                st.info(f"ì‚¬ìš©ì '{pending_uid}' ê±°ì ˆ ì²˜ë¦¬ ì™„ë£Œ."); st.rerun()
                            else: st.error("ì‚¬ìš©ì ê±°ì ˆ ì •ë³´ ì €ì¥ ì‹¤íŒ¨.")
            else: st.info("ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")

        # íŒŒì¼ ì—…ë¡œë“œ ë° í•™ìŠµ
        st.subheader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ë° í•™ìŠµ (Azure Blob Storage)")
        if 'processed_admin_file_info' not in st.session_state: st.session_state.processed_admin_file_info = None
        def clear_processed_admin_file_info_callback(): st.session_state.processed_admin_file_info = None
        
        admin_uploaded_file_widget = st.file_uploader(
            "í•™ìŠµí•  íŒŒì¼ ì—…ë¡œë“œ (PDF, DOCX, XLSX, CSV, PPTX, TXT, PNG, JPG, JPEG)",
            type=["pdf","docx","xlsx","xlsm","csv","pptx", "txt", "png", "jpg", "jpeg"], 
            key="admin_file_uploader_v7_del",
            on_change=clear_processed_admin_file_info_callback,
            accept_multiple_files=False 
        )

        if admin_uploaded_file_widget and container_client:
            current_admin_file_details = (admin_uploaded_file_widget.name, admin_uploaded_file_widget.size, admin_uploaded_file_widget.type)
            if st.session_state.processed_admin_file_info != current_admin_file_details: # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
                print(f"DEBUG Admin Upload: New file detected by admin. Info: {current_admin_file_details}")
                try: 
                    file_ext_admin_ul = os.path.splitext(admin_uploaded_file_widget.name)[1].lower()
                    is_admin_upload_image = file_ext_admin_ul in [".png", ".jpg", ".jpeg"]
                    content_to_learn, is_description_for_learning = None, False

                    if is_admin_upload_image:
                        with st.spinner(f"ì´ë¯¸ì§€ '{admin_uploaded_file_widget.name}' ì²˜ë¦¬ ë° ì„¤ëª… ìƒì„± ì¤‘..."):
                            admin_img_bytes = admin_uploaded_file_widget.getvalue()
                            admin_img_description = get_image_description(admin_img_bytes, admin_uploaded_file_widget.name, openai_client)
                        if admin_img_description:
                            content_to_learn = admin_img_description; is_description_for_learning = True
                            st.info(f"ì´ë¯¸ì§€ '{admin_uploaded_file_widget.name}' ì„¤ëª… ìƒì„± (ê¸¸ì´: {len(admin_img_description)}). ì´ ì„¤ëª…ì´ í•™ìŠµë©ë‹ˆë‹¤.")
                            st.text_area("ìƒì„±ëœ ì´ë¯¸ì§€ ì„¤ëª… (í•™ìŠµìš©)", admin_img_description, height=150, disabled=True)
                        else: st.error(f"ì´ë¯¸ì§€ '{admin_uploaded_file_widget.name}' ì„¤ëª… ìƒì„± ì‹¤íŒ¨. í•™ìŠµ ì œì™¸.")
                    else: 
                        with st.spinner(f"'{admin_uploaded_file_widget.name}'ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
                            content_to_learn = extract_text_from_file(admin_uploaded_file_widget)
                        if content_to_learn: st.info(f"'{admin_uploaded_file_widget.name}' í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê¸¸ì´: {len(content_to_learn)}).")
                        else: st.warning(f"'{admin_uploaded_file_widget.name}' ë‚´ìš© ì¶”ì¶œ ë¶ˆê°€ ë˜ëŠ” ë¹„ì–´ìˆìŒ. í•™ìŠµ ì œì™¸.")
                    
                    if content_to_learn: 
                        with st.spinner(f"'{admin_uploaded_file_widget.name}' ë‚´ìš© ì²˜ë¦¬ ë° í•™ìŠµ ì¤‘..."):
                            chunks_for_learning = chunk_text_into_pieces(content_to_learn)
                            if chunks_for_learning:
                                original_blob_path = save_original_file_to_blob(admin_uploaded_file_widget, container_client)
                                if original_blob_path: st.caption(f"ì›ë³¸ íŒŒì¼ '{admin_uploaded_file_widget.name}' Blob ì €ì¥: '{original_blob_path}'.")
                                else: st.warning(f"ì›ë³¸ íŒŒì¼ '{admin_uploaded_file_widget.name}' Blob ì €ì¥ ì‹¤íŒ¨.")

                                if add_document_to_vector_db_and_blob(admin_uploaded_file_widget, content_to_learn, chunks_for_learning, container_client, is_image_description=is_description_for_learning):
                                    st.success(f"íŒŒì¼ '{admin_uploaded_file_widget.name}' í•™ìŠµ ë° Azure Blob Storage ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
                                    st.session_state.processed_admin_file_info = current_admin_file_details 
                                    st.rerun() 
                                else: st.error(f"'{admin_uploaded_file_widget.name}' í•™ìŠµ ë˜ëŠ” Blob ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜."); st.session_state.processed_admin_file_info = None 
                            else: st.warning(f"'{admin_uploaded_file_widget.name}'ì— ëŒ€í•œ í•™ìŠµ ì²­í¬ ìƒì„± ì•ˆë¨."); st.session_state.processed_admin_file_info = None
                except Exception as e_admin_file_main_proc:
                    st.error(f"ê´€ë¦¬ì ì—…ë¡œë“œ íŒŒì¼ {admin_uploaded_file_widget.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e_admin_file_main_proc}")
                    print(f"CRITICAL ERROR in admin_upload_processing for {admin_uploaded_file_widget.name}: {e_admin_file_main_proc}\n{traceback.format_exc()}")
                    st.session_state.processed_admin_file_info = None
            elif st.session_state.processed_admin_file_info == current_admin_file_details:
                 st.caption(f"íŒŒì¼ '{admin_uploaded_file_widget.name}'ì€ ì´ì „ì— ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì¬í•™ìŠµí•˜ë ¤ë©´ ë‹¤ì‹œ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        elif admin_uploaded_file_widget and not container_client:
            st.error("íŒŒì¼ ì—…ë¡œë“œ ë° í•™ìŠµ ë¶ˆê°€: Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.markdown("---")

        # API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
        st.subheader("ğŸ“Š API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (Blob ë¡œê·¸ ê¸°ë°˜)")
        if container_client:
            usage_data_list = load_data_from_blob(USAGE_LOG_BLOB_NAME, container_client, "API usage log", default_value=[])
            if usage_data_list and isinstance(usage_data_list, list) and len(usage_data_list) > 0 :
                df_usage = pd.DataFrame(usage_data_list)
                for col_token in ["total_tokens", "prompt_tokens", "completion_tokens"]: 
                    df_usage[col_token] = pd.to_numeric(df_usage.get(col_token, 0), errors='coerce').fillna(0)
                if "request_type" not in df_usage.columns: df_usage["request_type"] = "unknown"
                
                total_tokens_all = df_usage["total_tokens"].sum()
                st.metric("ì´ API í˜¸ì¶œ ìˆ˜", len(df_usage))
                st.metric("ì´ ì‚¬ìš© í† í° ìˆ˜", f"{int(total_tokens_all):,}")

                token_cost_config = 0.0
                try: token_cost_config = float(st.secrets.get("TOKEN_COST","0.0"))
                except (ValueError, TypeError): pass 
                st.metric("ì˜ˆìƒ ë¹„ìš© (USD)", f"${total_tokens_all * token_cost_config:.4f}") 

                if "timestamp" in df_usage.columns:
                    try: 
                         df_usage['timestamp'] = pd.to_datetime(df_usage['timestamp'])
                         st.dataframe(df_usage.sort_values(by="timestamp",ascending=False), use_container_width=True, hide_index=True)
                    except Exception as e_sort_usage_df:
                         print(f"Warning: Could not sort usage log by timestamp: {e_sort_usage_df}")
                         st.dataframe(df_usage, use_container_width=True, hide_index=True) 
                else: st.dataframe(df_usage, use_container_width=True, hide_index=True)
            else: st.info("Blobì— ê¸°ë¡ëœ API ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        else: st.warning("API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í‘œì‹œ ë¶ˆê°€: Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.markdown("---")

        # Azure Blob Storage íŒŒì¼ ëª©ë¡
        st.subheader("ğŸ“‚ Azure Blob Storage íŒŒì¼ ëª©ë¡ (ìµœê·¼ 100ê°œ)")
        if container_client:
            try:
                blob_display_list = []
                blob_items_sorted = sorted(container_client.list_blobs(), key=lambda b: b.last_modified, reverse=True)
                for count_blob, blob_item_data in enumerate(blob_items_sorted):
                    if count_blob >= 100: break
                    blob_display_list.append({
                        "íŒŒì¼ëª…": blob_item_data.name, "í¬ê¸° (bytes)": blob_item_data.size,
                        "ìˆ˜ì •ì¼": blob_item_data.last_modified.strftime('%Y-%m-%d %H:%M:%S') if blob_item_data.last_modified else 'N/A'
                    })
                if blob_display_list: st.dataframe(pd.DataFrame(blob_display_list), use_container_width=True, hide_index=True)
                else: st.info("Azure Blob Storageì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            except AzureError as ae_blob_list: 
                 st.error(f"Azure Blob íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ Azure ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {ae_blob_list}")
                 print(f"AZURE ERROR listing blobs: {ae_blob_list}\n{traceback.format_exc()}")
            except Exception as e_blob_list:
                st.error(f"Azure Blob íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e_blob_list}")
                print(f"ERROR listing blobs: {e_blob_list}\n{traceback.format_exc()}")
        else: st.warning("íŒŒì¼ ëª©ë¡ í‘œì‹œ ë¶ˆê°€: Azure Blob í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
