import streamlit as st
# st.set_page_config must be the first Streamlit command.
st.set_page_config(
    page_title="ìœ ì•¤ìƒëª…ê³¼í•™ ì—…ë¬´ ê°€ì´ë“œ ë´‡",
    layout="centered",
    initial_sidebar_state="auto"
)

import os
import io
import fitz # PyMuPDF
import pandas as pd
import docx
from pptx import Presentation
import faiss
import openai
import numpy as np
import json
import time
from datetime import datetime
import uuid # ê³ ìœ  ID ìƒì„±ì„ ìœ„í•´ ì¶”ê°€
from openai import AzureOpenAI, APIConnectionError, APITimeoutError, RateLimitError, APIStatusError
from azure.core.exceptions import AzureError
from azure.storage.blob import BlobServiceClient
import tempfile
from werkzeug.security import check_password_hash, generate_password_hash
import traceback
import base64
import tiktoken
import re # For comment removal

from streamlit_cookies_manager import EncryptedCookieManager
print("Imported streamlit_cookies_manager (EncryptedCookieManager only).")


try:
    tokenizer = tiktoken.get_encoding("o200k_base")
    print("Tiktoken 'o200k_base' encoder loaded successfully.")
except Exception as e:
    st.error(f"Tiktoken encoder load failed: {e}. Token-based length limit may not work.")
    print(f"ERROR: Failed to load tiktoken encoder: {e}")
    tokenizer = None

APP_VERSION = "1.0.6 (Chat History Feature)" # ë²„ì „ ì—…ë°ì´íŠ¸

RULES_PATH_REPO = ".streamlit/prompt_rules.txt"
COMPANY_LOGO_PATH_REPO = "company_logo.png"
INDEX_BLOB_NAME = "vector_db/vector.index"
METADATA_BLOB_NAME = "vector_db/metadata.json"
USERS_BLOB_NAME = "app_data/users.json"
UPLOAD_LOG_BLOB_NAME = "app_logs/upload_log.json"
USAGE_LOG_BLOB_NAME = "app_logs/usage_log.json"
CHAT_HISTORY_BASE_PATH = "chat_histories/" # ëŒ€í™” ë‚´ì—­ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ

AZURE_OPENAI_TIMEOUT = 60.0
MODEL_MAX_INPUT_TOKENS = 128000
MODEL_MAX_OUTPUT_TOKENS = 16384
BUFFER_TOKENS = 500
TARGET_INPUT_TOKENS_FOR_PROMPT = MODEL_MAX_INPUT_TOKENS - MODEL_MAX_OUTPUT_TOKENS - BUFFER_TOKENS
IMAGE_DESCRIPTION_MAX_TOKENS = 500
EMBEDDING_BATCH_SIZE = 16

# --- ëŒ€í™” ë‚´ì—­ ê´€ë ¨ í•¨ìˆ˜ ---
def get_current_user_login_id():
    user_info = st.session_state.get("user", {})
    return user_info.get("uid") # ë¡œê·¸ì¸ ì‹œ ì €ì¥í•œ uid ì‚¬ìš©

def get_user_chat_history_blob_name(user_login_id):
    if not user_login_id:
        return None
    return f"{CHAT_HISTORY_BASE_PATH}{user_login_id}_history.json"

def load_user_conversations_from_blob():
    user_login_id = get_current_user_login_id()
    if not user_login_id or not container_client:
        print(f"Cannot load chat history: User ID ({user_login_id}) or container_client is missing.")
        return []
    blob_name = get_user_chat_history_blob_name(user_login_id)
    history_data = load_data_from_blob(blob_name, container_client, f"chat history for {user_login_id}", default_value={"conversations": []})
    loaded_conversations = history_data.get("conversations", [])
    print(f"Loaded {len(loaded_conversations)} conversations for user '{user_login_id}'.")
    # ë‚ ì§œ/ì‹œê°„ í•„ë“œë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜í•˜ê±°ë‚˜, ì •ë ¬ì„ ìœ„í•´ í•„ìš”ì‹œ ì²˜ë¦¬ (í˜„ì¬ëŠ” ë¬¸ìì—´ë¡œ ìœ ì§€)
    # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬ (last_updated ê¸°ì¤€)
    try:
        loaded_conversations.sort(key=lambda x: x.get("last_updated", "1970-01-01T00:00:00"), reverse=True)
    except Exception as e_sort:
        print(f"Error sorting conversations: {e_sort}") # ì •ë ¬ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìˆœì„œ ìœ ì§€
    return loaded_conversations


def save_user_conversations_to_blob():
    user_login_id = get_current_user_login_id()
    if not user_login_id or not container_client or "all_user_conversations" not in st.session_state:
        print(f"Cannot save chat history: User ID ({user_login_id}), container_client, or all_user_conversations missing.")
        return False
    
    # ì €ì¥ ì „ ìµœì‹ ìˆœìœ¼ë¡œ ë‹¤ì‹œ ì •ë ¬ (last_updated ê¸°ì¤€)
    try:
        st.session_state.all_user_conversations.sort(key=lambda x: x.get("last_updated", "1970-01-01T00:00:00"), reverse=True)
    except Exception as e_sort_save:
        print(f"Error sorting conversations before saving: {e_sort_save}")

    blob_name = get_user_chat_history_blob_name(user_login_id)
    print(f"Saving {len(st.session_state.all_user_conversations)} conversations for user '{user_login_id}' to {blob_name}.")
    return save_data_to_blob({"conversations": st.session_state.all_user_conversations}, blob_name, container_client, f"chat history for {user_login_id}")

def generate_conversation_title(messages_list):
    if not messages_list:
        return "ë¹ˆ ëŒ€í™”"
    for msg in messages_list:
        if msg.get("role") == "user" and msg.get("content","").strip():
            # "(ì²¨ë¶€ íŒŒì¼: ...)" ë¶€ë¶„ ì œì™¸
            title_candidate = msg["content"].split("\n(ì²¨ë¶€ íŒŒì¼:")[0].strip()
            return title_candidate[:30] + "..." if len(title_candidate) > 30 else title_candidate
    return "ëŒ€í™” ì‹œì‘"


def archive_current_chat_session_if_needed():
    user_login_id = get_current_user_login_id()
    # í˜„ì¬ ë©”ì‹œì§€ê°€ ì—†ê±°ë‚˜, ì‚¬ìš©ìê°€ ì—†ìœ¼ë©´ ì•„ì¹´ì´ë¸Œí•  í•„ìš” ì—†ìŒ
    if not user_login_id or not st.session_state.get("current_chat_messages"):
        print("Archive check: No user ID or no current messages. Skipping archive.")
        return False

    active_id = st.session_state.get("active_conversation_id")
    current_messages_copy = list(st.session_state.current_chat_messages) # í•­ìƒ ë³µì‚¬ë³¸ ì‚¬ìš©
    
    archived_or_updated = False

    if active_id: # í˜„ì¬ ë¶ˆëŸ¬ì˜¨ ëŒ€í™”ê°€ ìˆëŠ” ê²½ìš° (ì—…ë°ì´íŠ¸ ì‹œë„)
        found_and_updated = False
        for i, conv in enumerate(st.session_state.all_user_conversations):
            if conv["id"] == active_id:
                # ë©”ì‹œì§€ ë‚´ìš©ì´ ì‹¤ì œë¡œ ë³€ê²½ë˜ì—ˆëŠ”ì§€ ê°„ë‹¨íˆ í™•ì¸ (ë” ì •êµí•œ ë¹„êµë„ ê°€ëŠ¥)
                if conv["messages"] != current_messages_copy:
                    conv["messages"] = current_messages_copy
                    conv["last_updated"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    # ì œëª©ì€ ì²« ë©”ì‹œì§€ ê¸°ì¤€ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìœ¼ë¯€ë¡œ, ì¼ë°˜ì ìœ¼ë¡œëŠ” ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŒ.
                    # í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œ conv["title"] = generate_conversation_title(current_messages_copy) ì¶”ê°€
                    st.session_state.all_user_conversations[i] = conv # ë¦¬ìŠ¤íŠ¸ ë‚´ ê°ì²´ ì§ì ‘ ìˆ˜ì • ë°˜ì˜
                    print(f"Archived (updated) conversation ID: {active_id}, Title: '{conv['title']}'")
                    archived_or_updated = True
                else:
                    print(f"Conversation ID: {active_id} has no changes to messages. No update to archive.")
                found_and_updated = True
                break
        if not found_and_updated: # active_idê°€ ìˆì—ˆì§€ë§Œ ëª©ë¡ì— ì—†ëŠ” ì´ìƒí•œ ê²½ìš° (ìƒˆ ëŒ€í™”ë¡œ ì²˜ë¦¬)
             print(f"Warning: active_conversation_id '{active_id}' not found in log. Treating as new chat for archiving.")
             active_id = None # ìƒˆ ëŒ€í™”ë¡œ ì·¨ê¸‰í•˜ë„ë¡ active_id ì´ˆê¸°í™”

    if not active_id: # ìƒˆ ëŒ€í™”ì´ê±°ë‚˜, ìœ„ì—ì„œ active_idê°€ Noneìœ¼ë¡œ ë°”ë€ ê²½ìš°
        # current_chat_messagesê°€ ì‹¤ì œë¡œ ë‚´ìš©ì´ ìˆì–´ì•¼ ìƒˆ ëŒ€í™”ë¡œ ì €ì¥
        if current_messages_copy:
            new_conv_id = str(uuid.uuid4()) # ê³ ìœ  ID ìƒì„±
            title = generate_conversation_title(current_messages_copy)
            timestamp_str = current_messages_copy[0].get("time", datetime.now().strftime("%Y-%m-%d %H:%M"))

            new_conversation = {
                "id": new_conv_id,
                "title": title,
                "timestamp": timestamp_str, # ëŒ€í™” ì‹œì‘ ì‹œì  (ì²« ë©”ì‹œì§€ ì‹œê°„)
                "messages": current_messages_copy,
                "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            st.session_state.all_user_conversations.insert(0, new_conversation) # ìµœì‹  ëŒ€í™”ë¥¼ ë§¨ ì•ì— ì¶”ê°€
            # st.session_state.active_conversation_id = new_conv_id # ì´ í•¨ìˆ˜ í˜¸ì¶œ í›„ active_idëŠ” ë³´í†µ Noneì´ë‚˜ ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ë°”ë€œ
            print(f"Archived (new) conversation ID: {new_conv_id}, Title: '{title}'")
            archived_or_updated = True
        else: # current_messages_copyê°€ ë¹„ì–´ìˆìœ¼ë©´ ìƒˆ ëŒ€í™”ë¡œ ì €ì¥í•  ë‚´ìš© ì—†ìŒ
             print("Archive check: Current messages empty and no active_id. Skipping archive of new chat.")


    if archived_or_updated:
        save_user_conversations_to_blob()
    
    return archived_or_updated
# --- END ëŒ€í™” ë‚´ì—­ ê´€ë ¨ í•¨ìˆ˜ ---

def get_base64_of_bin_file(bin_file_path):
    try:
        with open(bin_file_path, 'rb') as f:
            data = f.read()
        return base64.b64encode(data).decode()
    except FileNotFoundError:
        print(f"ERROR: Logo file not found: {bin_file_path}")
        return None
    except Exception as e:
        print(f"ERROR: Processing logo file '{bin_file_path}': {e}")
        return None

def get_logo_and_version_html(app_version_str):
    logo_html_part = ""
    company_name_default = '<span class="version-text" style="font-weight:bold; font-size: 1.5em;">ìœ ì•¤ìƒëª…ê³¼í•™</span>'
    
    if os.path.exists(COMPANY_LOGO_PATH_REPO):
        logo_b64 = get_base64_of_bin_file(COMPANY_LOGO_PATH_REPO)
        if logo_b64:
            logo_html_part = f'<img src="data:image/png;base64,{logo_b64}" class="logo-image" width="150" style="vertical-align: middle;">'
        else:
            logo_html_part = company_name_default
    else:
        print(f"WARNING: Company logo file not found at {COMPANY_LOGO_PATH_REPO}")
        logo_html_part = company_name_default
        
    return f"""
        {logo_html_part}
        <span class="version-text" style="vertical-align: middle; margin-left: 10px;">{app_version_str}</span>
    """

st.markdown("""
<style>
    /* ê¸°ë³¸ CSS ìŠ¤íƒ€ì¼ */
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button {
        background-color: #FFFFFF; color: #333F48; border: 1px solid #BCC0C4;
        border-radius: 8px; padding: 8px 12px; font-weight: 500;
        width: auto; min-width: 100px; white-space: nowrap; display: inline-block;
        transition: background-color 0.3s ease, border-color 0.3s ease;
    }
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button:hover {
        background-color: #F0F2F5; border-color: #A0A4A8;
    }
    .stApp > header ~ div [data-testid="stHorizontalBlock"] > div:nth-child(2) div[data-testid="stButton"] > button:active {
        background-color: #E0E2E5;
    }
    .chat-bubble-container { display: flex; flex-direction: column; margin-bottom: 15px; }
    .user-align { align-items: flex-end; }
    .assistant-align { align-items: flex-start; }
    .bubble { padding: 10px 15px; border-radius: 18px; max-width: 75%; word-wrap: break-word; display: inline-block; color: black; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.08); position: relative; }
    .user-bubble { background-color: #90EE90; color: black; border-bottom-right-radius: 5px; }
    .assistant-bubble { background-color: #E9E9EB; border-bottom-left-radius: 5px; }
    .timestamp { font-size: 0.7rem; color: #8E8E93; padding: 2px 5px 0px 5px; }
    
    /* ë©”ì¸ ì•± ì œëª© ë° ë¶€ì œëª© (ë¡œê·¸ì¸ í›„) */
    .main-app-title-container { text-align: center; margin-bottom: 24px; }
    .main-app-title { font-size: 2.1rem; font-weight: bold; display: block; }
    .main-app-subtitle { font-size: 0.9rem; color: gray; display: block; margin-top: 4px;}
    
    /* ë¡œê³  ë° ë²„ì „ */
    .logo-container { display: flex; align-items: center; }
    .logo-image { margin-right: 10px; }
    .version-text { font-size: 0.9rem; color: gray; }

    /* ë¡œê·¸ì¸ í™”ë©´ ì „ìš© ì œëª© ìŠ¤íƒ€ì¼ */
    .login-page-header-container { text-align: center; margin-top: 10px; margin-bottom: 10px;}
    .login-page-main-title { font-size: 1.8rem; font-weight: bold; display: block; color: #333F48; } 
    .login-page-sub-title { font-size: 0.85rem; color: gray; display: block; margin-top: 2px; margin-bottom: 20px;}
    .login-form-title { 
        font-size: 1.6rem; 
        font-weight: bold;
        text-align: center;
        margin-top: 10px; 
        margin-bottom: 25px; 
    }

    /* ëª¨ë°”ì¼ í™”ë©´ ëŒ€ì‘ */
    @media (max-width: 768px) {
        .main-app-title { font-size: 1.8rem; }
        .main-app-subtitle { font-size: 0.8rem; }
        .login-page-main-title { font-size: 1.5rem; }
        .login-page-sub-title { font-size: 0.8rem; }
        .login-form-title { font-size: 1.3rem; margin-bottom: 20px; }
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def get_azure_openai_client_cached():
    print("Attempting to initialize Azure OpenAI client...")
    try:
        api_version_to_use = st.secrets.get("AZURE_OPENAI_VERSION", "2024-02-15-preview")
        print(f"DEBUG: Initializing AzureOpenAI client with API version: {api_version_to_use}")
        client = AzureOpenAI(
            api_key=st.secrets["AZURE_OPENAI_KEY"],
            azure_endpoint=st.secrets["AZURE_OPENAI_ENDPOINT"],
            api_version=api_version_to_use,
            timeout=AZURE_OPENAI_TIMEOUT
        )
        print("Azure OpenAI client initialized successfully.")
        return client
    except KeyError as e:
        st.error(f"Azure OpenAI config error: Missing key '{e.args[0]}' in secrets.")
        print(f"ERROR: Missing Azure OpenAI secret: {e.args[0]}")
        return None
    except Exception as e:
        st.error(f"Error initializing Azure OpenAI client: {e}.")
        print(f"ERROR: Azure OpenAI client initialization failed: {e}\n{traceback.format_exc()}")
        return None

@st.cache_resource
def get_azure_blob_clients_cached():
    print("Attempting to initialize Azure Blob Service client...")
    try:
        conn_str = st.secrets["AZURE_BLOB_CONN"]
        blob_service_client = BlobServiceClient.from_connection_string(conn_str, connection_timeout=60, read_timeout=120)
        container_name = st.secrets["BLOB_CONTAINER"]
        container_client = blob_service_client.get_container_client(container_name)
        print(f"Azure Blob Service client and container client for '{container_name}' initialized successfully.")
        return blob_service_client, container_client
    except KeyError as e:
        st.error(f"Azure Blob Storage config error: Missing key '{e.args[0]}' in secrets.")
        print(f"ERROR: Missing Azure Blob Storage secret: {e.args[0]}")
        return None, None
    except Exception as e:
        st.error(f"Error initializing Azure Blob client: {e}.")
        print(f"ERROR: Azure Blob client initialization failed: {e}\n{traceback.format_exc()}")
        return None, None

openai_client = get_azure_openai_client_cached()
blob_service, container_client = get_azure_blob_clients_cached()

EMBEDDING_MODEL = None
if openai_client:
    try:
        EMBEDDING_MODEL = st.secrets["AZURE_OPENAI_EMBEDDING_DEPLOYMENT"]
        print(f"Embedding model set to: {EMBEDDING_MODEL}")
    except KeyError:
        st.error("Missing 'AZURE_OPENAI_EMBEDDING_DEPLOYMENT' in secrets.")
        print("ERROR: Missing AZURE_OPENAI_EMBEDDING_DEPLOYMENT secret.")
        openai_client = None
    except Exception as e:
        st.error(f"Error loading embedding model config: {e}")
        print(f"ERROR: Loading AZURE_OPENAI_EMBEDDING_DEPLOYMENT secret: {e}")
        openai_client = None

def load_data_from_blob(blob_name, _container_client, data_description="data", default_value=None):
    if not _container_client:
        print(f"ERROR: Blob Container client is None for load_data_from_blob ('{data_description}'). Returning default.")
        return default_value if default_value is not None else {}
    print(f"Attempting to load '{data_description}' from Blob: '{blob_name}'")
    try:
        blob_client_instance = _container_client.get_blob_client(blob_name)
        if blob_client_instance.exists():
            with tempfile.TemporaryDirectory() as tmpdir:
                local_temp_path = os.path.join(tmpdir, os.path.basename(blob_name))
                with open(local_temp_path, "wb") as download_file:
                    download_stream = blob_client_instance.download_blob(timeout=60)
                    download_file.write(download_stream.readall())
                if os.path.getsize(local_temp_path) > 0:
                    with open(local_temp_path, "r", encoding="utf-8") as f:
                        loaded_data = json.load(f)
                    print(f"Successfully loaded '{data_description}' from Blob: '{blob_name}'")
                    return loaded_data
                else:
                    print(f"WARNING: '{data_description}' file '{blob_name}' exists in Blob but is empty. Returning default.")
                    return default_value if default_value is not None else {}
        else:
            print(f"WARNING: '{data_description}' file '{blob_name}' not found in Blob Storage. Returning default.")
            return default_value if default_value is not None else {}
    except json.JSONDecodeError:
        print(f"ERROR: Failed to decode JSON for '{data_description}' from Blob '{blob_name}'. Returning default.")
        st.warning(f"File '{data_description}' ({blob_name}) is corrupted or not valid JSON. Using default.")
        return default_value if default_value is not None else {}
    except AzureError as ae:
        print(f"AZURE ERROR loading '{data_description}' from Blob '{blob_name}': {ae}\n{traceback.format_exc()}")
        st.warning(f"Azure service error loading '{data_description}': {ae}. Using default.")
        return default_value if default_value is not None else {}
    except Exception as e:
        print(f"GENERAL ERROR loading '{data_description}' from Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        st.warning(f"Unknown error loading '{data_description}': {e}. Using default.")
        return default_value if default_value is not None else {}

def save_data_to_blob(data_to_save, blob_name, _container_client, data_description="data"):
    if not _container_client:
        st.error(f"Cannot save '{data_description}': Azure Blob client not ready.")
        print(f"ERROR: Blob Container client is None, cannot save '{blob_name}'.")
        return False
    try:
        if not isinstance(data_to_save, (dict, list)): # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ì¸ì§€ í™•ì¸
            st.error(f"Save failed for '{data_description}': Data is not JSON serializable (type: {type(data_to_save)}).")
            print(f"ERROR: Data for '{blob_name}' is not JSON serializable (type: {type(data_to_save)}).")
            return False
        with tempfile.TemporaryDirectory() as tmpdir:
            local_temp_path = os.path.join(tmpdir, os.path.basename(blob_name))
            with open(local_temp_path, "w", encoding="utf-8") as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
            blob_client_instance = _container_client.get_blob_client(blob_name)
            with open(local_temp_path, "rb") as data_stream:
                blob_client_instance.upload_blob(data_stream, overwrite=True, timeout=60)
            print(f"Successfully saved '{data_description}' to Blob: '{blob_name}'")
        return True
    except AzureError as ae:
        st.error(f"Azure service error saving '{data_description}' to Blob: {ae}")
        print(f"AZURE ERROR saving '{data_description}' to Blob '{blob_name}': {ae}\n{traceback.format_exc()}")
        return False
    except Exception as e:
        st.error(f"Unknown error saving '{data_description}' to Blob: {e}")
        print(f"GENERAL ERROR saving '{data_description}' to Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        return False

def save_binary_data_to_blob(local_file_path, blob_name, _container_client, data_description="binary data"):
    if not _container_client:
        st.error(f"Cannot save binary '{data_description}': Azure Blob client not ready.")
        print(f"ERROR: Blob Container client is None, cannot save binary '{blob_name}'.")
        return False
    if not os.path.exists(local_file_path):
        st.error(f"Local file for binary '{data_description}' not found: '{local_file_path}'")
        print(f"ERROR: Local file for binary data not found: '{local_file_path}'")
        return False
    try:
        blob_client_instance = _container_client.get_blob_client(blob_name)
        with open(local_file_path, "rb") as data_stream:
            blob_client_instance.upload_blob(data_stream, overwrite=True, timeout=120)
        print(f"Successfully saved binary '{data_description}' to Blob: '{blob_name}'")
        return True
    except AzureError as ae:
        st.error(f"Azure service error saving binary '{data_description}' to Blob: {ae}")
        print(f"AZURE ERROR saving binary '{data_description}' to Blob '{blob_name}': {ae}\n{traceback.format_exc()}")
        return False
    except Exception as e:
        st.error(f"Unknown error saving binary '{data_description}' to Blob: {e}")
        print(f"GENERAL ERROR saving binary '{data_description}' to Blob '{blob_name}': {e}\n{traceback.format_exc()}")
        return False

USERS = {}
if container_client:
    USERS = load_data_from_blob(USERS_BLOB_NAME, container_client, "user info", default_value={})
    if not isinstance(USERS, dict) :
        print(f"ERROR: USERS loaded from blob is not a dict ({type(USERS)}). Re-initializing.")
        USERS = {}
    if "admin" not in USERS: # admin ê³„ì • ì—†ìœ¼ë©´ ìƒì„±
        print(f"'{USERS_BLOB_NAME}' from Blob is empty or admin is missing. Creating default admin.")
        USERS["admin"] = {
            "name": "ê´€ë¦¬ì", "department": "í’ˆì§ˆë³´ì¦íŒ€", "uid": "admin", # uid ì¶”ê°€
            "password_hash": generate_password_hash(st.secrets.get("ADMIN_PASSWORD", "diteam_fallback_secret")),
            "approved": True, "role": "admin"
        }
        if not save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "initial user info"):
             st.warning("Failed to save default admin info to Blob. Will retry on next run.")
else:
    st.error("Azure Blob Storage connection failed. Cannot initialize user info. App may not function correctly.")
    print("CRITICAL: Cannot initialize USERS due to Blob client failure.")
    USERS = {"admin": {"name": "ê´€ë¦¬ì(ì—°ê²°ì‹¤íŒ¨)", "department": "ì‹œìŠ¤í…œ", "uid":"admin", "password_hash": generate_password_hash("fallback"), "approved": True, "role": "admin"}}

cookies = None
cookie_manager_ready = False # ì „ì—­ ë³€ìˆ˜ë¡œ ì¿ í‚¤ ë§¤ë‹ˆì € ì¤€ë¹„ ìƒíƒœ ê´€ë¦¬
print(f"Attempting to load COOKIE_SECRET from st.secrets...")
try:
    cookie_secret_key = st.secrets.get("COOKIE_SECRET")
    if not cookie_secret_key:
        st.error("'COOKIE_SECRET' is not set or empty in st.secrets.")
        print("ERROR: COOKIE_SECRET is not set or empty in st.secrets.")
    else:
        cookies = EncryptedCookieManager(
            prefix="gmp_chatbot_auth_v5_6_history/", # ì¿ í‚¤ prefix ë³€ê²½ (ë²„ì „ì—…)
            password=cookie_secret_key
        )
        print("CookieManager object created. Readiness will be checked before use.")
except Exception as e:
    st.error(f"Unknown error creating cookie manager object: {e}")
    print(f"CRITICAL: CookieManager object creation error: {e}\n{traceback.format_exc()}")
    cookies = None

SESSION_TIMEOUT = 1800 # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ê¸°ë³¸ê°’ (ì´ˆ)
try:
    session_timeout_secret = st.secrets.get("SESSION_TIMEOUT")
    if session_timeout_secret: SESSION_TIMEOUT = int(session_timeout_secret)
    print(f"Session timeout set to: {SESSION_TIMEOUT} seconds.")
except (ValueError, TypeError):
    print(f"WARNING: SESSION_TIMEOUT in secrets ('{session_timeout_secret}') is not a valid integer. Using default {SESSION_TIMEOUT}s.")
except Exception as e:
     print(f"WARNING: Error reading SESSION_TIMEOUT from secrets: {e}. Using default {SESSION_TIMEOUT}s.")

# --- Session State ì´ˆê¸°í™” ---
# ê¸°ì¡´ messages ëŒ€ì‹  current_chat_messages ì‚¬ìš©, ëŒ€í™” ë‚´ì—­ ê´€ë ¨ ë³€ìˆ˜ ì¶”ê°€
session_keys_to_initialize = {
    "authenticated": False,
    "user": {},
    "current_chat_messages": [],
    "all_user_conversations": [],
    "active_conversation_id": None,
    "show_uploader": False # íŒŒì¼ ì—…ë¡œë” í‘œì‹œ ì—¬ë¶€
}
for key, default_value in session_keys_to_initialize.items():
    if key not in st.session_state:
        st.session_state[key] = default_value
        print(f"Initializing st.session_state['{key}'] to {default_value}")

# --- ì¿ í‚¤ë¥¼ ì‚¬ìš©í•œ ì„¸ì…˜ ë³µì› ì‹œë„ (ì•± ì‹¤í–‰ ì´ˆê¸°) ---
# ì´ ë¡œì§ì€ st.session_state["authenticated"]ê°€ Falseì¼ ë•Œë§Œ ì˜ë¯¸ê°€ ìˆìœ¼ë©°,
# ì¿ í‚¤ê°€ ìˆê³  ìœ íš¨í•˜ë‹¤ë©´ authenticatedë¥¼ Trueë¡œ ë³€ê²½í•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤.
if not st.session_state.get("authenticated", False) and cookies is not None:
    print("Attempting initial session restore from cookies as user is not authenticated in session_state.")
    try:
        if cookies.ready():
            cookie_manager_ready = True
            print("CookieManager.ready() is True for initial session restore.")
            auth_cookie_val = cookies.get("authenticated")
            print(f"Cookie 'authenticated' value for initial restore: {auth_cookie_val}")

            if auth_cookie_val == "true":
                login_time_str = cookies.get("login_time", "0")
                try:
                    login_time = float(login_time_str if login_time_str and login_time_str.replace('.', '', 1).isdigit() else "0")
                except ValueError:
                    login_time = 0.0
                
                if (time.time() - login_time) < SESSION_TIMEOUT:
                    user_json_cookie = cookies.get("user", "{}")
                    try:
                        user_data_from_cookie = json.loads(user_json_cookie if user_json_cookie else "{}")
                        if user_data_from_cookie and isinstance(user_data_from_cookie, dict) and "uid" in user_data_from_cookie: # uid ì¡´ì¬ í™•ì¸
                            st.session_state["user"] = user_data_from_cookie
                            st.session_state["authenticated"] = True
                            # ë¡œê·¸ì¸ ì„±ê³µ ì‹œ ëŒ€í™” ë‚´ì—­ ë¡œë“œ
                            st.session_state.all_user_conversations = load_user_conversations_from_blob()
                            st.session_state.current_chat_messages = [] # ìƒˆ ëŒ€í™”ë¡œ ì‹œì‘
                            st.session_state.active_conversation_id = None
                            print(f"User '{user_data_from_cookie.get('name')}' session restored from cookie. Chat history loaded.")
                            # st.rerun() # ì—¬ê¸°ì„œ reruní•˜ë©´ ì¿ í‚¤ ê´€ë ¨ ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥ì„± ìˆìŒ. ë‹¤ìŒ ë‹¨ê³„ì—ì„œ UIê°€ ê²°ì •í•˜ë„ë¡ í•¨.
                        else: # ì¿ í‚¤ì— ì‚¬ìš©ì ì •ë³´ê°€ ì—†ê±°ë‚˜ uidê°€ ì—†ëŠ” ê²½ìš°
                            print("User data in cookie is empty, invalid, or missing uid. Clearing auth state from cookie.")
                            if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
                            st.session_state["authenticated"] = False # ëª…ì‹œì ìœ¼ë¡œ False
                    except json.JSONDecodeError: # ì‚¬ìš©ì ì •ë³´ JSON íŒŒì‹± ì‹¤íŒ¨
                        print("ERROR: Failed to decode user JSON from cookie. Clearing auth state from cookie.")
                        if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
                        st.session_state["authenticated"] = False # ëª…ì‹œì ìœ¼ë¡œ False
                else: # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ
                    print("Session timeout detected from cookie. Clearing auth state and cookies.")
                    if cookies.ready(): cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
                    st.session_state["authenticated"] = False # ëª…ì‹œì ìœ¼ë¡œ False
            # else: auth_cookie_valì´ "true"ê°€ ì•„ë‹ˆë©´ st.session_state["authenticated"]ëŠ” Falseë¡œ ìœ ì§€ë¨
        else: # cookies.ready() is False
            print("CookieManager.ready() is False for initial session restore. Cannot load cookies yet.")
            # cookie_manager_readyëŠ” Falseë¡œ ìœ ì§€
    except Exception as e_cookie_op_initial:
        print(f"Exception during initial cookie operations: {e_cookie_op_initial}\n{traceback.format_exc()}")
        st.session_state["authenticated"] = False # ì•ˆì „í•˜ê²Œ False
        # cookie_manager_readyëŠ” Falseë¡œ ìœ ì§€ë  ìˆ˜ ìˆìŒ

# ë¡œê·¸ì¸ UI í‘œì‹œ ì „ ì¿ í‚¤ ë§¤ë‹ˆì € ì¤€ë¹„ ìƒíƒœ ìµœì¢… í™•ì¸ (ìœ„ì—ì„œ readyê°€ ì•„ë‹ˆì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
if cookies is not None and not cookie_manager_ready:
    print("Checking CookieManager readiness again before login UI (if not ready yet)...")
    try:
        if cookies.ready():
            cookie_manager_ready = True
            print("CookieManager became ready before login UI (second check).")
            # ì—¬ê¸°ì„œ ë‹¤ì‹œ ì„¸ì…˜ ë³µì› ì‹œë„ (ìœ„ì—ì„œ ì‹¤íŒ¨í•œ ê²½ìš°ë¥¼ ìœ„í•´)
            if not st.session_state.get("authenticated", False): # ì•„ì§ ì¸ì¦ ì•ˆëìœ¼ë©´
                print("Attempting session restore again as CookieManager just became ready.")
                # (ìœ„ì˜ ì¿ í‚¤ ë³µì› ë¡œì§ê³¼ ìœ ì‚¬í•˜ê²Œ ë‹¤ì‹œ í•œë²ˆ ì‹¤í–‰)
                # ì´ ë¶€ë¶„ì€ ë³µì¡ì„±ì„ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìœ„ì˜ ì´ˆê¸° ë³µì› ë¡œì§ì´ ì¶©ë¶„íˆ ì•ˆì •ì ì´ë¼ë©´ ìƒëµ ê°€ëŠ¥
                # í˜„ì¬ëŠ” ìœ„ì˜ ì´ˆê¸° ë³µì› ì‹œë„ í›„, ê·¸ë˜ë„ ì•ˆëìœ¼ë©´ ë¡œê·¸ì¸ í¼ìœ¼ë¡œ ë„˜ì–´ê°.
                # ë§Œì•½ ì—¬ê¸°ì„œ ë³µì›ì— ì„±ê³µí•˜ë©´ st.rerun() í•„ìš”í•  ìˆ˜ ìˆìŒ.
        else:
            print("CookieManager still not ready before login UI (second check).")
    except Exception as e_ready_login_ui:
        print(f"WARNING: cookies.ready() call just before login UI failed: {e_ready_login_ui}")


if not st.session_state.get("authenticated", False):
    st.markdown("""
    <div class="login-page-header-container" style="margin-top: 80px;"> 
      <span class="login-page-main-title">ìœ ì•¤ìƒëª…ê³¼í•™ GMP/SOP ì—…ë¬´ ê°€ì´ë“œ ë´‡</span>
      <span class="login-page-sub-title">Made by DI.PART</span>
    </div>
    """, unsafe_allow_html=True)
    st.markdown('<p class="login-form-title">ğŸ” ë¡œê·¸ì¸ ë˜ëŠ” íšŒì›ê°€ì…</p>', unsafe_allow_html=True)

    if cookies is None or not cookie_manager_ready:
        st.warning("ì¿ í‚¤ ì‹œìŠ¤í…œì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¡œê·¸ì¸ì´ ìœ ì§€ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ìƒˆë¡œê³ ì¹¨ í•´ë³´ì„¸ìš”.")

    with st.form("auth_form_final_v5_history", clear_on_submit=False):
        mode = st.radio("ì„ íƒ", ["ë¡œê·¸ì¸", "íšŒì›ê°€ì…"], key="auth_mode_final_v5_history")
        uid_input = st.text_input("ID", key="auth_uid_final_v5_history") # ë³€ìˆ˜ëª… ë³€ê²½ (uidëŠ” ë‚´ë¶€ ì‚¬ìš©)
        pwd = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="auth_pwd_final_v5_history")
        name, dept = "", ""
        if mode == "íšŒì›ê°€ì…":
            name = st.text_input("ì´ë¦„", key="auth_name_final_v5_history")
            dept = st.text_input("ë¶€ì„œ", key="auth_dept_final_v5_history")
        submit_button = st.form_submit_button("í™•ì¸")

    if submit_button:
        if not uid_input or not pwd: st.error("IDì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif mode == "íšŒì›ê°€ì…" and (not name or not dept): st.error("íšŒì›ê°€ì… ì‹œ ì´ë¦„ê³¼ ë¶€ì„œë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            if mode == "ë¡œê·¸ì¸":
                user_data_login = USERS.get(uid_input)
                if not user_data_login: st.error("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” IDì…ë‹ˆë‹¤.")
                elif not user_data_login.get("approved", False): st.warning("ê´€ë¦¬ì ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ ê³„ì •ì…ë‹ˆë‹¤.")
                elif check_password_hash(user_data_login["password_hash"], pwd):
                    
                    # ì‚¬ìš©ì ì •ë³´ì— uid ì €ì¥ (ëŒ€í™” ë‚´ì—­ ë“±ì— ì‚¬ìš©í•˜ê¸° ìœ„í•¨)
                    user_data_to_session = user_data_login.copy() # ì›ë³¸ USERS ë”•ì…”ë„ˆë¦¬ ë³€ê²½ ë°©ì§€
                    user_data_to_session["uid"] = uid_input # ë¡œê·¸ì¸ IDë¥¼ uid í‚¤ë¡œ ì €ì¥

                    st.session_state["authenticated"] = True
                    st.session_state["user"] = user_data_to_session
                    
                    # ë¡œê·¸ì¸ ì„±ê³µ ì‹œ ëŒ€í™” ë‚´ì—­ ë¡œë“œ ë° ìƒˆ ëŒ€í™” ì¤€ë¹„
                    st.session_state.all_user_conversations = load_user_conversations_from_blob()
                    st.session_state.current_chat_messages = [] # ìƒˆ ëŒ€í™”ë¡œ ì‹œì‘
                    st.session_state.active_conversation_id = None
                    print(f"Login successful for user '{uid_input}'. Chat history loaded. Starting new chat session.")

                    if cookies is not None and cookie_manager_ready:
                        try:
                            cookies["authenticated"] = "true"
                            cookies["user"] = json.dumps(user_data_to_session) # uid í¬í•¨ëœ ì •ë³´ ì €ì¥
                            cookies["login_time"] = str(time.time())
                            cookies.save()
                            print(f"Cookies saved for user '{uid_input}'.")
                        except Exception as e_cookie_save_login:
                            st.warning(f"ë¡œê·¸ì¸ ì¿ í‚¤ ì €ì¥ ì¤‘ ë¬¸ì œ ë°œìƒ: {e_cookie_save_login}")
                            print(f"ERROR: Failed to save login cookies: {e_cookie_save_login}")
                    elif cookies is None:
                         st.warning("ì¿ í‚¤ ì‹œìŠ¤í…œ ë¯¸ì´ˆê¸°í™”ë¡œ ë¡œê·¸ì¸ ìƒíƒœ ì €ì¥ ë¶ˆê°€.")
                    elif not cookie_manager_ready:
                         st.warning("ì¿ í‚¤ ì‹œìŠ¤í…œ ë¯¸ì¤€ë¹„ë¡œ ë¡œê·¸ì¸ ìƒíƒœ ì €ì¥ ë¶ˆê°€.")

                    st.success(f"{user_data_to_session.get('name', uid_input)}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤!"); st.rerun()
                else: st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            elif mode == "íšŒì›ê°€ì…":
                if uid_input in USERS: st.error("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” IDì…ë‹ˆë‹¤.")
                else:
                    USERS[uid_input] = {"name": name, "department": dept, "uid": uid_input, # uidë„ ì €ì¥
                                  "password_hash": generate_password_hash(pwd),
                                  "approved": False, "role": "user"}
                    if not save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "user info (signup)"):
                        st.error("íšŒì› ì •ë³´ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
                        USERS.pop(uid_input, None)
                    else:
                        st.success("íšŒì›ê°€ì… ìš”ì²­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ì ìŠ¹ì¸ í›„ ë¡œê·¸ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.stop()

# --- ì´í•˜ ì½”ë“œëŠ” ì¸ì¦ëœ ì‚¬ìš©ìì—ê²Œë§Œ ë³´ì„ ---

current_user_info = st.session_state.get("user", {}) # uid í¬í•¨

# --- ì‚¬ì´ë“œë°”: ìƒˆ ëŒ€í™” ë²„íŠ¼ ë° ëŒ€í™” ë‚´ì—­ ---
with st.sidebar:
    st.markdown(f"**{current_user_info.get('name', 'ì‚¬ìš©ì')}ë‹˜ ({current_user_info.get('uid', 'ì•Œìˆ˜ì—†ìŒ')})**")
    st.markdown(f"{current_user_info.get('department', 'ë¶€ì„œì •ë³´ì—†ìŒ')}")
    st.markdown("---")

    if st.button("â• ìƒˆ ëŒ€í™” ì‹œì‘", use_container_width=True, key="new_chat_button"):
        archive_current_chat_session_if_needed() # í˜„ì¬ ëŒ€í™”ê°€ ìˆë‹¤ë©´ ì €ì¥
        st.session_state.current_chat_messages = []
        st.session_state.active_conversation_id = None
        print("New chat started by user.")
        st.rerun()

    st.markdown("##### ì´ì „ ëŒ€í™” ëª©ë¡")
    if not st.session_state.all_user_conversations:
        st.caption("ì´ì „ ëŒ€í™” ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ëŒ€í™” ëª©ë¡ í‘œì‹œ (ìµœì‹  10ê°œ ë˜ëŠ” ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•˜ê²Œ)
    # all_user_conversationsëŠ” load ì‹œ last_updated ê¸°ì¤€ìœ¼ë¡œ ì´ë¯¸ ì •ë ¬ë¨
    for i, conv in enumerate(st.session_state.all_user_conversations[:20]): # ìµœê·¼ 20ê°œ í‘œì‹œ
        title_display = conv.get('title', f"ëŒ€í™” {conv.get('id', i)}")
        timestamp_display = conv.get('timestamp', conv.get('last_updated','ì‹œê°„ì—†ìŒ'))
        # ë²„íŠ¼ ë ˆì´ë¸”ì— ê³ ìœ ì„±ì„ ë”í•˜ê¸° ìœ„í•´ ID ì¼ë¶€ ì‚¬ìš© (ì œëª©ì´ ì¤‘ë³µë  ê²½ìš° ëŒ€ë¹„)
        button_label = f"{title_display} ({timestamp_display})"
        button_key = f"conv_btn_{conv['id']}"

        # í˜„ì¬ í™œì„±í™”ëœ ëŒ€í™”ëŠ” ë‹¤ë¥´ê²Œ í‘œì‹œ (ì„ íƒì‚¬í•­)
        if st.session_state.active_conversation_id == conv["id"]:
            st.markdown(f"**â¡ï¸ {button_label}**")
        elif st.button(button_label, key=button_key, use_container_width=True):
            print(f"Loading conversation ID: {conv['id']}, Title: '{title_display}'")
            archive_current_chat_session_if_needed() # í˜„ì¬ í™œì„± ëŒ€í™” ì €ì¥
            st.session_state.current_chat_messages = list(conv["messages"]) # ëŒ€í™” ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸° (ë³µì‚¬ë³¸)
            st.session_state.active_conversation_id = conv["id"]
            st.rerun()
    
    if len(st.session_state.all_user_conversations) > 20:
        st.caption("ë” ë§ì€ ë‚´ì—­ì€ ì „ì²´ ë³´ê¸° ê¸°ëŠ¥(ì¶”í›„ êµ¬í˜„)ì„ ì´ìš©í•´ì£¼ì„¸ìš”.")


top_cols_main = st.columns([0.7, 0.3])
with top_cols_main[0]:
    main_logo_html = get_logo_and_version_html(APP_VERSION)
    st.markdown(f"""<div class="logo-container">{main_logo_html}</div>""", unsafe_allow_html=True)


with top_cols_main[1]:
    st.markdown('<div style="text-align: right;">', unsafe_allow_html=True)
    if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_button_final_v5_history"):
        archive_current_chat_session_if_needed() # ë¡œê·¸ì•„ì›ƒ ì „ í˜„ì¬ ëŒ€í™” ì €ì¥
        
        st.session_state["authenticated"] = False
        st.session_state["user"] = {}
        st.session_state.current_chat_messages = []
        st.session_state.all_user_conversations = []
        st.session_state.active_conversation_id = None
        print("Logout successful. Chat messages and history session state cleared.")
        if cookies is not None and cookie_manager_ready:
            try:
                cookies["authenticated"] = "false"; cookies["user"] = ""; cookies["login_time"] = ""; cookies.save()
                print("Cookies cleared on logout.")
            except Exception as e_logout_cookie:
                 print(f"ERROR: Failed to clear cookies on logout: {e_logout_cookie}")
        st.rerun()
    st.markdown('</div>', unsafe_allow_html=True)

st.markdown("""
<div class="main-app-title-container">
  <span class="main-app-title">ìœ ì•¤ìƒëª…ê³¼í•™ GMP/SOP ì—…ë¬´ ê°€ì´ë“œ ë´‡</span>
  <span class="main-app-subtitle">Made by DI.PART</span>
</div>
""", unsafe_allow_html=True)


@st.cache_resource
def load_vector_db_from_blob_cached(_container_client):
    if not _container_client:
        print("ERROR: Blob Container client is None for load_vector_db_from_blob_cached.")
        return faiss.IndexFlatL2(1536), []
    current_embedding_dimension = 1536
    idx, meta = faiss.IndexFlatL2(current_embedding_dimension), []
    print(f"Attempting to load vector DB from Blob: '{INDEX_BLOB_NAME}', '{METADATA_BLOB_NAME}' with dimension {current_embedding_dimension}")
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            local_index_path = os.path.join(tmpdir, os.path.basename(INDEX_BLOB_NAME))
            local_metadata_path = os.path.join(tmpdir, os.path.basename(METADATA_BLOB_NAME))

            index_blob_client = _container_client.get_blob_client(INDEX_BLOB_NAME)
            if index_blob_client.exists():
                print(f"Downloading '{INDEX_BLOB_NAME}'...")
                with open(local_index_path, "wb") as download_file:
                    download_stream = index_blob_client.download_blob(timeout=60)
                    download_file.write(download_stream.readall())
                if os.path.getsize(local_index_path) > 0:
                    try:
                        idx = faiss.read_index(local_index_path)
                        if idx.d != current_embedding_dimension:
                            print(f"WARNING: Loaded FAISS index dimension ({idx.d}) does not match expected dimension ({current_embedding_dimension}). Re-initializing.")
                            idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []
                        else:
                            print(f"'{INDEX_BLOB_NAME}' loaded successfully from Blob Storage. Dimension: {idx.d}")
                    except Exception as e_faiss_read:
                        print(f"ERROR reading FAISS index: {e_faiss_read}. Re-initializing index.")
                        idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []
                else:
                    print(f"WARNING: '{INDEX_BLOB_NAME}' is empty in Blob. Using new index."); idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []
            else:
                print(f"WARNING: '{INDEX_BLOB_NAME}' not found in Blob Storage. New index will be used/created."); idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []

            if idx is not None:
                metadata_blob_client = _container_client.get_blob_client(METADATA_BLOB_NAME)
                if metadata_blob_client.exists() and (idx.ntotal > 0 or (index_blob_client.exists() and os.path.exists(local_index_path) and os.path.getsize(local_index_path) > 0) ):
                    print(f"Downloading '{METADATA_BLOB_NAME}'...")
                    with open(local_metadata_path, "wb") as download_file_meta:
                        download_stream_meta = metadata_blob_client.download_blob(timeout=60)
                        download_file_meta.write(download_stream_meta.readall())
                    if os.path.getsize(local_metadata_path) > 0 :
                        with open(local_metadata_path, "r", encoding="utf-8") as f_meta: meta = json.load(f_meta)
                    else: meta = []; print(f"WARNING: '{METADATA_BLOB_NAME}' is empty in Blob.")
                elif idx.ntotal == 0 and not index_blob_client.exists():
                     print(f"INFO: Index is new and empty, starting with empty metadata."); meta = []
                else:
                    print(f"INFO: Metadata file '{METADATA_BLOB_NAME}' not found or index is empty. Starting with empty metadata."); meta = []

            if idx is not None and idx.ntotal == 0 and len(meta) > 0:
                print(f"INFO: FAISS index is empty (ntotal=0) but metadata is not. Clearing metadata for consistency."); meta = []
            elif idx is not None and idx.ntotal > 0 and not meta and index_blob_client.exists() and os.path.exists(local_index_path) and os.path.getsize(local_index_path) > 0 :
                print(f"CRITICAL WARNING: FAISS index has data (ntotal={idx.ntotal}) but metadata is empty. This may lead to errors.")
    except AzureError as ae:
        st.error(f"Azure service error loading vector DB from Blob: {ae}"); print(f"AZURE ERROR loading vector DB: {ae}\n{traceback.format_exc()}"); idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []
    except Exception as e:
        st.error(f"Unknown error loading vector DB from Blob: {e}"); print(f"GENERAL ERROR loading vector DB: {e}\n{traceback.format_exc()}"); idx = faiss.IndexFlatL2(current_embedding_dimension); meta = []
    return idx, meta

index, metadata = faiss.IndexFlatL2(1536), []
if container_client:
    index, metadata = load_vector_db_from_blob_cached(container_client)
    print(f"DEBUG: FAISS index loaded after cache. ntotal: {index.ntotal if index else 'None'}, dimension: {index.d if index else 'N/A'}")
    print(f"DEBUG: Metadata loaded after cache. Length: {len(metadata) if metadata is not None else 'None'}")
else:
    st.error("Azure Blob Storage connection failed. Cannot load vector DB. File learning/search will be limited.")
    print("CRITICAL: Cannot load vector DB due to Blob client failure (main section).")

@st.cache_data
def load_prompt_rules_cached():
    default_rules = """1. ì œê³µëœ 'ë¬¸ì„œ ë‚´ìš©'ì„ ìµœìš°ì„ ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤. (ì´í•˜ ìƒëµ)"""
    if os.path.exists(RULES_PATH_REPO):
        try:
            with open(RULES_PATH_REPO, "r", encoding="utf-8") as f: rules_content = f.read()
            print(f"Prompt rules loaded successfully from '{RULES_PATH_REPO}'.")
            return rules_content
        except Exception as e:
            st.warning(f"Error loading '{RULES_PATH_REPO}': {e}. Using default rules."); print(f"WARNING: Error loading prompt rules: {e}. Using default."); return default_rules
    else:
        print(f"WARNING: Prompt rules file not found at '{RULES_PATH_REPO}'. Using default rules."); return default_rules
PROMPT_RULES_CONTENT = load_prompt_rules_cached()

def extract_text_from_file(uploaded_file_obj):
    ext = os.path.splitext(uploaded_file_obj.name)[1].lower()
    text_content = ""
    if ext in [".png", ".jpg", ".jpeg"]: return ""
    try:
        uploaded_file_obj.seek(0); file_bytes = uploaded_file_obj.read()
        if ext == ".pdf":
            with fitz.open(stream=file_bytes, filetype="pdf") as doc: text_content = "\n".join(page.get_text() for page in doc)
        elif ext == ".docx":
            with io.BytesIO(file_bytes) as doc_io:
                doc = docx.Document(doc_io); full_text = [p.text for p in doc.paragraphs]
                for table_idx, table in enumerate(doc.tables):
                    table_data_text = [f"--- Table {table_idx+1} Start ---"]
                    for row in table.rows: table_data_text.append(" | ".join(cell.text.strip() for cell in row.cells))
                    table_data_text.append(f"--- Table {table_idx+1} End ---"); full_text.append("\n".join(table_data_text))
                text_content = "\n\n".join(full_text)
        elif ext in (".xlsx", ".xlsm"):
            with io.BytesIO(file_bytes) as excel_io: df_dict = pd.read_excel(excel_io, sheet_name=None)
            text_content = "\n\n".join(f"--- Sheet: {name} ---\n{df.to_string(index=False)}" for name, df in df_dict.items())
        elif ext == ".csv":
            with io.BytesIO(file_bytes) as csv_io:
                try: df = pd.read_csv(csv_io)
                except UnicodeDecodeError: df = pd.read_csv(io.BytesIO(file_bytes), encoding='cp949') # seek(0)ì€ file_bytes ì‚¬ìš© ì‹œ ë¶ˆí•„ìš”
                text_content = df.to_string(index=False)
        elif ext == ".pptx":
            with io.BytesIO(file_bytes) as ppt_io: prs = Presentation(ppt_io); text_content = "\n".join(s.text for sl in prs.slides for s in sl.shapes if hasattr(s, "text"))
        elif ext == ".txt":
            try: text_content = file_bytes.decode('utf-8')
            except UnicodeDecodeError: text_content = file_bytes.decode('cp949')
        else: st.warning(f"Unsupported text file type: {ext}"); return ""
    except Exception as e: st.error(f"Error extracting text from '{uploaded_file_obj.name}': {e}"); print(f"ERROR extracting text: {e}\n{traceback.format_exc()}"); return ""
    return text_content.strip()

def save_original_file_to_blob(uploaded_file_obj, _container_client, base_path="original_files"):
    if not _container_client or not uploaded_file_obj: return None
    try:
        safe_file_name = re.sub(r'[\\/*?:"<>|]', "_", uploaded_file_obj.name)
        blob_name = f"{base_path}/{datetime.now().strftime('%Y%m%d%H%M%S')}_{safe_file_name}"
        blob_client_instance = _container_client.get_blob_client(blob_name)
        uploaded_file_obj.seek(0); file_bytes_for_original = uploaded_file_obj.read()
        with io.BytesIO(file_bytes_for_original) as data_stream:
            blob_client_instance.upload_blob(data_stream, overwrite=True, timeout=120)
        print(f"Successfully saved original file '{safe_file_name}' to Blob as '{blob_name}'"); return blob_name
    except Exception as e: print(f"ERROR saving original file to Blob: {e}"); return None

def log_openai_api_usage_to_blob(user_id, model_name, usage_object, _container_client, request_type="general_api_call"):
    if not _container_client: print(f"ERROR: Blob client None, cannot log API usage."); return False
    log_entry = {"timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "user_id": user_id, "model_name": model_name, "request_type": request_type, "prompt_tokens": getattr(usage_object, 'prompt_tokens', 0), "completion_tokens": getattr(usage_object, 'completion_tokens', 0), "total_tokens": getattr(usage_object, 'total_tokens', 0)}
    try:
        current_logs = load_data_from_blob(USAGE_LOG_BLOB_NAME, _container_client, "API usage log", default_value=[])
        if not isinstance(current_logs, list): current_logs = []
        current_logs.append(log_entry)
        if save_data_to_blob(current_logs, USAGE_LOG_BLOB_NAME, _container_client, "API usage log"): print(f"Successfully logged API usage for '{user_id}'."); return True
        else: print(f"ERROR: Failed to save API usage log after appending."); return False
    except Exception as e: print(f"GENERAL ERROR logging API usage: {e}\n{traceback.format_exc()}"); return False

def chunk_text_into_pieces(text_to_chunk, chunk_size=500):
    if not text_to_chunk or not text_to_chunk.strip(): return [];
    chunks_list, current_buffer = [], ""
    for line in text_to_chunk.split("\n"): 
        stripped_line = line.strip()
        if not stripped_line and not current_buffer.strip(): continue 
        if len(current_buffer) + len(stripped_line) + 1 < chunk_size: current_buffer += stripped_line + "\n"
        else: 
            if current_buffer.strip(): chunks_list.append(current_buffer.strip())
            current_buffer = stripped_line + "\n" 
    if current_buffer.strip(): chunks_list.append(current_buffer.strip())
    return [c for c in chunks_list if c] 

def get_image_description(image_bytes, image_filename, client_instance):
    if not client_instance: print("ERROR: OpenAI client not ready for image description."); return None
    print(f"DEBUG: Requesting description for image '{image_filename}'")
    try:
        base64_image = base64.b64encode(image_bytes).decode('utf-8')
        ext = os.path.splitext(image_filename)[1].lower(); mime_type = "image/jpeg" if ext in [".jpg", ".jpeg"] else "image/png" if ext == ".png" else "application/octet-stream"
        vision_model = st.secrets["AZURE_OPENAI_DEPLOYMENT"]
        response = client_instance.chat.completions.create(model=vision_model, messages=[{"role": "user", "content": [{"type": "text", "text": f"Describe this image ('{image_filename}') from a work/professional perspective for search and context. Mention key objects, states, GMP/SOP relevance if any."}, {"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{base64_image}" }}]}], max_tokens=IMAGE_DESCRIPTION_MAX_TOKENS, temperature=0.2, timeout=AZURE_OPENAI_TIMEOUT)
        description = response.choices[0].message.content.strip(); print(f"DEBUG: Image description for '{image_filename}' generated (len: {len(description)})."); return description
    except Exception as e: print(f"ERROR during image description for '{image_filename}': {e}\n{traceback.format_exc()}"); return None

def get_text_embedding(text_to_embed, client=openai_client, model=EMBEDDING_MODEL):
    if not client or not model or not text_to_embed or not text_to_embed.strip(): return None
    try: response = client.embeddings.create(input=[text_to_embed], model=model, timeout=AZURE_OPENAI_TIMEOUT / 2); return response.data[0].embedding
    except Exception as e: print(f"ERROR during single text embedding for '{text_to_embed[:30]}...': {e}"); return None

def get_batch_embeddings(texts_to_embed, client=openai_client, model=EMBEDDING_MODEL, batch_size=EMBEDDING_BATCH_SIZE):
    if not client or not model or not texts_to_embed: return []
    all_embeddings = []
    for i in range(0, len(texts_to_embed), batch_size):
        batch = texts_to_embed[i:i + batch_size]; 
        if not batch: continue
        print(f"DEBUG: Requesting embeddings for batch of {len(batch)} texts...")
        try:
            response = client.embeddings.create(input=batch, model=model, timeout=AZURE_OPENAI_TIMEOUT)
            batch_embeddings = [item.embedding for item in sorted(response.data, key=lambda e: e.index)]
            all_embeddings.extend(batch_embeddings); print(f"DEBUG: Embeddings received for batch {i//batch_size + 1}.")
        except Exception as e: print(f"ERROR during batch embedding for batch starting with '{batch[0][:30]}...': {e}"); all_embeddings.extend([None] * len(batch))
    return all_embeddings

def search_similar_chunks(query_text, k_results=3):
    if index is None or index.ntotal == 0 or not metadata: return []
    query_vector = get_text_embedding(query_text)
    if query_vector is None: return []
    try:
        actual_k = min(k_results, index.ntotal); 
        if actual_k == 0 : return []
        distances, indices_found = index.search(np.array([query_vector]).astype("float32"), actual_k)
        results = [{"source": metadata[i].get("file_name", "Unknown"), "content": metadata[i].get("content", ""), "is_image_description": metadata[i].get("is_image_description", False), "original_file_extension": metadata[i].get("original_file_extension", "")} for i in indices_found[0] if 0 <= i < len(metadata) and isinstance(metadata[i], dict)]
        return results
    except Exception as e: print(f"ERROR: Similarity search failed: {e}\n{traceback.format_exc()}"); return []

def add_document_to_vector_db_and_blob(uploaded_file_obj, processed_content, text_chunks, _container_client, is_image_description=False):
    global index, metadata
    if not text_chunks or not _container_client: st.warning(f"No content or Blob client for '{uploaded_file_obj.name}'."); return False
    file_type_log = "image desc" if is_image_description else "text"
    print(f"Adding '{file_type_log}' from '{uploaded_file_obj.name}' to vector DB.")
    chunk_embeddings = get_batch_embeddings(text_chunks)
    vectors_to_add, new_metadata = [], []
    for i, chunk in enumerate(text_chunks):
        embedding = chunk_embeddings[i] if i < len(chunk_embeddings) else None
        if embedding:
            vectors_to_add.append(embedding)
            new_metadata.append({"file_name": uploaded_file_obj.name, "content": chunk, "is_image_description": is_image_description, "original_file_extension": os.path.splitext(uploaded_file_obj.name)[1].lower()})
    if not vectors_to_add: st.error(f"No valid embeddings for '{uploaded_file_obj.name}'. Not learned."); return False
    try:
        dim = np.array(vectors_to_add[0]).shape[0]
        if index is None or index.d != dim: index = faiss.IndexFlatL2(dim); metadata = []
        if vectors_to_add: index.add(np.array(vectors_to_add).astype("float32"))
        metadata.extend(new_metadata)
        print(f"Added {len(vectors_to_add)} chunks from '{uploaded_file_obj.name}'. Index total: {index.ntotal}")
        with tempfile.TemporaryDirectory() as tmpdir:
            tmp_idx_path = os.path.join(tmpdir, "temp.index")
            if index.ntotal > 0: faiss.write_index(index, tmp_idx_path); save_binary_data_to_blob(tmp_idx_path, INDEX_BLOB_NAME, _container_client, "vector index")
        save_data_to_blob(metadata, METADATA_BLOB_NAME, _container_client, "metadata")
        uploader = st.session_state.user.get("name", "N/A")
        log_entry = {"file": uploaded_file_obj.name, "type": file_type_log, "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "chunks": len(vectors_to_add), "uploader": uploader}
        logs = load_data_from_blob(UPLOAD_LOG_BLOB_NAME, _container_client, "upload log", [])
        if not isinstance(logs, list): logs = []
        logs.append(log_entry); save_data_to_blob(logs, UPLOAD_LOG_BLOB_NAME, _container_client, "upload log")
        return True
    except Exception as e: st.error(f"Error learning doc or Blob upload: {e}"); print(f"ERROR adding doc: {e}\n{traceback.format_exc()}"); return False

chat_interface_tab, admin_settings_tab = None, None
if current_user_info.get("role") == "admin":
    chat_interface_tab, admin_settings_tab = st.tabs(["ğŸ’¬ ì±—ë´‡ ì§ˆë¬¸", "âš™ï¸ ê´€ë¦¬ì ì„¤ì •"])
else:
    chat_interface_tab = st.container() 

if chat_interface_tab:
    with chat_interface_tab:
        st.header("ì—…ë¬´ ì§ˆë¬¸")
        st.markdown("ğŸ’¡ ì˜ˆì‹œ: SOP ë°±ì—… ì£¼ê¸°, PIC/S Annex 11 ì°¨ì´, (íŒŒì¼ ì²¨ë¶€ í›„) ì´ ì‚¬ì§„ ì† ìƒí™©ì€ ì–´ë–¤ ê·œì •ì— í•´ë‹¹í•˜ë‚˜ìš”? ë“±")

        for msg_item in st.session_state.current_chat_messages: # current_chat_messages ì‚¬ìš©
            role, content, time_str = msg_item.get("role"), msg_item.get("content", ""), msg_item.get("time", "")
            align_class = "user-align" if role == "user" else "assistant-align"
            bubble_class = "user-bubble" if role == "user" else "assistant-bubble"
            st.markdown(f"""<div class="chat-bubble-container {align_class}"><div class="bubble {bubble_class}">{content}</div><div class="timestamp">{time_str}</div></div>""", unsafe_allow_html=True)

        st.markdown("<div style='height:16px'></div>", unsafe_allow_html=True) 
        if st.button("ğŸ“‚ íŒŒì¼ ì²¨ë¶€/ìˆ¨ê¸°ê¸°", key="toggle_chat_uploader_history_fix"): 
            st.session_state.show_uploader = not st.session_state.get("show_uploader", False)

        chat_file_uploader_key = "chat_file_uploader_history_fix_widget" 
        uploaded_chat_file_runtime = None 
        if st.session_state.get("show_uploader", False):
            uploaded_chat_file_runtime = st.file_uploader("ì§ˆë¬¸ê³¼ í•¨ê»˜ ì°¸ê³ í•  íŒŒì¼ ì²¨ë¶€ (ì„ íƒ ì‚¬í•­)",
                                     type=["pdf","docx","xlsx","xlsm","csv","pptx", "txt", "png", "jpg", "jpeg"], 
                                     key=chat_file_uploader_key)
            if uploaded_chat_file_runtime: 
                st.caption(f"ì²¨ë¶€ë¨: {uploaded_chat_file_runtime.name} ({uploaded_chat_file_runtime.type}, {uploaded_chat_file_runtime.size} bytes)")
                if uploaded_chat_file_runtime.type.startswith("image/"): st.image(uploaded_chat_file_runtime, width=200)

        with st.form("chat_input_form_history_fix", clear_on_submit=True): 
            query_input_col, send_button_col = st.columns([4,1])
            with query_input_col:
                user_query_input = st.text_input("ì§ˆë¬¸ ì…ë ¥:", placeholder="ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...", key="user_query_text_input_history_fix", label_visibility="collapsed") 
            with send_button_col: send_query_button = st.form_submit_button("ì „ì†¡")

        if send_query_button and user_query_input.strip():
            if not openai_client or not tokenizer:
                st.error("OpenAI ì„œë¹„ìŠ¤ ë˜ëŠ” í† í¬ë‚˜ì´ì €ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹µë³€ ìƒì„± ë¶ˆê°€."); st.stop()
            
            timestamp_now_str = datetime.now().strftime("%Y-%m-%d %H:%M")
            user_message_content = user_query_input
            if uploaded_chat_file_runtime: user_message_content += f"\n(ì²¨ë¶€ íŒŒì¼: {uploaded_chat_file_runtime.name})"
            
            st.session_state.current_chat_messages.append({"role":"user", "content":user_message_content, "time":timestamp_now_str})
            
            # active_conversation_idê°€ ì—†ë‹¤ë©´ (ìƒˆ ëŒ€í™” ì‹œì‘), ì´ ì‹œì ì—ì„œ IDë¥¼ ë¶€ì—¬í•˜ê³  all_user_conversationsì— ì„ì‹œ ì¶”ê°€ (ë‚˜ì¤‘ì— archiveì‹œ í™•ì •)
            # ë˜ëŠ”, ë‹µë³€ í›„ archive_current_chat_session_if_needed()ë¥¼ í˜¸ì¶œí•˜ì—¬ ì €ì¥/ì—…ë°ì´íŠ¸
            
            user_id_for_log = current_user_info.get("name", "anonymous_chat")
            print(f"User '{user_id_for_log}' submitted query: '{user_query_input[:50]}...' (File: {uploaded_chat_file_runtime.name if uploaded_chat_file_runtime else 'None'})")
            
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                assistant_response_content = "Error generating response."
                try: 
                    print("Step 1: Preparing context...")
                    context_items = []
                    text_from_chat_file, is_chat_file_img_desc, chat_file_src_name = None, False, None

                    if uploaded_chat_file_runtime:
                        ext = os.path.splitext(uploaded_chat_file_runtime.name)[1].lower()
                        is_img = ext in [".png", ".jpg", ".jpeg"]
                        if is_img:
                            with st.spinner(f"Analyzing image '{uploaded_chat_file_runtime.name}'..."):
                                desc = get_image_description(uploaded_chat_file_runtime.getvalue(), uploaded_chat_file_runtime.name, openai_client)
                            if desc: text_from_chat_file = desc; chat_file_src_name = f"User image: {uploaded_chat_file_runtime.name}"; is_chat_file_img_desc = True
                            else: st.warning(f"Failed to describe image '{uploaded_chat_file_runtime.name}'.")
                        else: 
                            text_from_chat_file = extract_text_from_file(uploaded_chat_file_runtime)
                            if text_from_chat_file: chat_file_src_name = f"User file: {uploaded_chat_file_runtime.name}"
                            elif text_from_chat_file == "": st.info(f"File '{uploaded_chat_file_runtime.name}' is empty or unreadable.")
                        if text_from_chat_file: context_items.append({"source": chat_file_src_name, "content": text_from_chat_file, "is_image_description": is_chat_file_img_desc})
                    
                    prompt_struct = f"{PROMPT_RULES_CONTENT}\n\nContext:\n<Doc Start>\n{{context}}\n<Doc End>"
                    base_tokens = len(tokenizer.encode(prompt_struct.replace('{context}', '')))
                    query_tokens = len(tokenizer.encode(user_query_input))
                    max_ctx_tokens = TARGET_INPUT_TOKENS_FOR_PROMPT - base_tokens - query_tokens
                    ctx_str = "No relevant documents found."

                    if max_ctx_tokens > 0:
                        query_for_search = user_query_input + (f"\nImage content: {text_from_chat_file}" if is_chat_file_img_desc and text_from_chat_file else "")
                        retrieved_db_items = search_similar_chunks(query_for_search, k_results=3)
                        if retrieved_db_items: context_items.extend(retrieved_db_items)
                        
                        if context_items:
                            seen_ctx = set(); fmt_ctx_chunks = []
                            for item in context_items:
                                content = item.get("content","").strip()
                                if content and content not in seen_ctx:
                                    src = item.get('source','Unknown').replace("User image: ","").replace("User file: ","")
                                    prefix = "[Image Desc: " if item.get("is_image_description") else "[Source: "
                                    fmt_ctx_chunks.append(f"{prefix}{src}]\n{content}")
                                    seen_ctx.add(content)
                            if fmt_ctx_chunks:
                                full_ctx_str = "\n\n---\n\n".join(fmt_ctx_chunks)
                                full_ctx_tokens = tokenizer.encode(full_ctx_str)
                                if len(full_ctx_tokens) > max_ctx_tokens:
                                    truncated_tokens = full_ctx_tokens[:max_ctx_tokens]
                                    ctx_str = tokenizer.decode(truncated_tokens) + "\n(...more content truncated.)"
                                else: ctx_str = full_ctx_str
                    
                    system_prompt = prompt_struct.replace('{context}', ctx_str)
                    final_prompt_tokens = len(tokenizer.encode(system_prompt)) + query_tokens
                    if final_prompt_tokens > MODEL_MAX_INPUT_TOKENS: print(f"CRITICAL WARNING: Final input tokens ({final_prompt_tokens}) > model max ({MODEL_MAX_INPUT_TOKENS})!")
                    
                    api_messages = [{"role":"system", "content": system_prompt}, {"role":"user", "content": user_query_input}]
                    print("Step 2: Sending request to Azure OpenAI...")
                    chat_model = st.secrets.get("AZURE_OPENAI_DEPLOYMENT")
                    if not chat_model: st.error("Chat model not configured in secrets."); raise ValueError("Chat model missing")
                        
                    completion = openai_client.chat.completions.create(model=chat_model, messages=api_messages, max_tokens=MODEL_MAX_OUTPUT_TOKENS, temperature=0.1, timeout=AZURE_OPENAI_TIMEOUT)
                    assistant_response_content = completion.choices[0].message.content.strip()
                    print("Azure OpenAI response received.")
                    if completion.usage and container_client: log_openai_api_usage_to_blob(user_id_for_log, chat_model, completion.usage, container_client, "chat_rag")
                
                except Exception as gen_err: 
                    assistant_response_content = f"Unexpected error: {gen_err}."
                    st.error(assistant_response_content); print(f"ERROR during response generation: {gen_err}\n{traceback.format_exc()}")

            st.session_state.current_chat_messages.append({"role":"assistant", "content":assistant_response_content, "time":timestamp_now_str})
            # ë‹µë³€ í›„ í˜„ì¬ ëŒ€í™” ìƒíƒœë¥¼ ì•„ì¹´ì´ë¸Œ/ì—…ë°ì´íŠ¸.
            # active_conversation_idê°€ Noneì´ì—ˆë‹¤ë©´, archive í•¨ìˆ˜ ë‚´ì—ì„œ ìƒˆë¡œ ìƒì„±ë˜ê³  all_user_conversationsì— ì¶”ê°€ë¨.
            # ê·¸ í›„ active_conversation_idë¥¼ ì—…ë°ì´íŠ¸ í•´ì¤˜ì•¼ í•¨.
            if st.session_state.active_conversation_id is None and st.session_state.all_user_conversations:
                 # archive_current_chat_session_if_neededê°€ í˜¸ì¶œë˜ë©´ ìƒˆ IDê°€ all_user_conversations[0]ì— ìƒê¹€
                 # í•˜ì§€ë§Œ archive_current_chat_session_if_neededëŠ” ì•„ì§ ì—¬ê¸°ì„œ í˜¸ì¶œë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ,
                 # archive_current_chat_session_if_needed í˜¸ì¶œ ì „ì— active_idë¥¼ ì„¤ì •í•´ì•¼ í•œë‹¤ë©´,
                 # ë˜ëŠ” archive í•¨ìˆ˜ê°€ ìƒˆ IDë¥¼ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •í•´ì•¼ í•¨.
                 # ì—¬ê¸°ì„œëŠ” ê·¸ëƒ¥ ë‘ê³ , ì»¨í…ìŠ¤íŠ¸ ì „í™˜ ì‹œ (ìƒˆ ëŒ€í™”, ë‹¤ë¥¸ ëŒ€í™” ë¡œë“œ, ë¡œê·¸ì•„ì›ƒ) archiveê°€ ì²˜ë¦¬í•˜ë„ë¡ í•¨.
                 pass # active_idëŠ” ì»¨í…ìŠ¤íŠ¸ ì „í™˜ ì‹œ ê²°ì •ë¨

            print("Response processing complete. Triggering rerun."); st.rerun()

if admin_settings_tab:
    with admin_settings_tab:
        st.header("âš™ï¸ ê´€ë¦¬ì ì„¤ì •")
        st.subheader("ğŸ‘¥ ê°€ì… ìŠ¹ì¸ ëŒ€ê¸°ì")
        if not USERS or not isinstance(USERS, dict): st.warning("User info error.")
        else:
            pending = {uid:udata for uid,udata in USERS.items() if isinstance(udata, dict) and not udata.get("approved")}
            if pending:
                for uid, udata in pending.items():
                    with st.expander(f"{udata.get('name','N/A')} ({uid}) - {udata.get('department','N/A')}"):
                        app_col, rej_col = st.columns(2)
                        if app_col.button("ìŠ¹ì¸", key=f"admin_approve_{uid}"): 
                            USERS[uid]["approved"] = True
                            if save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "user approval"): st.success(f"User '{uid}' approved."); st.rerun()
                            else: st.error("Failed to save approval.")
                        if rej_col.button("ê±°ì ˆ", key=f"admin_reject_{uid}"): 
                            USERS.pop(uid, None)
                            if save_data_to_blob(USERS, USERS_BLOB_NAME, container_client, "user rejection"): st.info(f"User '{uid}' rejected."); st.rerun()
                            else: st.error("Failed to save rejection.")
            else: st.info("No users pending approval.")
        st.markdown("---")

        st.subheader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ë° í•™ìŠµ (Azure Blob Storage)")
        if 'processed_admin_file_info' not in st.session_state: st.session_state.processed_admin_file_info = None
        def clear_admin_file_info(): st.session_state.processed_admin_file_info = None
        admin_file = st.file_uploader("í•™ìŠµ íŒŒì¼ (PDF, DOCX, XLSX, CSV, PPTX, TXT, PNG, JPG, JPEG)", type=["pdf","docx","xlsx","xlsm","csv","pptx", "txt", "png", "jpg", "jpeg"], key="admin_uploader_hist_fix", on_change=clear_admin_file_info)

        if admin_file and container_client:
            file_info = (admin_file.name, admin_file.size, admin_file.type)
            if st.session_state.processed_admin_file_info != file_info:
                print(f"DEBUG Admin Upload: New file {file_info}")
                try: 
                    ext = os.path.splitext(admin_file.name)[1].lower(); is_img = ext in [".png", ".jpg", ".jpeg"]
                    content, is_img_desc = None, False
                    if is_img:
                        with st.spinner(f"Processing image '{admin_file.name}'..."):
                            desc = get_image_description(admin_file.getvalue(), admin_file.name, openai_client)
                        if desc: content = desc; is_img_desc = True; st.info(f"Image '{admin_file.name}' description generated (Len: {len(desc)})."); st.text_area("Desc:", desc, height=150, disabled=True)
                        else: st.error(f"Failed to describe image '{admin_file.name}'.")
                    else: 
                        with st.spinner(f"Extracting text from '{admin_file.name}'..."): content = extract_text_from_file(admin_file)
                        if content: st.info(f"Text extracted from '{admin_file.name}' (Len: {len(content)}).")
                        else: st.warning(f"No content from '{admin_file.name}'.")
                    
                    if content: 
                        with st.spinner(f"Learning content from '{admin_file.name}'..."):
                            chunks = chunk_text_into_pieces(content)
                            if chunks:
                                path = save_original_file_to_blob(admin_file, container_client)
                                if path: st.caption(f"Original '{admin_file.name}' saved to Blob: '{path}'.")
                                else: st.warning(f"Failed to save original '{admin_file.name}' to Blob.")
                                if add_document_to_vector_db_and_blob(admin_file, content, chunks, container_client, is_img_desc):
                                    st.success(f"File '{admin_file.name}' learned and updated to Azure Blob!"); st.session_state.processed_admin_file_info = file_info; st.rerun()
                                else: st.error(f"Error learning or Blob update for '{admin_file.name}'."); st.session_state.processed_admin_file_info = None
                            else: st.warning(f"No learning chunks for '{admin_file.name}'.")
                except Exception as e_admin_proc: st.error(f"Error processing admin file {admin_file.name}: {e_admin_proc}"); print(f"CRITICAL ERROR admin_upload for {admin_file.name}: {e_admin_proc}\n{traceback.format_exc()}"); st.session_state.processed_admin_file_info = None
            elif st.session_state.processed_admin_file_info == file_info: st.caption(f"File '{admin_file.name}' previously processed. Re-upload to re-learn.")
        elif admin_file and not container_client: st.error("Cannot upload: Azure Blob client not ready.")
        st.markdown("---")

        st.subheader("ğŸ“Š API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (Blob ë¡œê·¸ ê¸°ë°˜)")
        if container_client:
            usage_data = load_data_from_blob(USAGE_LOG_BLOB_NAME, container_client, "API usage log", [])
            if usage_data and isinstance(usage_data, list) and len(usage_data) > 0 :
                df = pd.DataFrame(usage_data)
                for col in ["total_tokens", "prompt_tokens", "completion_tokens"]: df[col] = pd.to_numeric(df.get(col, 0), errors='coerce').fillna(0)
                if "request_type" not in df.columns: df["request_type"] = "unknown"
                total_tokens = df["total_tokens"].sum()
                st.metric("ì´ API í˜¸ì¶œ", len(df)); st.metric("ì´ ì‚¬ìš© í† í°", f"{int(total_tokens):,}")
                cost_unit = 0.0; 
                try: cost_unit=float(st.secrets.get("TOKEN_COST","0"))
                except: pass
                st.metric("ì˜ˆìƒ ë¹„ìš© (USD)", f"${total_tokens * cost_unit:.4f}") 
                if "timestamp" in df.columns:
                    try: df['timestamp'] = pd.to_datetime(df['timestamp']); st.dataframe(df.sort_values(by="timestamp",ascending=False), use_container_width=True)
                    except: st.dataframe(df, use_container_width=True) 
                else: st.dataframe(df, use_container_width=True)
            else: st.info("No API usage data recorded.")
        else: st.warning("Cannot display API usage: Azure Blob client not ready.")
        st.markdown("---")

        st.subheader("ğŸ“‚ Azure Blob Storage íŒŒì¼ ëª©ë¡ (ìµœê·¼ 100ê°œ)")
        if container_client:
            try:
                blobs_display = []
                blobs_sorted = sorted(container_client.list_blobs(), key=lambda b: b.last_modified, reverse=True)
                for i, blob in enumerate(blobs_sorted):
                    if i >= 100: break
                    blobs_display.append({"íŒŒì¼ëª…": blob.name, "í¬ê¸° (bytes)": blob.size, "ìˆ˜ì •ì¼": blob.last_modified.strftime('%Y-%m-%d %H:%M:%S') if blob.last_modified else 'N/A'})
                if blobs_display: st.dataframe(pd.DataFrame(blobs_display), use_container_width=True)
                else: st.info("No files in Azure Blob Storage.")
            except Exception as e_list_blobs: st.error(f"Error listing Blobs: {e_list_blobs}"); print(f"ERROR listing blobs: {e_list_blobs}\n{traceback.format_exc()}")
        else: st.warning("Cannot display file list: Azure Blob client not ready.")
